Colt/xml/cern/clhep/PhysicalConstants.xml
44	3.14159265358979323846;
54	c   = 299.792458 mm/ns c^2 = 898.7404 (mm/ns)^2
61	h     = 4.13566e-12 MeV*ns hbar  = 6.58212e-13 MeV*ns hbarc = 197.32705e-12 MeV*mm
74	see SystemOfUnits.h
77	amu_c2 - atomic equivalent mass unit amu    - atomic mass unit
87	permeability of free space mu0    = 2.01334e-16 Mev*(ns*eplus)^2/mm permittivity of free space epsil0 = 5.52636e+10 eplus^2/(MeV*mm)
94	electromagnetic coupling = 1.43996e-12 MeV*mm/(eplus^2)

Colt/xml/cern/clhep/Units.xml
48	symbols
65	Angle
70	(3.14159265358979323846/180.0)*radian;
74	symbols
80	Time [T]
93	symbols
98	Electric charge [Q]
101	positron charge
102	positron charge in coulomb
103	coulomb = 6.24150 e+18 * eplus
105	Energy [E]
115	joule = 6.24150 e+12 * MeV
117	symbols
125	Mass [E][T^2][L^-2]
132	symbols
137	Power [E][T^-1]
140	watt = 6.24150 e+3 * MeV/ns
142	Force [E][L^-1]
145	newton = 6.24150 e+9 * MeV/mm
147	Pressure [E][L^-3]
150	pascal = 6.24150 e+3 * MeV/mm3
152	bar    = 6.24150 e+8 * MeV/mm3
153	atm    = 6.32420 e+8 * MeV/mm3
155	Electric current [Q][T^-1]
158	ampere = 6.24150 e+9 * eplus/ns
163	Electric potential [E][Q^-1]
170	Electric resistance [E][T][Q^-2]
173	ohm = 1.60217e-16*(MeV/eplus)/(eplus/ns)
175	Electric capacitance [Q^2][E^-1]
178	farad = 6.24150e+24 * eplus/Megavolt
184	Magnetic Flux [T][E][Q^-1]
187	weber = 1000*megavolt*ns
189	Magnetic Field [T][E][Q^-1][L^-2]
192	tesla =0.001*megavolt*ns/mm2
197	Inductance [T^2][E][Q^-2]
200	henry = 1.60217e-7*MeV*(ns/eplus)**2
202	Temperature
207	Amount of substance
212	Activity [T^-1]
218	Absorbed dose [L^2][T^-2]
223	Luminous intensity [I]
228	Luminous flux [I]
233	Illuminance [I][L^-2]
238	Miscellaneous

Colt/xml/cern/colt/Arrays.xml
100	for (int i = oldCapacity; --i >= 0; ) newArray[i] = array[i];

Colt/xml/cern/colt/bitvector/BitMatrix.xml
42	The bits of this matrix. bits are stored in row major, i.e. bitIndex==rowcolumns + column columnOf(bitIndex)==bitIndex%columns rowOf(bitIndex)==bitIndexcolumns
190	this is equivalent to the low level version below, apart from that it iterates in the reverse oder and is slower. if (size()==0) return true; BitVector vector = toBitVector(); return vector.forEachIndexFromToInState(0,size()-1,state, new cern.colt.function.IntFunction() { public boolean apply(int index) { return function.apply(index%columns, indexcolumns); } } );
203	low level implementation for speed.
212	for each coordinate of bits of partial unit
226	for each coordinate of bits of full units
230	all 64 bits set
235	at least one element within current unit matches. iterate over all bits within current unit.
248	unrolled comparison for speed.
261	no element within current unit matches --> skip unit
264	avoid implementation with *, /, %
402	dangerous intersection

Colt/xml/cern/colt/bitvector/BitVector.xml
53	Bits are packed into arrays of "units."  Currently a unit is a long, which consists of 64 bits, requiring 6 address bits.  The choice of unit is determined purely by performance concerns.
68	the size
70	IntProcedure for method indexOfFromTo(...)
118	cached for speed.
119	cached for speed.
132	cached for speed.
133	cached for speed.
145	determine cardinality on full units
149	all bits set?
152	more than one bit set?
159	determine cardinality on remaining partial unit, if any.
186	new LongArrayList(bits).fillFromToWith(0,size()-1,0L);
280	perform logical comparison on full units
284	perform logical comparison on remaining bits
312	this version is equivalent to the low level version below, but about 100 times slower for large ranges. if (nbits==0) return true; checkRangeFromTo(from, to, nbits); final long[] theBits = this.bits;  cached for speed int length=to-from+1; for (int i=from; --length >= 0; i++) { if (QuickBitVector.get(theBits,i)==state) { if (!function.apply(i)) return false; } } return true;
327	This low level implementation exploits the fact that for any full unit one can determine in O(1) whether it contains at least one true bit, and whether it contains at least one false bit. Thus, 64 bits can often be skipped with one simple comparison if the vector is either sparse or dense.  However, careful coding must be done for leading andor trailing units which are not entirely contained in the query range.
338	System.out.println("\n"); System.out.println(this); System.out.println("from="+from+", to="+to+", bit="+state);
342	Cache some vars for speed.
346	Prepare
349	current bitvector index
351	Iterate over the leading partial unit, if any.
354	There exists a leading partial unit.
356	System.out.println("partialWidth1="+partialWidth);
362	leading partial unit is done.
365	done
367	If there is a trailing partial unit, then there is one full unit less to test.
370	trailing partial unit needs to be tested extra.
376	System.out.println("partialWidth2="+partialWidth);
378	Iterate over all full units, if any. (It does not matter that iterating over partial units is a little bit slow, the only thing that matters is that iterating over full units is quick.)
383	all 64 bits set
385	System.out.println("fromUnit="+fromUnit+", toUnit="+toUnit);
389	at least one element within current unit matches. iterate over all bits within current unit.
393	is bit set?
400	is bit cleared?
411	System.out.println("trail with i="+i);
413	Iterate over trailing partial unit, if any.
548	cached for speed.
549	cached for speed.
636	dangerous intersection
640	cached for speed.
641	cached for speed.
643	This version is equivalent to the version below but 20 times slower... for (int i=from; --length >= 0; i++, sourceFrom++) { QuickBitVector.put(theBits,i,QuickBitVector.get(sourceBits,sourceFrom)); }
650	Low level implementation for speed. This could be done even faster by implementing on even lower levels. But then the code would probably become a "don't touch" piece.
653	width/64
657	copy entire 64 bit blocks, if any.
665	copy trailing bits, if any.
666	width%64
683	cached for speed
696	only one unit to do
698	slower: for (; bitIndex<=to; ) QuickBitVector.put(theBits,bitIndex++,value);
702	treat leading partial unit, if any.
703	fix by Olivier Janssens
706	slower: for (int i=bitsPerUnit-fromOffset; --i >= 0; ) { QuickBitVector.put(theBits,bitIndex++,value);
712	there is a trailing partial unit
714	treat full units, if any.
718	treat trailing partial unit, if any.
721	slower: for (int i=toOffset+1; --i >= 0; ) { QuickBitVector.put(theBits,bitIndex++,value);
801	cached for speed.
802	cached for speed.

Colt/xml/cern/colt/bitvector/QuickBitVector.xml
33	64=2^6
34	= 1 << ADDRESS_BITS_PER_UNIT
35	= BITS_PER_UNIT - 1;
37	precompute bitmasks for speed
56	This turned out to be slower: 0xffffffffffffffffL == ~0L == -1L == all 64 bits set. int width; return (width=to-from+1) == 0 ? 0L : (0xffffffffffffffffL >>> (BITS_PER_UNIT-width)) << from;
96	equivalent to from/64
98	equivalent to from%64
100	this is equivalent to the above, but slower: final int fromIndex=from/BITS_PER_UNIT; final int toIndex=to/BITS_PER_UNIT; final int fromOffset=from%BITS_PER_UNIT; final int toOffset=to%BITS_PER_UNIT;
108	range does not cross unit boundaries; value to retrieve is contained in one single long value.
114	range crosses unit boundaries; value to retrieve is spread over two long values. get part from first long value
119	get part from second long value
123	combine
176	equivalent to bitIndex%64
189	System.out.println((i)+":"+pows[i]);
192	System.out.println((0)+":"+pows[0]);
195	OLD STUFF
196	for (int i=BITS_PER_UNIT+1; --i >= 0; ) { pows[i]=value; value = value >>> 1; System.out.println((i)+":"+pows[i]); }
204	long[] pows=new long[BITS_PER_UNIT]; for (int i=0; i<BITS_PER_UNIT-1; i++) { pows[i]=Math.round(Math.pow(2.0,i+1))-1; System.out.println((i)+":"+pows[i]); } pows[BITS_PER_UNIT-1] = ~0L; System.out.println((BITS_PER_UNIT-1)+":"+pows[BITS_PER_UNIT-1]); return pows;
243	equivalent to from/64
245	equivalent to from%64
247	this is equivalent to the above, but slower: int fromIndex=fromBITS_PER_UNIT; int toIndex=toBITS_PER_UNIT; int fromOffset=from%BITS_PER_UNIT; int toOffset=to%BITS_PER_UNIT;
255	make sure all unused bits to the left are cleared.
262	range does not cross unit boundaries; should go into one single long value.
270	range crosses unit boundaries; value should go into two long values. copy into first long value.
276	copy into second long value.
295	equivalent to bitIndex/64

Colt/xml/cern/colt/buffer/DoubleBuffer.xml
23	vars cached for speed

Colt/xml/cern/colt/buffer/DoubleBuffer2D.xml
24	vars cached for speed

Colt/xml/cern/colt/buffer/DoubleBuffer2DConsumer.xml

Colt/xml/cern/colt/buffer/DoubleBuffer3D.xml
25	vars cached for speed

Colt/xml/cern/colt/buffer/DoubleBuffer3DConsumer.xml

Colt/xml/cern/colt/buffer/DoubleBufferConsumer.xml

Colt/xml/cern/colt/buffer/IntBuffer.xml
23	vars cached for speed

Colt/xml/cern/colt/buffer/IntBuffer2D.xml
24	vars cached for speed

Colt/xml/cern/colt/buffer/IntBuffer2DConsumer.xml

Colt/xml/cern/colt/buffer/IntBuffer3D.xml
25	vars cached for speed

Colt/xml/cern/colt/buffer/IntBuffer3DConsumer.xml

Colt/xml/cern/colt/buffer/IntBufferConsumer.xml

Colt/xml/cern/colt/buffer/ObjectBuffer.xml
23	vars cached for speed

Colt/xml/cern/colt/buffer/ObjectBufferConsumer.xml

Colt/xml/cern/colt/function/BooleanProcedure.xml

Colt/xml/cern/colt/function/ByteComparator.xml

Colt/xml/cern/colt/function/ByteProcedure.xml

Colt/xml/cern/colt/function/CharComparator.xml

Colt/xml/cern/colt/function/CharProcedure.xml

Colt/xml/cern/colt/function/Double27Function.xml

Colt/xml/cern/colt/function/Double5Function.xml

Colt/xml/cern/colt/function/Double9Function.xml

Colt/xml/cern/colt/function/DoubleComparator.xml

Colt/xml/cern/colt/function/DoubleDoubleFunction.xml

Colt/xml/cern/colt/function/DoubleDoubleProcedure.xml

Colt/xml/cern/colt/function/DoubleFunction.xml

Colt/xml/cern/colt/function/DoubleIntProcedure.xml

Colt/xml/cern/colt/function/DoubleProcedure.xml

Colt/xml/cern/colt/function/FloatComparator.xml

Colt/xml/cern/colt/function/FloatProcedure.xml

Colt/xml/cern/colt/function/IntComparator.xml

Colt/xml/cern/colt/function/IntDoubleFunction.xml

Colt/xml/cern/colt/function/IntDoubleProcedure.xml

Colt/xml/cern/colt/function/IntFunction.xml

Colt/xml/cern/colt/function/IntIntDoubleFunction.xml

Colt/xml/cern/colt/function/IntIntDoubleProcedure.xml

Colt/xml/cern/colt/function/IntIntFunction.xml

Colt/xml/cern/colt/function/IntIntIntProcedure.xml

Colt/xml/cern/colt/function/IntIntProcedure.xml

Colt/xml/cern/colt/function/IntObjectProcedure.xml

Colt/xml/cern/colt/function/IntProcedure.xml

Colt/xml/cern/colt/function/LongComparator.xml

Colt/xml/cern/colt/function/LongObjectProcedure.xml

Colt/xml/cern/colt/function/LongProcedure.xml

Colt/xml/cern/colt/function/ObjectFunction.xml

Colt/xml/cern/colt/function/ObjectObjectFunction.xml

Colt/xml/cern/colt/function/ObjectProcedure.xml

Colt/xml/cern/colt/function/ShortComparator.xml

Colt/xml/cern/colt/function/ShortProcedure.xml

Colt/xml/cern/colt/GenericPermuting.xml
143	factorial(21) would overflow 64-bit long)
144	Simply make a list (0,1,..N-1) and randomize it, seeded with "p". Note that this is perhaps not what you want...
151	swap(i, random)
160	the normal case - exact enumeration
238	"tracks" and "pos" keeps track of the current indexes of the elements Example: We have a list==[A,B,C,D,E], indexes==[0,4,1,2,3] and swap B and E we need to know that the element formlerly at index 1 is now at index 4, and the one formerly at index 4 is now at index 1. Otherwise we stumble over our own feet and produce nonsense. Initially index i really is at index i, but this will change due to swapping.
243	work1, work2 to avoid high frequency memalloc's

Colt/xml/cern/colt/GenericSorting.xml
183	rotate(firstCut, middle, secondCut, swapper); is manually inlined for speed (jitter inlining seems to work only for small call depths, even if methods are "static private") speedup = 1.7 begin inline
196	end inline
220	if (comp==null) throw new NullPointerException();
272	We retain the same method signature as quickSort. Given only a comparator and swapper we do not know how to copy and move elements fromto temporary arrays. Hence, in contrast to the JDK mergesorts this is an "in-place" mergesort, i.e. does not allocate any temporary arrays. A non-inplace mergesort would perhaps be faster in most cases, but would require non-intuitive delegate objects...
280	Insertion sort on smallest arrays
290	Recursively sort halves
295	If list is already sorted, nothing left to do.  This is an optimization that results in faster sorts for nearly ordered lists.
299	Merge sorted halves
332	Insertion sort on smallest arrays
341	Choose a partition element, v
342	Small arrays, middle element
346	Big arrays, pseudomedian of 9
352	Mid-size, med of 3
354	long v = x[m];
356	Establish Invariant: v* (<v)* (>v)* v*
362	moving target; DELTA to JDK !!!
363	moving target; DELTA to JDK !!!
370	moving target; DELTA to JDK !!!
371	moving target; DELTA to JDK !!!
377	moving target; DELTA to JDK !!!
378	moving target; DELTA to JDK !!!
382	Swap partition elements back to middle
387	Recursively sort non-partition-elements
402	no more needed since manually inlined
420	no more needed since manually inlined
445	if (comp==null) throw new NullPointerException();

Colt/xml/cern/colt/GenericSortingTest.xml

Colt/xml/cern/colt/list/AbstractBooleanList.xml
152	key found
154	key not found.
226	delta
290	delta
309	found
311	not found
339	found
341	not found
366	nothing to do
393	fillFromToWith(from+numMoved, size-1, 0.0f); //delta
414	unambiguous copy (it may hold other==this)
474	avoid stumbling over my own feet
516	delta
551	swap
613	swap(i, random)

Colt/xml/cern/colt/list/AbstractByteList.xml
152	key found
154	key not found.
226	delta
290	delta
309	found
311	not found
339	found
341	not found
490	nothing to do
517	fillFromToWith(from+numMoved, size-1, 0.0f); //delta
538	unambiguous copy (it may hold other==this)
598	avoid stumbling over my own feet
640	delta
675	swap
737	swap(i, random)

Colt/xml/cern/colt/list/AbstractCharList.xml
152	key found
154	key not found.
226	delta
290	delta
309	found
311	not found
339	found
341	not found
490	nothing to do
517	fillFromToWith(from+numMoved, size-1, 0.0f); //delta
538	unambiguous copy (it may hold other==this)
598	avoid stumbling over my own feet
640	delta
675	swap
737	swap(i, random)

Colt/xml/cern/colt/list/AbstractCollection.xml
24	public abstract class AbstractCollection extends Object implements Cloneable, java.io.Serializable {

Colt/xml/cern/colt/list/AbstractDoubleList.xml
160	key found
162	key not found.
234	delta
298	delta
317	found
319	not found
347	found
349	not found
451	cern.colt.Sorting.mergeSort(myElements, from, to+1); // TODO just for debugging
500	nothing to do
527	fillFromToWith(from+numMoved, size-1, 0.0f); //delta
548	unambiguous copy (it may hold other==this)
608	avoid stumbling over my own feet
650	delta
685	swap
747	swap(i, random)

Colt/xml/cern/colt/list/AbstractFloatList.xml
152	key found
154	key not found.
226	delta
290	delta
309	found
311	not found
339	found
341	not found
490	nothing to do
517	fillFromToWith(from+numMoved, size-1, 0.0f); //delta
538	unambiguous copy (it may hold other==this)
598	avoid stumbling over my own feet
640	delta
675	swap
737	swap(i, random)

Colt/xml/cern/colt/list/AbstractIntList.xml
159	key found
161	key not found.
233	delta
297	delta
316	found
318	not found
346	found
348	not found
450	cern.colt.Sorting.mergeSort(myElements, from, to+1); // TODO just for debugging
498	nothing to do
525	fillFromToWith(from+numMoved, size-1, 0.0f); //delta
546	unambiguous copy (it may hold other==this)
606	avoid stumbling over my own feet
648	delta
683	swap
745	swap(i, random)

Colt/xml/cern/colt/list/AbstractList.xml

Colt/xml/cern/colt/list/AbstractLongList.xml
152	key found
154	key not found.
226	delta
290	delta
309	found
311	not found
339	found
341	not found
490	nothing to do
517	fillFromToWith(from+numMoved, size-1, 0.0f); //delta
538	unambiguous copy (it may hold other==this)
598	avoid stumbling over my own feet
640	delta
675	swap
737	swap(i, random)

Colt/xml/cern/colt/list/AbstractShortList.xml
152	key found
154	key not found.
226	delta
290	delta
309	found
311	not found
339	found
341	not found
490	nothing to do
517	fillFromToWith(from+numMoved, size-1, 0.0f); //delta
538	unambiguous copy (it may hold other==this)
598	avoid stumbling over my own feet
640	delta
675	swap
737	swap(i, random)

Colt/xml/cern/colt/list/adapter/DoubleListAdapter.xml

Colt/xml/cern/colt/list/adapter/FloatListAdapter.xml

Colt/xml/cern/colt/list/adapter/IntListAdapter.xml

Colt/xml/cern/colt/list/adapter/LongListAdapter.xml

Colt/xml/cern/colt/list/adapter/ObjectListAdapter.xml

Colt/xml/cern/colt/list/BooleanArrayList.xml
57	overridden for performance only.
73	overridden for performance only.
87	overridden for performance only.
166	delta
167	overridden for performance only.
188	overridden for performance only.
203	overridden for performance only.
232	overridden for performance only.
238	found
240	not found
255	overridden for performance only.
261	found
263	not found
315	overridden for performance only.
318	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
328	nothing to do
337	it is faster to sort other before searching in it
346	it is faster to search in other without sorting
367	overridden for performance only.
369	slower
388	overridden for performance only.
391	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
409	it is faster to sort other before searching in it
418	it is faster to search in other without sorting
433	overridden for performance only.
439	swap
454	overridden for performance only.
478	overridden for performance only.
489	swap(i, random)

Colt/xml/cern/colt/list/ByteArrayList.xml
57	overridden for performance only.
73	overridden for performance only.
113	overridden for performance only.
243	delta
244	overridden for performance only.
265	overridden for performance only.
280	overridden for performance only.
309	overridden for performance only.
315	found
317	not found
332	overridden for performance only.
338	found
340	not found
366	overridden for performance only.
369	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
379	nothing to do
388	it is faster to sort other before searching in it
397	it is faster to search in other without sorting
418	overridden for performance only.
420	slower
439	overridden for performance only.
442	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
460	it is faster to sort other before searching in it
469	it is faster to search in other without sorting
484	overridden for performance only.
490	swap
505	overridden for performance only.
529	overridden for performance only.
540	swap(i, random)
556	try to figure out which option is fastest.
558	O(N*log(N,base=2)) ; ln(2)=0.6931471805599453
561	O(Max(width,N))

Colt/xml/cern/colt/list/CharArrayList.xml
57	overridden for performance only.
73	overridden for performance only.
113	overridden for performance only.
209	delta
210	overridden for performance only.
231	overridden for performance only.
246	overridden for performance only.
275	overridden for performance only.
281	found
283	not found
298	overridden for performance only.
304	found
306	not found
332	overridden for performance only.
335	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
345	nothing to do
354	it is faster to sort other before searching in it
363	it is faster to search in other without sorting
384	overridden for performance only.
386	slower
405	overridden for performance only.
408	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
426	it is faster to sort other before searching in it
435	it is faster to search in other without sorting
450	overridden for performance only.
456	swap
471	overridden for performance only.
495	overridden for performance only.
506	swap(i, random)
529	Computes min and max and decides on this basis. In practice the additional overhead is very small compared to the potential gains.
533	never consider options resulting in outrageous memory allocations.
538	determine minimum and maximum.
549	try to figure out which option is fastest.
551	O(N*log(N,base=2)) ; ln(2)=0.6931471805599453
554	O(Max(width,N))

Colt/xml/cern/colt/list/DistinctNumberList.xml
76	overridden for performance only.
150	java.util.Arrays.sort(this.distinctElements);

Colt/xml/cern/colt/list/DoubleArrayList.xml
57	overridden for performance only.
71	overridden for performance only.
115	overridden for performance only.
173	delta
174	overridden for performance only.
195	overridden for performance only.
210	overridden for performance only.
239	overridden for performance only.
245	found
247	not found
262	overridden for performance only.
268	found
270	not found
296	overridden for performance only.
299	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
309	nothing to do
318	it is faster to sort other before searching in it
327	it is faster to search in other without sorting
348	overridden for performance only.
350	slower
369	overridden for performance only.
372	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
390	it is faster to sort other before searching in it
399	it is faster to search in other without sorting
414	overridden for performance only.
420	swap
435	overridden for performance only.
459	overridden for performance only.
470	swap(i, random)

Colt/xml/cern/colt/list/FloatArrayList.xml
57	overridden for performance only.
71	overridden for performance only.
111	overridden for performance only.
169	delta
170	overridden for performance only.
191	overridden for performance only.
206	overridden for performance only.
235	overridden for performance only.
241	found
243	not found
258	overridden for performance only.
264	found
266	not found
292	overridden for performance only.
295	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
305	nothing to do
314	it is faster to sort other before searching in it
323	it is faster to search in other without sorting
344	overridden for performance only.
346	slower
365	overridden for performance only.
368	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
386	it is faster to sort other before searching in it
395	it is faster to search in other without sorting
410	overridden for performance only.
416	swap
431	overridden for performance only.
455	overridden for performance only.
466	swap(i, random)

Colt/xml/cern/colt/list/IntArrayList.xml
57	overridden for performance only.
73	overridden for performance only.
117	overridden for performance only.
213	delta
214	overridden for performance only.
235	overridden for performance only.
250	overridden for performance only.
279	overridden for performance only.
285	found
287	not found
302	overridden for performance only.
308	found
310	not found
336	overridden for performance only.
339	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
349	nothing to do
358	it is faster to sort other before searching in it
367	it is faster to search in other without sorting
388	overridden for performance only.
390	slower
409	overridden for performance only.
412	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
430	it is faster to sort other before searching in it
439	it is faster to search in other without sorting
454	overridden for performance only.
460	swap
475	overridden for performance only.
499	overridden for performance only.
510	swap(i, random)
533	Computes min and max and decides on this basis. In practice the additional overhead is very small compared to the potential gains.
537	never consider options resulting in outrageous memory allocations.
542	determine minimum and maximum.
553	try to figure out which option is fastest.
555	O(N*log(N,base=2)) ; ln(2)=0.6931471805599453
558	O(Max(width,N))

Colt/xml/cern/colt/list/LongArrayList.xml
57	overridden for performance only.
71	overridden for performance only.
111	overridden for performance only.
207	delta
208	overridden for performance only.
229	overridden for performance only.
244	overridden for performance only.
273	overridden for performance only.
279	found
281	not found
296	overridden for performance only.
302	found
304	not found
330	overridden for performance only.
333	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
343	nothing to do
352	it is faster to sort other before searching in it
361	it is faster to search in other without sorting
382	overridden for performance only.
384	slower
403	overridden for performance only.
406	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
424	it is faster to sort other before searching in it
433	it is faster to search in other without sorting
448	overridden for performance only.
454	swap
469	overridden for performance only.
493	overridden for performance only.
504	swap(i, random)
527	Computes min and max and decides on this basis. In practice the additional overhead is very small compared to the potential gains.
531	never consider options resulting in outrageous memory allocations.
536	determine minimum and maximum.
547	try to figure out which option is fastest.
549	O(N*log(N,base=2)) ; ln(2)=0.6931471805599453
552	O(Max(width,N))

Colt/xml/cern/colt/list/MinMaxNumberList.xml
90	overridden for performance only.
105	cache some vars for speed.
111	now let's go.
119	*bitsPerElem;
136	overflow or underflow in calculating "1+maximum-minimum" happens if signed long representation is too short for doing unsigned calculations e.g. if minimum==LONG.MIN_VALUE, maximum==LONG.MAX_VALUE --> in such cases store all bits of values without any compression.
201	BitVector tmpBitVector = new BitVector(this.bits, this.size*bitsPerElem);
204	part[p] = minVal + tmpBitVector.getLongFromTo(j, j+bitsPerElem-1);
239	this.capacity=initialCapacity;
254	overflow or underflow in calculating "1+maxValue-minValue" happens if signed long representation is too short for doing unsigned calculations e.g. if minValue==LONG.MIN_VALUE, maxValue=LONG.MAX_VALUE --> in such cases store all bits of values without any en/decoding

Colt/xml/cern/colt/list/ObjectArrayList.xml
87	overridden for performance only.
190	key found
192	key not found.
327	delta
345	delta
448	found
454	found
457	not found
514	found
520	found
523	not found
673	nothing to do
700	delta
770	avoid stumbling over my own feet
779	System.out.println("from="+from); System.out.println("to="+to); System.out.println("diff="+diff);
816	delta
856	swap
904	swap(i, random)

Colt/xml/cern/colt/list/ShortArrayList.xml
57	overridden for performance only.
73	overridden for performance only.
113	overridden for performance only.
209	delta
210	overridden for performance only.
231	overridden for performance only.
246	overridden for performance only.
275	overridden for performance only.
281	found
283	not found
298	overridden for performance only.
304	found
306	not found
332	overridden for performance only.
335	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
345	nothing to do
354	it is faster to sort other before searching in it
363	it is faster to search in other without sorting
384	overridden for performance only.
386	slower
405	overridden for performance only.
408	There are two possibilities to do the thing a) use other.indexOf(...) b) sort other, then use other.binarySearch(...)  Let's try to figure out which one is faster. Let M=size, N=other.size, then a) takes O(MN) steps b) takes O(NlogN + MlogN) steps (sorting is O(NlogN) and binarySearch is O(logN))  Hence, if NlogN + MlogN < MN, we use b) otherwise we use a).
426	it is faster to sort other before searching in it
435	it is faster to search in other without sorting
450	overridden for performance only.
456	swap
471	overridden for performance only.
495	overridden for performance only.
506	swap(i, random)
529	Computes min and max and decides on this basis. In practice the additional overhead is very small compared to the potential gains.
533	never consider options resulting in outrageous memory allocations.
538	determine minimum and maximum.
549	try to figure out which option is fastest.
551	O(N*log(N,base=2)) ; ln(2)=0.6931471805599453
554	O(Max(width,N))

Colt/xml/cern/colt/list/SimpleLongArrayList.xml

Colt/xml/cern/colt/map/AbstractDoubleIntMap.xml
30	public static int hashCollisions = 0; // for debug only
284	keys(keyList); values(valueList);  final double[] k = keyList.elements(); final int[] v = valueList.elements(); cern.colt.Swapper swapper = new cern.colt.Swapper() { public void swap(int a, int b) { int t1;	double t2; t1 = v[a]; v[a] = v[b]; v[b] = t1; t2 = k[a]; k[a] = k[b];	k[b] = t2; } };  cern.colt.function.IntComparator comp = new cern.colt.function.IntComparator() { public int compare(int a, int b) { return k[a]<k[b] ? -1 : k[a]==k[b] ? 0 : 1; } }; cern.colt.MultiSorting.sort(0,keyList.size(),comp,swapper);
308	this variant may be quicker cern.colt.map.OpenDoubleIntHashMap.hashCollisions = 0; System.out.println("collisions="+cern.colt.map.OpenDoubleIntHashMap.hashCollisions);
317	System.out.println("collisions="+cern.colt.map.OpenDoubleIntHashMap.hashCollisions);
354	cern.colt.map.OpenDoubleIntHashMap.hashCollisions = 0;
356	System.out.println("collisions="+cern.colt.map.OpenDoubleIntHashMap.hashCollisions);

Colt/xml/cern/colt/map/AbstractIntDoubleMap.xml
30	public static int hashCollisions = 0; // for debug only
384	StringBuffer buf = new StringBuffer();

Colt/xml/cern/colt/map/AbstractIntIntMap.xml
29	public static int hashCollisions = 0; // for debug only
348	theKeys.sort();

Colt/xml/cern/colt/map/AbstractIntObjectMap.xml
30	public static int hashCollisions = 0; // for debug only
323	return v[a]<v[b] ? -1 : v[a]>v[b] ? 1 : (k[a]<k[b] ? -1 : (k[a]==k[b] ? 0 : 1));
323	return v[a]<v[b] ? -1 : v[a]>v[b] ? 1 : (k[a]<k[b] ? -1 : (k[a]==k[b] ? 0 : 1));

Colt/xml/cern/colt/map/AbstractLongObjectMap.xml
30	public static int hashCollisions = 0; // for debug only
323	return v[a]<v[b] ? -1 : v[a]>v[b] ? 1 : (k[a]<k[b] ? -1 : (k[a]==k[b] ? 0 : 1));
323	return v[a]<v[b] ? -1 : v[a]>v[b] ? 1 : (k[a]<k[b] ? -1 : (k[a]==k[b] ? 0 : 1));

Colt/xml/cern/colt/map/AbstractMap.xml
23	public static boolean debug = false; // debug only
70	makes sure there is always at least one FREE slot

Colt/xml/cern/colt/map/Benchmark.xml
32	for (int i=size; --i >=0; ) {
45	map.hashCollisions = 0;
49	map.ensureCapacity(size*3);
78	System.out.println("collisions="+map.hashCollisions);
87	boolean add = args[2].equals("add");
95	using a map int[]    keys   = {0    , 3     , 277+3, 277*2+3, 100000, 9    }; double[] values = {100.0, 1000.0, 277+3, 277*2+3, 70.0  , 71.0 ,}; int[]    keys   = {0,1,3,4,5,6, 271,272,273,274,275,276,277+5, 277+6,277+7};
107	AbstractIntIntMap map = new OpenIntIntHashMap(size*2, 0.2, 0.5);
112	System.out.println(map);
115	System.out.println(map.containsKey(3)); System.out.println(map.get(3));  System.out.println(map.containsKey(4)); System.out.println(map.get(4));  System.out.println(map.containsValue((int)71.0)); System.out.println(map.keyOf((int)71.0));
126	System.out.println(map); System.out.println(map.keys()); System.out.println(map.values());
129	if (map instanceof QuickOpenIntIntHashMap) { System.out.println("totalProbesSaved="+((QuickOpenIntIntHashMap)map).totalProbesSaved); } System.out.println("probes="+map.hashCollisions);  map.hashCollisions = 0;
140	System.out.println(map);
142	System.out.println("probes="+map.hashCollisions);

Colt/xml/cern/colt/map/HashFunctions.xml
40	return (int) Double.doubleToLongBits(value*663608941.737); this avoids excessive hashCollisions in the case values are of the form (1.0, 2.0, 3.0, ...)
50	this avoids excessive hashCollisions in the case values are of the form (1.0, 2.0, 3.0, ...)
60	return value * 0x278DDE6D; // see cern.jet.random.engine.DRand
62	value &= 0x7FFFFFFF;  make it >=0 int hashCode = 0; do hashCode = 31hashCode + value%10; while ((value = 10) > 0);  return 28629151hashCode;  spread even further; h31^5
78	value &= 0x7FFFFFFFFFFFFFFFL;  make it >=0 (0x7FFFFFFFFFFFFFFFL==Long.MAX_VALUE) int hashCode = 0; do hashCode = 31hashCode + (int) (value%10); while ((value = 10) > 0);  return 28629151hashCode;  spread even further; h31^5

Colt/xml/cern/colt/map/OpenDoubleIntHashMap.xml
91	new DoubleArrayList(values).fillFromToWith(0, state.length-1, 0); // delta
94	delta
179	not contained
196	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
197	int decrement = (hash / length) % length;
200	stop if we find a removed or free slot, or if we find the key itself do NOT skip over removed slots (yes, open addressing is like that...)
204	hashCollisions++;
209	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...) assertion: there is at least one FREE slot.
215	hashCollisions++;
223	key already contained at slot i. return a negative number identifying the slot.
227	not already contained, should be inserted at slot i. return a number >= 0 identifying the slot.
242	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
243	int decrement = (hash / length) % length;
246	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...)
250	hashCollisions++;
254	not found
255	found, return index where key is contained
269	not found
281	returns the first key found; there may be more matching keys, however.
349	already contained
357	System.out.print("grow rehashing "); System.out.println("at distinct="+distinct+", capacity="+table.length+" to newCapacity="+newCapacity+" ...");
371	delta
386	if (oldCapacity == newCapacity) return;
402	delta
422	key not contained
425	this.values[i]=0; // delta
430	if (table.length != newCapacity) { System.out.print("shrink rehashing "); System.out.println("at distinct="+distinct+", capacity="+table.length+" to newCapacity="+newCapacity+" ..."); }
453	open addressing needs at least one FREE slot at any time.
459	memory will be exhausted long before this pathological case happens, anyway.
465	delta
467	lowWaterMark will be established upon first expansion. establishing it now (upon instance construction) would immediately make the table shrink upon first put(...). After all the idea of an "initialCapacity" implies violating lowWaterMarks when an object is young. See ensureCapacity(...)
480	* 1.2 because open addressing's performance exponentially degrades beyond that point so that even rehashing the table can take very long

Colt/xml/cern/colt/map/OpenIntDoubleHashMap.xml
28	public static int hashCollisions = 0;
92	specialization for speed
93	x[i] = mult*x[i]
104	the general case x[i] = f(x[i])
138	new DoubleArrayList(values).fillFromToWith(0, state.length-1, 0); // delta
140	if (debug) { for (int i=table.length; --i >= 0; ) { state[i] = FREE; table[i]= Integer.MAX_VALUE; values[i]= Double.NaN; } }
151	delta
236	not contained
253	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
254	int decrement = (hash / length) % length;
257	stop if we find a removed or free slot, or if we find the key itself do NOT skip over removed slots (yes, open addressing is like that...)
261	hashCollisions++;
266	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...) assertion: there is at least one FREE slot.
272	hashCollisions++;
280	key already contained at slot i. return a negative number identifying the slot.
284	not already contained, should be inserted at slot i. return a number >= 0 identifying the slot.
299	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
300	int decrement = (hash / length) % length;
303	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...) assertion: there is at least one FREE slot.
308	hashCollisions++;
312	not found
313	found, return index where key is contained
327	not found
339	returns the first key found; there may be more matching keys, however.
407	already contained
409	if (debug) if (this.state[i] != FULL) throw new InternalError(); if (debug) if (this.table[i] != key) throw new InternalError();
417	System.out.print("grow rehashing "); System.out.println("at distinct="+distinct+", capacity="+table.length+" to newCapacity="+newCapacity+" ...");
431	delta
446	if (oldCapacity == newCapacity) return;
449	if (debug) check();
465	delta
478	if (debug) check();
488	key not contained
490	if (debug) if (this.state[i] == FREE) throw new InternalError(); if (debug) if (this.state[i] == REMOVED) throw new InternalError();
493	this.values[i]=0; // delta
495	if (debug) this.table[i]=Integer.MAX_VALUE; // delta if (debug) this.values[i]=Double.NaN;  delta
501	if (table.length != newCapacity) { System.out.print("shrink rehashing "); System.out.println("at distinct="+distinct+", capacity="+table.length+" to newCapacity="+newCapacity+" ..."); }
524	open addressing needs at least one FREE slot at any time.
530	memory will be exhausted long before this pathological case happens, anyway.
536	delta
538	lowWaterMark will be established upon first expansion. establishing it now (upon instance construction) would immediately make the table shrink upon first put(...). After all the idea of an "initialCapacity" implies violating lowWaterMarks when an object is young. See ensureCapacity(...)
551	* 1.2 because open addressing's performance exponentially degrades beyond that point so that even rehashing the table can take very long

Colt/xml/cern/colt/map/OpenIntIntHashMap.xml
90	new IntArrayList(values).fillFromToWith(0, state.length-1, 0); // delta
93	delta
178	not contained
189	System.out.println("key="+key);
196	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
197	int decrement = (hash / length) % length;
200	stop if we find a removed or free slot, or if we find the key itself do NOT skip over removed slots (yes, open addressing is like that...)
204	hashCollisions++;
209	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...) assertion: there is at least one FREE slot.
215	hashCollisions++;
223	key already contained at slot i. return a negative number identifying the slot.
227	not already contained, should be inserted at slot i. return a number >= 0 identifying the slot.
242	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
243	int decrement = (hash / length) % length;
246	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...)
250	hashCollisions++;
254	not found
255	found, return index where key is contained
269	not found
281	returns the first key found; there may be more matching keys, however.
349	already contained
358	System.out.print("grow rehashing "); System.out.println("at distinct="+distinct+", capacity="+table.length+" to newCapacity="+newCapacity+" ...");
371	delta
386	if (oldCapacity == newCapacity) return;
402	delta
422	key not contained
425	this.values[i]=0; // delta
430	if (table.length != newCapacity) { System.out.print("shrink rehashing "); System.out.println("at distinct="+distinct+", capacity="+table.length+" to newCapacity="+newCapacity+" ..."); }
453	open addressing needs at least one FREE slot at any time.
459	memory will be exhausted long before this pathological case happens, anyway.
465	delta
467	lowWaterMark will be established upon first expansion. establishing it now (upon instance construction) would immediately make the table shrink upon first put(...). After all the idea of an "initialCapacity" implies violating lowWaterMarks when an object is young. See ensureCapacity(...)
480	* 1.2 because open addressing's performance exponentially degrades beyond that point so that even rehashing the table can take very long

Colt/xml/cern/colt/map/OpenIntObjectHashMap.xml
91	delta
94	delta
179	not contained
196	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
197	int decrement = (hash / length) % length;
200	stop if we find a removed or free slot, or if we find the key itself do NOT skip over removed slots (yes, open addressing is like that...)
204	hashCollisions++;
209	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...) assertion: there is at least one FREE slot.
215	hashCollisions++;
223	key already contained at slot i. return a negative number identifying the slot.
227	not already contained, should be inserted at slot i. return a number >= 0 identifying the slot.
242	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
243	int decrement = (hash / length) % length;
246	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...)
250	hashCollisions++;
254	not found
255	found, return index where key is contained
269	not found
281	returns the first key found; there may be more matching keys, however.
349	already contained
367	delta
382	if (oldCapacity == newCapacity) return;
398	delta
418	key not contained
421	delta
443	open addressing needs at least one FREE slot at any time.
449	memory will be exhausted long before this pathological case happens, anyway.
455	delta
457	lowWaterMark will be established upon first expansion. establishing it now (upon instance construction) would immediately make the table shrink upon first put(...). After all the idea of an "initialCapacity" implies violating lowWaterMarks when an object is young. See ensureCapacity(...)
470	* 1.2 because open addressing's performance exponentially degrades beyond that point so that even rehashing the table can take very long

Colt/xml/cern/colt/map/OpenLongObjectHashMap.xml
91	delta
94	delta
179	not contained
196	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
197	int decrement = (hash / length) % length;
200	stop if we find a removed or free slot, or if we find the key itself do NOT skip over removed slots (yes, open addressing is like that...)
204	hashCollisions++;
209	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...) assertion: there is at least one FREE slot.
215	hashCollisions++;
223	key already contained at slot i. return a negative number identifying the slot.
227	not already contained, should be inserted at slot i. return a number >= 0 identifying the slot.
242	double hashing, see http://www.eece.unm.edu/faculty/heileman/hash/node4.html
243	int decrement = (hash / length) % length;
246	stop if we find a free slot, or if we find the key itself. do skip over removed slots (yes, open addressing is like that...)
250	hashCollisions++;
254	not found
255	found, return index where key is contained
269	not found
281	returns the first key found; there may be more matching keys, however.
349	already contained
367	delta
382	if (oldCapacity == newCapacity) return;
398	delta
418	key not contained
421	delta
443	open addressing needs at least one FREE slot at any time.
449	memory will be exhausted long before this pathological case happens, anyway.
455	delta
457	lowWaterMark will be established upon first expansion. establishing it now (upon instance construction) would immediately make the table shrink upon first put(...). After all the idea of an "initialCapacity" implies violating lowWaterMarks when an object is young. See ensureCapacity(...)
470	* 1.2 because open addressing's performance exponentially degrades beyond that point so that even rehashing the table can take very long

Colt/xml/cern/colt/map/PrimeFinder.xml
24	yes, it is prime.
157	int i = new cern.colt.list.IntArrayList(primeCapacities).binarySearch(desiredCapacity); // for debug only TODO
159	desired capacity not found, choose next prime greater than desired capacity
160	remember the semantics of binarySearch...
168	check that primes contain no accidental errors
178	System.out.println(primeCapacity);

Colt/xml/cern/colt/map/QuickOpenIntIntHashMap.xml
26	benchmark only
65	This is open addressing with double hashing, using "Brent's variation". Brent's variation slows insertions a bit down (not much) but reduces probes (collisions) for successful searches, in particular for large load factors. (It does not improve unsuccessful searches.) See D. Knuth, Searching and Sorting, 3rd ed., p.533-545  h1(key) = hash % M h2(key) = decrement = Max(1, hashM % M) M is prime = capacity = table.length probing positions are table[(h1-jh2) % M] for j=0,1,... (M and h2 could also be chosen differently, but h2 is required to be relative prime to M.)
87	System.out.println("insert search for (key,value)=("+key+","+value+") at i="+i+", dec="+decrement);
89	stop if we find a removed or free slot, or if we find the key itself do NOT skip over removed slots (yes, open addressing is like that...) int comp = comparisons;
92	the number of probes
93	the first position to probe
97	hashCollisions++;
100	if (comparisons-comp>0) System.out.println("probed "+(comparisons-comp)+" slots.");
102	key already contained at slot i.
106	not already contained, should be inserted at slot i.
111	System.out.print("grow rehashing "); System.out.println("at distinct="+distinct+", capacity="+table.length+" to newCapacity="+newCapacity+" ...");
118	Brent's variation does a local reorganization to reduce probes. It essentially means: We test whether it is possible to move the association we probed first (table[p0]) out of the way. If this is possible, it will reduce probes for the key to be inserted, since it takes its place; it gets hit earlier. However, future probes for the key that we move out of the way will increase. Thus we only move it out of the way, if we have a net gain, that is, if we save more probes than we loose. For the first probe we safe more than we loose if the number of probes we needed was >=2 (t>=2). If the first probe cannot be moved out of the way, we try the next probe (p1). Now we safe more than we loose if t>=3. We repeat this until we find that we cannot gain or that we can indeed move p(x) out of the way.  Note: Under the great majority of insertions t<=1, so the loop is entered very infrequently.
132	System.out.println("t="+t);
137	pc = (p0-j*decrement) % M, j=1,2,..
140	not a free slot, continue searching for free slot to move to, or break.
144	free or removed slot found, now move...
145	System.out.println("copying p0="+p0+" to pc="+pc+", (key,val)=("+tab[p0]+","+values[p0]+"), saving "+(t-1)+" probes.");
150	prepare to insert: table[p0]=key
151	break loop
155	System.out.println("inserting at i="+i);
162	delta
177	if (oldCapacity == newCapacity) return;
193	delta
196	switch of watermarks
200	int element = oldTable[i]; int index = indexOfInsertion(element); newTable[index]=element; newValues[index]=oldValues[i]; newState[index]=FULL;

Colt/xml/cern/colt/matrix/bench/BenchmarkKernel.xml
38	unreliable timing due to very fast iteration; reading, starting and stopping timer distorts measurement do it again with minimal timer overhead System.out.println("iter="+iter+", minSeconds/iter="+minSeconds/iter);
51	prevent compiler from optimizing away the loop
58	if (dummy != 0) throw new RuntimeException("dummy != 0");
76	"java.vm.specification.version", "java.vm.specification.vendor", "java.vm.specification.name", "java.specification.version", "java.specification.vendor", "java.specification.name"
86	build string matrix
90	retrieve property values
93	prop not available
97	format matrix

Colt/xml/cern/colt/matrix/bench/BenchmarkMatrix.xml
45	parse
81	parse
116	parse
150	parse
192	Mflops
216	Mflops
219	double p = B.columns();
219	double p = B.columns();
232	must be nonsingular for inversion
245	Mflops
247	identity
250	LU.decompose
254	LU.solve
259	mult
232	must be nonsingular for inversion
247	identity
250	LU.decompose
254	LU.solve
259	mult
287	for (int row=rows; --row >= 0; ) { for (int column=columns; --column >= 0; ) { A.set(row,column, B.get(row,column)); } }
287	for (int row=rows; --row >= 0; ) { for (int column=columns; --column >= 0; ) { A.set(row,column, B.get(row,column)); } }
312	for (int row=rows; --row >= 0; ) { for (int column=columns; --column >= 0; ) {
312	for (int row=rows; --row >= 0; ) { for (int column=columns; --column >= 0; ) {
344	Mflops
359	transposed --> faster (memory aware) iteration in correlation algo
365	Mflops
359	transposed --> faster (memory aware) iteration in correlation algo
408	for (int row=rows; --row >= 0; ) { for (int column=columns; --column >= 0; ) {
408	for (int row=rows; --row >= 0; ) { for (int column=columns; --column >= 0; ) {
430	Mflops
457	Mflops
471	do not allocate mem for "D" --> safe some mem
478	Mflops
471	do not allocate mem for "D" --> safe some mem
500	Mflops
503	double p = B.columns();
503	double p = B.columns();
525	for (int row=rows; --row >= 0; ) { for (int column=columns; --column >= 0; ) {
529	a very fast random number generator (this is an inline version of class cern.jet.random.engine.DRand)
532	random uniform in (0.0,1.0)
525	for (int row=rows; --row >= 0; ) { for (int column=columns; --column >= 0; ) {
529	a very fast random number generator (this is an inline version of class cern.jet.random.engine.DRand)
532	random uniform in (0.0,1.0)
562	Mflops
589	Mflops
635	else if (cmd.equals("xxxxxxxxxxxxxxxxx")) return xxxxx(); }
669	overall help
673	help on specific command
689	interactive mode, commands supplied via java class args
693	batch mode, read commands from file
694	parse command file in args[0] one command per line (including parameters) for example: dgemm dense 2 2.0 false true 0.999 10 30 50 100 250 500 1000 dgemm dense 2 2.5 false true 0.999 10 50 dgemm sparse 2 2.5 false true 0.001 500 1000
709	allow // comments
710	allow /* comments */
714	while not end of file
715	execute a command line at a time
716	System.out.println(words);
717	ignore emty lines
721	execute command
730	ok: 2.0 -> 2   wrong: 2.0 -> 2.0 (kills Integer.parseInt())
745	java.io.InputStream input = new java.io.DataInputStream(new java.io.BufferedInputStream(new java.io.FileInputStream(args[1]))); BufferedReader d = new BufferedReader(new InputStreamReader(in));
750	while not end of file
765	int[] sizes = {33,500,1000}; double[] densities = {0.001,0.01,0.99};
768	int[] sizes = {3,5,7,9,30,45,60,61,100,200,300,500,800,1000}; double[] densities = {0.001,0.01,0.1,0.999};
771	int[] sizes = {3}; double[] densities = {0.1};
777	DoubleFactory2D factory = (k==0 ? DoubleFactory2D.dense : k==1 ? DoubleFactory2D.sparse : DoubleFactory2D.rowCompressed); DoubleFactory2D factory = (k==0 ? DoubleFactory2D.dense : k==1 ? DoubleFactory2D.sparse : k==2 ? DoubleFactory2D.rowCompressed : DoubleFactory2D.rowCompressedModified);
785	System.out.println("doing size="+size+"...");
790	System.out.println("   doing density="+density+"...");
793	if (true) { if (!((k==1 && density >= 0.1 && size >=100) || (size>5000 && (k==0 || density>1.0E-4) ))) {
797	--> help gc before allocating new mem
801	help gc
806	skip this parameter combination (not used in practice & would take a lot of memory and time)
810	System.out.println(secs); System.out.println(opsPerSec+" Mops/sec\n");
819	"density";
820	String[] sliceNames = {"dense", "sparse"}; String[] sliceNames = {"dense", "sparse", "rowCompressed"};
824	{F.mean, F.median, F.sum};
830	show transposed
835	title = "Speedup of dense over sparse"; DoubleMatrix2D speedup = cern.colt.matrix.doublealgo.Transform.div(timings.viewSlice(0).copy(),timings.viewSlice(1)); System.out.println("\n"+new cern.colt.matrix.doublealgo.Formatter("%1.3G").toTitleString(speedup,rowNames,colNames,rowAxisName,colAxisName,title,aggr));
861	--> help gc before allocating new mem
865	help gc
873	System.out.println(secs); System.out.println(opsPerSec+" Mops/sec\n");
879	{F.mean, F.median, F.sum};
920	String usage = "Illegal arguments! Arguments to be supplied:\n" +
921	"\te.g. "+cmd+" dense 2 2.0 false 0.999 10 30 50 100 250 500 1000\n"+

Colt/xml/cern/colt/matrix/bench/Double2DProcedure.xml

Colt/xml/cern/colt/matrix/bench/TimerProcedure.xml

Colt/xml/cern/colt/matrix/doublealgo/DoubleMatrix1DComparator.xml

Colt/xml/cern/colt/matrix/doublealgo/DoubleMatrix2DComparator.xml

Colt/xml/cern/colt/matrix/doublealgo/Formatter.xml
289	parameters
300	now the processing
313	may not compile because of packages not included in the distribution htmlStrings[i] = cern.colt.matrixpattern.Converting.toHTML(strings[i]); htmlSourceCodes[i] = cern.colt.matrixpattern.Converting.toHTML(sourceCodes[i]);
320	may not compile because of packages not included in the distribution
322	System.out.println("\nhtmlString("+formats[i]+"):\n"+htmlStrings[i]); System.out.println("\nhtmlSourceCode("+formats[i]+"):\n"+htmlSourceCodes[i]);
336	parameters
338	5, 0.0, -0.0, -Double.NaN, Double.NaN, 0.0/0.0, Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY, Double.MIN_VALUE, Double.MAX_VALUE
340	Double.MIN_VALUE, Double.MAX_VALUE //, Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY
342	String[] formats =         {"%G", "%1.10G", "%f", "%1.2f", "%0.2e"};
346	now the processing
351	String[] javaStrings = new String[size];
400	System.out.println(s);
406	System.out.println(s);
414	parameters
422	double[][] values = { {3,     1,      }, {5.1   ,16.37,  } };
428	String[] columnNames = { "he",   "",  "he", "four" }; String[] rowNames = { "hello", "du", null, "abcdef", "five" };
432	String[] columnNames = { "0.1", "0.3" }; String[] rowNames = { "SunJDK1.2.2 classic", "IBMJDK1.1.8"};
442	parameters
450	double[][] values = { {3,     1,      }, {5.1   ,16.37,  } };
456	String[] columnNames = { "he",   "",  "he", "four" }; String[] rowNames = { "hello", "du", null, "abcdef", "five" };
460	String[] columnNames = { "0.1", "0.3" }; String[] rowNames = { "SunJDK1.2.2 classic", "IBMJDK1.1.8"};
470	parameters
478	double[][] values = { {3,     1,      }, {5.1   ,16.37,  } };
484	String[] columnNames = { "he",   "",  "he", "four" }; String[] rowNames = { "hello", "du", null, "abcdef", "five" }; String[] columnNames = { "0.1", "0.3", "0.5", "0.7" };
489	String[] columnNames = { "0.1", "0.3" }; String[] rowNames = { "SunJDK1.2.2 classic", "IBMJDK1.1.8"};
492	System.out.println(cern.colt.matrix.DoubleFactory2D.dense.make(values)); System.out.println(new Formatter().toSourceCode(cern.colt.matrix.DoubleFactory2D.dense.make(values)));
501	parameters
502	double[][] values = { {3,     0,        -3.4, 0}, {5.1   ,0,        +3.0123456789, 0}, {16.37, 0.0,       2.5, 0}, {-16.3, 0,        -3.012345678E-4, -1}, {1236.3456789, 0,  7, -1.2} };
526	String[] columnNames = { "W", "X", "Y", "Z", "mean", "median", "sum"}; String[] rowNames = { "SunJDK1.2.2 classic", "IBMJDK1.1.8", "SunJDK1.3 Hotspot", "other1", "other2", "mean", "median", "sum" }; hep.aida.bin.BinFunction1D[] aggr = {F.mean, F.median, F.sum};
530	System.out.println(cern.colt.matrix.DoubleFactory2D.dense.make(values)); System.out.println(new Formatter().toSourceCode(cern.colt.matrix.DoubleFactory2D.dense.make(values))); System.out.println(new Formatter().toString(cern.colt.matrix.DoubleFactory2D.dense.make(values))); System.out.println(new Formatter().toTitleString(cern.colt.matrix.DoubleFactory2D.dense.make(values),rowNames,columnNames,rowAxisName,columnAxisName,title));
535	System.out.println(cern.colt.matrixpattern.Converting.toHTML(new Formatter(format).toTitleString(cern.colt.matrix.DoubleFactory2D.dense.make(values),rowNames,columnNames,rowAxisName,columnAxisName,title, aggr)));
676	String oldAlignment = this.alignment; this.alignment = DECIMAL;
679	this.alignment = oldAlignment;
701	hold row aggregations
702	hold column aggregations
704	aggregate an entire column at a time
705	aggregate an entire row at a time
707	turn into strings tmp holds "matrix" plus "colStats" below (needed so that numbers in a columns can be decimal point aligned)
717	copy strings into a large matrix holding the source matrix and all aggregations
724	append a vertical "|" separator plus names of aggregation functions to line holding columnNames
728	add names of aggregation functions
733	append names of aggregation functions to line holding rowNames
736	add names of aggregation functions
741	turn large matrix into string
744	insert a horizontal "----------------------" separation line above the column stats determine insertion position and line width
749	scan "aggr.length+1+v" lines backwards

Colt/xml/cern/colt/matrix/doublealgo/Partitioning.xml
114	this one knows how to swap two row indexes (a,b)
122	compare splitter[a] with columnView[rowIndexes[b]]
132	compare columnView[rowIndexes[a]] with columnView[rowIndexes[b]]
141	compare splitter[a] with splitter[b]
150	generic partitioning does the main work of reordering row indexes
217	row indexes to reorder instead of matrix itself
222	take all columns in the original order
226	view the matrix according to the reordered row indexes
284	double splitter;  int, double --> template type dependent  if (splitFrom>splitTo) return;  nothing to do if (from>to) {  all bins are empty from--; for (int i = splitFrom; i<=splitTo; ) splitIndexes[i++] = from; return; }  Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation. int medianIndex; if (splitFrom==splitTo) {  we don't really have a choice medianIndex = splitFrom; } else {  we do have a choice int m = (from+to)  2;        Small arrays, middle element int len = to-from+1; if (len > SMALL) { int l = from; int n = to; if (len > MEDIUM) {         Big arrays, pseudomedian of 9 int s = len8; l = med3(column, l,     l+s, l+2s); m = med3(column, m-s,   m,   m+s); n = med3(column, n-2s, n-s, n); } m = med3(column, l, m, n);  Mid-size, pseudomedian of 3 }  Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists. medianIndex = cern.colt.Sorting.binarySearchFromTo(splitters,column.getQuick(m),splitFrom,splitTo); if (medianIndex < 0) medianIndex = -medianIndex - 1;  not found if (medianIndex > splitTo) medianIndex = splitTo;  not found, one past the end  } splitter = splitters[medianIndex];  Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to int	splitIndex = xPartitionOld(matrix,column,from,to,splitter); splitIndexes[medianIndex] = splitIndex;  Optimization: Handle special cases to cut down recursions. if (splitIndex < from) {  no element falls into this bin all bins with splitters[i] <= splitter are empty int i = medianIndex-1; while (i>=splitFrom && (!(splitter < splitters[i]))) splitIndexes[i--] = splitIndex; splitFrom = medianIndex+1; } else if (splitIndex >= to) {  all elements fall into this bin all bins with splitters[i] >= splitter are empty int i = medianIndex+1; while (i<=splitTo && (!(splitter > splitters[i]))) splitIndexes[i++] = splitIndex; splitTo = medianIndex-1; }  recursively partition left half if (splitFrom <= medianIndex-1) { xPartitionOld(matrix, column, from,         splitIndex, splitters, splitFrom, medianIndex-1,  splitIndexes); }  recursively partition right half if (medianIndex+1 <= splitTo) { xPartitionOld(matrix, column, splitIndex+1, to,         splitters, medianIndex+1,  splitTo,   splitIndexes); }
374	double element;   int, double --> template type dependent for (int i=from-1; ++i<=to; ) { element = column.getQuick(i); if (element < splitter) { swap x[i] with x[from] matrix.swapRows(i,from); from++; } } return from-1;

Colt/xml/cern/colt/matrix/doublealgo/Sorting.xml
47	already has quicksort implemented
69	NaN equals NaN
70	e.g. NaN > 5
72	e.g. 5 < NaN
103	row indexes to reorder instead of matrix itself
110	swap NaNs to the end
110	swap NaNs to the end
143	row indexes to reorder instead of matrix itself
233	set up index reordering
237	compares two aggregates at a time
242	swap NaNs to the end
246	swaps aggregates and reorders indexes
255	sort indexes and aggregates
258	view the matrix according to the reordered row indexes take all columns in the original order
242	swap NaNs to the end
303	row indexes to reorder instead of matrix itself
311	swap NaNs to the end
318	view the matrix according to the reordered row indexes take all columns in the original order
311	swap NaNs to the end
346	row indexes to reorder instead of matrix itself
349	precompute views for speed
354	return c.compare(matrix.viewRow(a), matrix.viewRow(b));
361	view the matrix according to the reordered row indexes take all columns in the original order
354	return c.compare(matrix.viewRow(a), matrix.viewRow(b));
434	precompute aggregates over rows, as defined by "aggregate"
436	a bit clumsy, because Statistic.aggregate(...) is defined on columns, so we need to transpose views
468	indexes to reorder instead of matrix itself
476	swap NaNs to the end
483	view the matrix according to the reordered slice indexes take all rows and columns in the original order
476	swap NaNs to the end
511	indexes to reorder instead of matrix itself
514	precompute views for speed
519	return c.compare(matrix.viewSlice(a), matrix.viewSlice(b));
526	view the matrix according to the reordered slice indexes take all rows and columns in the original order
519	return c.compare(matrix.viewSlice(a), matrix.viewSlice(b));
582	check whether it is really sorted
584	sorted.assign( new cern.colt.function.DoubleFunction() { public double apply(double arg) { return Math.sin(arg); } } );
606	matrix1.assign(matrix2, new cern.colt.function.DoubleDoubleFunction() { public double apply(double x, double y) { return Math.pow(x,y); } } );
621	for reliable benchmarks, call this method twice: once with small dummy parameters to "warm up" the jitter, then with your real work-load
629	initialize randomly
632	also benchmark copying in its several implementation flavours
643	System.out.println(A);
652	THE QUICK VERSION (takes some 10 secs)
654	A = sort.sort(A,hep.aida.bin.BinFunctions1D.sumLog);
657	check results for correctness WARNING: be sure NOT TO PRINT huge matrices unless you have tons of main memory and time!! so we just show the first 5 rows
679	double a = x.aggregate(F.plus,F.log); double b = y.aggregate(F.plus,F.log);
679	double a = x.aggregate(F.plus,F.log); double b = y.aggregate(F.plus,F.log);
708	DoubleMatrix1DComparator comp = new DoubleMatrix1DComparator() { public int compare(DoubleMatrix1D a, DoubleMatrix1D b) { double as = a.zSum(); double bs = b.zSum(); return as < bs ? -1 : as == bs ? 0 : 1; } };
730	for reliable benchmarks, call this method twice: once with small dummy parameters to "warm up" the jitter, then with your real work-load
737	initialize randomly

Colt/xml/cern/colt/matrix/doublealgo/Statistic.xml
154	copy column into values
244	symmetric
280	symmetric
329	compute distinct values of x
330	copy x into vals
333	since bins are right-open [from,to) we need an additional dummy bin so that the last distinct value does not fall into the overflow bin
338	compute distinct values of y
342	since bins are right-open [from,to) we need an additional dummy bin so that the last distinct value does not fall into the overflow bin
368	compute distinct values of x
369	copy x into vals
372	since bins are right-open [from,to) we need an additional dummy bin so that the last distinct value does not fall into the overflow bin
377	compute distinct values of y
381	since bins are right-open [from,to) we need an additional dummy bin so that the last distinct value does not fall into the overflow bin
386	compute distinct values of z
390	since bins are right-open [from,to) we need an additional dummy bin so that the last distinct value does not fall into the overflow bin
412	System.out.println(correlation(covariance(A))); System.out.println(distance(A,EUCLID));
416	System.out.println(cern.colt.matrixpattern.Converting.toHTML(A.toString())); System.out.println(cern.colt.matrixpattern.Converting.toHTML(covariance(A).toString())); System.out.println(cern.colt.matrixpattern.Converting.toHTML(correlation(covariance(A)).toString())); System.out.println(cern.colt.matrixpattern.Converting.toHTML(distance(A,EUCLID).toString()));
428	double value = 1; DoubleMatrix2D A = factory.make(rows,columns); A.assign(value);
478	cache views
484	work out all permutations
489	symmetric
561	check preconditions and allow for a little tolerance
567	random generator seeded with current time
572	sampler works on long's, not int's
574	sample
648	check preconditions and allow for a little tolerance
658	random generator seeded with current time
664	sampler works on long's, not int's
666	sample rows
673	sample columns
696	check preconditions and allow for a little tolerance
710	random generator seeded with current time
717	sampler works on long's, not int's
719	sample slices
726	sample rows
733	sample columns
754	int rows = matrix.rows(); int columns = matrix.columns(); DoubleMatrix2D distance = new cern.colt.matrix.impl.DenseDoubleMatrix2D(columns,columns);  cache views DoubleMatrix1D[] cols = new DoubleMatrix1D[columns]; for (int i=columns; --i >= 0; ) { cols[i] = matrix.viewColumn(i); }  setup distance function cern.jet.math.Functions F = cern.jet.math.Functions.functions; DoubleDoubleFunction function = null; DoubleDoubleFunction function2 = null; if (norm==EUCLID) function = F.chain(F.square,F.minus); else if (norm==BRAY_CURTIS) function = F.chain(F.abs,F.minus); else if (norm==CANBERRA) function = new DoubleDoubleFunction() { public final double apply(double a, double b) {	return Math.abs(a-b)  Math.abs(a+b);} }; else if (norm==MAXIMUM) function = F.chain(F.abs,F.minus); else if (norm==MANHATTAN) function = F.chain(F.abs,F.minus); else throw new IllegalArgumentException("Unknown norm");  work out all permutations for (int i=columns; --i >= 0; ) { for (int j=i; --j >= 0; ) { double d = 0; if (norm==EUCLID) d = Math.sqrt(cols[i].aggregate(cols[j], F.plus, function)); else if (norm==BRAY_CURTIS) d = cols[i].aggregate(cols[j], F.plus, function)  cols[i].aggregate(cols[j], F.plus, F.plus); else if (norm==CANBERRA) d = cols[i].aggregate(cols[j], F.plus, function); else if (norm==MAXIMUM) d = cols[i].aggregate(cols[j], F.max, function); else if (norm==MANHATTAN) d = cols[i].aggregate(cols[j], F.plus, function); distance.setQuick(i,j,d); distance.setQuick(j,i,d);  symmetric } } return distance;
807	setup distance function final cern.jet.math.Functions F = cern.jet.math.Functions.functions; VectorVectorFunction function; if (norm==EUCLID) function = new VectorVectorFunction() { public final double apply(DoubleMatrix1D a, DoubleMatrix1D b) { return Math.sqrt(a.aggregate(b, F.plus, F.chain(F.square,F.minus))); } }; else if (norm==BRAY_CURTIS) function = new VectorVectorFunction() { public final double apply(DoubleMatrix1D a, DoubleMatrix1D b) { return a.aggregate(b, F.plus, F.chain(F.abs,F.minus))  a.aggregate(b, F.plus, F.plus); } }; else if (norm==CANBERRA) function = new VectorVectorFunction() { DoubleDoubleFunction fun = new DoubleDoubleFunction() { public final double apply(double a, double b) { return Math.abs(a-b)  Math.abs(a+b); } }; public final double apply(DoubleMatrix1D a, DoubleMatrix1D b) { return a.aggregate(b, F.plus, fun); } }; else if (norm==MAXIMUM) function = new VectorVectorFunction() { public final double apply(DoubleMatrix1D a, DoubleMatrix1D b) { return a.aggregate(b, F.max, F.chain(F.abs,F.minus)); } }; else if (norm==MANHATTAN) function = new VectorVectorFunction() { public final double apply(DoubleMatrix1D a, DoubleMatrix1D b) { return a.aggregate(b, F.plus, F.chain(F.abs,F.minus)); } }; else throw new IllegalArgumentException("Unknown norm");  return distance(matrix,function);

Colt/xml/cern/colt/matrix/doublealgo/Stencil.xml
48	odd -> make it even
51	do two steps at a time for efficiency
77	odd -> make it even
80	do two steps at a time for efficiency

Colt/xml/cern/colt/matrix/doublealgo/Transform.xml
63	alias

Colt/xml/cern/colt/matrix/DoubleFactory1D.xml
55	concatenate

Colt/xml/cern/colt/matrix/DoubleFactory2D.xml
94	A factory producing sparse row compressed modified matrices.
97	public static final DoubleFactory2D rowCompressedModified = new DoubleFactory2D();
116	force both to have maximal shared number of rows.
120	concatenate
147	force both to have maximal shared number of columns.
151	concatenate
308	determine maximum column width of each column
323	determine row height of each row
339	shape of result
347	copy
475	determine maximum column width of each column
490	determine row height of each row
506	shape of result parts
514	copy
541	System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(make(parts1).toString()));
543	illegal 2 != 3 DoubleMatrix2D[][] parts2 = { { null,        make(2,2,1), null        }, { make(4,4,2), null,        make(4,3,3) }, { null,        make(2,3,4), null        } }; System.out.println("\n"+make(parts2));
562	System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(make(parts3).toString()));
574	System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(make(parts4).toString()));
601	System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(make(parts1).toString()));
603	illegal 2 != 3 DoubleMatrix2D[][] parts2 = { { null,        make(2,2,1), null        }, { make(4,4,2), null,        make(4,3,3) }, { null,        make(2,3,4), null        } }; System.out.println("\n"+Factory2D.make(parts2));
615	DoubleMatrix2D[][] parts3 = { { identity(3),               null,                        }, { null,                      identity(3).viewColumnFlip() }, { identity(3).viewRowFlip(), null                         } }; System.out.println("\n"+make(parts3)); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(make(parts3).toString()));  DoubleMatrix2D A = ascending(2,2); DoubleMatrix2D B = descending(2,2); DoubleMatrix2D _ = null;  DoubleMatrix2D[][] parts4 = { { A, _, A, _ }, { _, A, _, B } }; System.out.println("\n"+make(parts4)); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(make(parts4).toString()));
750	if (this==rowCompressedModified) return new RCMDoubleMatrix2D(rows,columns);

Colt/xml/cern/colt/matrix/DoubleFactory3D.xml

Colt/xml/cern/colt/matrix/DoubleMatrix1D.xml
227	specialized for speed
228	x[i] = x[i] * y[i]
232	x[i] = 0 for all zeros
233	x[i] * y[i] for all nonZeros
239	x[i] = x[i] + 0*y[i]
242	x[i] = x[i] + y[i]
248	x[i] = x[i] - y[i]
254	the general case x[i] = x[i] + mult*y[i]
261	the general case x[i] = f(x[i],y[i])
619	check for "all"
755	determine minimum length
764	setup
769	skip to start
772	now the sparse dot product
791	double sum = 0; int[] nonZeroIndexElements = nonZeroIndexes.elements(); for (int index=nonZeroIndexes.size(); --index >= 0; ) { int i = nonZeroIndexElements[index]; sum += getQuick(i)  y.getQuick(i); } return sum;

Colt/xml/cern/colt/matrix/DoubleMatrix1DProcedure.xml

Colt/xml/cern/colt/matrix/DoubleMatrix2D.xml
61	last cell already done
105	last cell already done
144	for (int row=rows; --row >= 0;) { for (int column=columns; --column >= 0;) {
197	for (int row=0; row<rows; row++) {
198	for (int column=0; column<columns; column++) {
709	check for "all"
770	take all columns
886	nothing to do
898	in each step six cells can be remembered in registers - they don't need to be reread from slow memory in each step 3 instead of 9 cells need to be read from memory.
941	boolean ignore = (z==null);

Colt/xml/cern/colt/matrix/DoubleMatrix2DProcedure.xml

Colt/xml/cern/colt/matrix/DoubleMatrix3D.xml
62	last cell already done
114	last cell already done
523	int sliceOffset = index(0,0,column);
594	int sliceOffset = index(0,row,0);
633	check for "all"
695	take all rows and columns
725	int sliceOffset = index(slice,0,0);
890	nothing to do
920	in each step 18 cells can be remembered in registers - they don't need to be reread from slow memory in each step 9 instead of 27 cells need to be read from memory.

Colt/xml/cern/colt/matrix/DoubleMatrix3DProcedure.xml

Colt/xml/cern/colt/matrix/impl/AbstractFormatter.xml
104	for efficient String manipulations
127	int[] maxColTrail = new int[columns];
129	for each column, determine alignment parameters
133	int maxTrail = Integer.MIN_VALUE;
138	maxTrail = Math.max(maxTrail, trail(s));
142	maxColTrail[column] = maxTrail;
145	format each row according to alignment parameters StringBuffer total = new StringBuffer();
156	{-1,0,1,2} = {left,centered,right,decimal point}
167	{-1,0,1,2} = {left,centered,right,decimal point}
174	if (alignment==1) {
179	else if (alignment==2) {
185	else if (align==0) {
192	else if (align<0) {
219	parameters Object[][] values = { {3,     0,        -3.4, 0}, {5.1   ,0,        +3.0123456789, 0}, {16.37, 0.0,       2.5, 0}, {-16.3, 0,        -3.012345678E-4, -1}, {1236.3456789, 0,  7, -1.2} }; String[] formats =         {"%G", "%1.10G", "%f", "%1.2f", "%0.2e", null};   now the processing int size = formats.length; ObjectMatrix2D matrix = cern.colt.matrix.ObjectFactory2D.dense.make(values); String[] strings = new String[size]; String[] sourceCodes = new String[size]; String[] htmlStrings = new String[size]; String[] htmlSourceCodes = new String[size];  for (int i=0; i<size; i++) { String format = formats[i]; strings[i] = toString(matrix,format); sourceCodes[i] = toSourceCode(matrix,format);  may not compile because of packages not included in the distribution htmlStrings[i] = cern.colt.matrixpattern.Converting.toHTML(strings[i]); htmlSourceCodes[i] = cern.colt.matrixpattern.Converting.toHTML(sourceCodes[i]); }  System.out.println("original:\n"+toString(matrix));  may not compile because of packages not included in the distribution for (int i=0; i<size; i++) { System.out.println("\nhtmlString("+formats[i]+"):\n"+htmlStrings[i]); System.out.println("\nhtmlSourceCode("+formats[i]+"):\n"+htmlSourceCodes[i]); }  for (int i=0; i<size; i++) { System.out.println("\nstring("+formats[i]+"):\n"+strings[i]); System.out.println("\nsourceCode("+formats[i]+"):\n"+sourceCodes[i]); }
267	parameters Object[] values = { 5, 0.0, -0.0, -Object.NaN, Object.NaN, 0.00.0, Object.NEGATIVE_INFINITY, Object.POSITIVE_INFINITY, Object.MIN_VALUE, Object.MAX_VALUE 5, 0.0, -0.0, -Object.NaN, Object.NaN, 0.00.0, Object.MIN_VALUE, Object.MAX_VALUE , Object.NEGATIVE_INFINITY, Object.POSITIVE_INFINITY Object.MIN_VALUE, Object.MAX_VALUE , Object.NEGATIVE_INFINITY, Object.POSITIVE_INFINITY }; String[] formats =         {"%G", "%1.10G", "%f", "%1.2f", "%0.2e"}; String[] formats =         {"%G", "%1.19G"};   now the processing int size = formats.length; ObjectMatrix1D matrix = new DenseObjectMatrix1D(values);  String[] strings = new String[size]; String[] javaStrings = new String[size];  for (int i=0; i<size; i++) { String format = formats[i]; strings[i] = toString(matrix,format); for (int j=0; j<matrix.size(); j++) { System.out.println(String.valueOf(matrix.get(j))); } }  System.out.println("original:\n"+toString(matrix));  for (int i=0; i<size; i++) { System.out.println("\nstring("+formats[i]+"):\n"+strings[i]); }
304	cern.colt.Timer timer = new cern.colt.Timer(); String s; StringBuffer buf; ObjectMatrix2D matrix = cern.colt.matrix.ObjectFactory2D.dense.make(size,size, value);  timer.reset().start(); buf = new StringBuffer(); for (int i=size; --i >= 0; ) { for (int j=size; --j >= 0; ) { buf.append(matrix.getQuick(i,j)); } } buf = null; timer.stop().display();  timer.reset().start(); corejava.Format format = new corejava.Format("%G"); buf = new StringBuffer(); for (int i=size; --i >= 0; ) { for (int j=size; --j >= 0; ) { buf.append(format.form(matrix.getQuick(i,j))); } } buf = null; timer.stop().display();  timer.reset().start(); s = Formatting.toString(matrix, null); System.out.println(s); s = null; timer.stop().display();  timer.reset().start(); s = Formatting.toString(matrix, "%G"); System.out.println(s); s = null; timer.stop().display();
437	Pre-fabricate 40 static strings with 0,1,2,..,39 blanks, for usage within method blanks(length). Now, we don't need to construct and fill them on demand, and garbage collect them again. All 40 strings share the identical char[] array, only with different offset and length --> somewhat smaller static memory footprint
447	System.out.println(i+"-"+blanksCache[i]+"-");
454	return "Matrix1D of size="+matrix.size(); return matrix.size()+" element matrix"; return "matrix("+matrix.size()+")";

Colt/xml/cern/colt/matrix/impl/AbstractMatrix.xml
23	public static boolean debug = true;

Colt/xml/cern/colt/matrix/impl/AbstractMatrix1D.xml
32	Indicates non-flipped state (flip==1) or flipped state (flip==-1). see _setFlip() for further info.
36	protected int flip;
38	Indicates non-flipped state or flipped state. see _setFlip() for further info.
42	protected int flipMask;
44	this.isNoView implies: offset==0, stride==1
67	return zero + ((rank+flipMask)^flipMask); return zero + rank*flip;  slower

Colt/xml/cern/colt/matrix/impl/AbstractMatrix2D.xml
35	Indicates non-flipped state (flip==1) or flipped state (flip==-1). see _setFlip() for further info.
39	protected int rowFlip, columnFlip;
41	Indicates non-flipped state or flipped state. see _setFlip() for further info.
45	protected int rowFlipMask, columnFlipMask;
69	return columnZero + ((rank+columnFlipMask)^columnFlipMask); return columnZero + rank*columnFlip;  slower
90	return rowZero + ((rank+rowFlipMask)^rowFlipMask); return rowZero + rank*rowFlip;  slower
230	swap;
235	flips stay unaffected

Colt/xml/cern/colt/matrix/impl/AbstractMatrix3D.xml
43	this.isNoView implies: offset==0, sliceStride==rows*slices, rowStride==columns, columnStride==1
289	swap shape
296	swap strides

Colt/xml/cern/colt/matrix/impl/Benchmark.xml
31	certain loops need to be constructed so that the jitter can't optimize them away and we get fantastic numbers. this involves primarly read-loops
44	else if (kind.equals("denseArray")) matrix = new DoubleArrayMatrix2D(size,size);
48	Matrix AJ = new Matrix(columnwise,3); Basic.random(matrix, new cern.jet.random.Uniform(new cern.jet.random.engine.MersenneTwister()));
54	long NN = matrix.size(); int nn = (int) (NNpercentNonZero); long[] nonZeroIndexes = new long[nn]; cern.jet.random.sampling.RandomSampler sampler = new cern.jet.random.sampling.RandomSampler(nn,NN,0,new cern.jet.random.engine.MersenneTwister()); sampler.nextBlock(nn,nonZeroIndexes,0); for (int i=nn; --i >=0; ) { int row = (int) (nonZeroIndexes[i]size); int column = (int) (nonZeroIndexes[i]%size); matrix.set(row,column, value); }
67	timer1.start(); for (int i=0; i<runs; i++) { LUDecomposition LU = new LUDecomposition(matrix); } timer1.stop(); timer1.display();  { Jama.Matrix jmatrix = new Jama.Matrix(matrix.toArray()); timer2.start(); for (int i=0; i<runs; i++) { Jama.LUDecomposition LU = new Jama.LUDecomposition(jmatrix); } timer2.stop(); timer2.display(); }
95	{ timer6.start(); double a = cubicLoop(runs,size); timer6.stop(); timer6.display(); System.out.println(a); }
109	DoubleMatrix2D C = Basic.product(A,B);
130	{ DoubleMatrix2D A = matrix.like().assign(value); DoubleMatrix2D B = matrix.like().assign(value); DoubleMatrix2D C = Basic.product(A,B); timer5.start(); for (int i=0; i<runs; i++) { cern.colt.matrix.Blas.matrixMultiply(A,B,C); } timer5.stop(); timer5.display(); }
145	{ Jama.Matrix A = new Jama.Matrix(size,size); Jama.Matrix B = new Jama.Matrix(size,size); Jama.Matrix C; timer4.start(); for (int i=0; i<runs; i++) { C = A.times(B); } timer4.stop(); timer4.display(); }
187	int size = Integer.parseInt(args[3]); boolean isSparse = args[4].equals("sparse");

Colt/xml/cern/colt/matrix/impl/BenchmarkMatrix2D.xml
174	certain loops need to be constructed so that the jitter can't optimize them away and we get fantastic numbers. this involves primarly read-loops
194	!!! so that the jitter can't optimize away the whole loop
207	!!! so that the jitter can't optimize away the whole loop
216	else if (kind.equals("denseArray")) matrix = new DoubleArrayMatrix2D(rows,columns);
220	if (kind.equals("sparse")) ((SparseDoubleMatrix2D)matrix).elements.hashCollisions = 0;
238	invite gc
247	if (kind.equals("sparse")) { int hashCollisions = ((SparseDoubleMatrix2D)matrix).elements.hashCollisions; System.out.println("hashCollisions="+hashCollisions); System.out.println("--> "+ ((double)hashCollisions  (rowscolumns)) +" hashCollisionselement on average."); }
256	if (kind.equals("sparse")) ((SparseDoubleMatrix2D)matrix).elements.hashCollisions = 0;
270	if (kind.equals("sparse")) System.out.println("hashCollisions="+((SparseDoubleMatrix2D)matrix).elements.hashCollisions);
271	!!! so that the jitter can't optimize away the whole loop
288	if (kind.equals("sparse")) System.out.println("hashCollisions="+((SparseDoubleMatrix2D)view).elements.hashCollisions);
289	!!! so that the jitter can't optimize away the whole loop
293	if (kind.equals("sparse")) ((SparseDoubleMatrix2D)matrix).elements.hashCollisions = 0;
295	initializing
312	invite gc
319	if (kind.equals("sparse")) System.out.println("hashCollisions"+((SparseDoubleMatrix2D)matrix).elements.hashCollisions);
329	certain loops need to be constructed so that the jitter can't optimize them away and we get fantastic numbers. this involves primarly read-loops
340	else if (kind.equals("denseArray")) matrix = new DoubleArrayMatrix2D(rows,columns);
345	if (kind.equals("sparse")) ((SparseDoubleMatrix2D)matrix).elements.hashCollisions = 0;
357	if (kind.equals("sparse")) { int hashCollisions = ((SparseDoubleMatrix2D)matrix).elements.hashCollisions; System.out.println("hashCollisions="+hashCollisions); System.out.println("--> "+ ((double)hashCollisions  (rowscolumns)) +" hashCollisionselement on average."); }
367	if (kind.equals("sparse")) ((SparseDoubleMatrix2D)matrix).elements.hashCollisions = 0;
379	if (kind.equals("sparse")) { int hashCollisions = ((SparseDoubleMatrix2D)matrix).elements.hashCollisions; System.out.println("hashCollisions="+hashCollisions); System.out.println("--> "+ ((double)hashCollisions  (rowscolumns)) +" hashCollisionselement on average."); }
392	certain loops need to be constructed so that the jitter can't optimize them away and we get fantastic numbers. this involves primarly read-loops
410	!!! so that the jitter can't optimize away the whole loop
423	!!! so that the jitter can't optimize away the whole loop
445	invite gc
473	!!! so that the jitter can't optimize away the whole loop
478	initializing for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { matrix.setQuick(row,column,1); } }
497	invite gc
515	certain loops need to be constructed so that the jitter can't optimize them away and we get fantastic numbers. this involves primarly read-loops
533	!!! so that the jitter can't optimize away the whole loop
546	!!! so that the jitter can't optimize away the whole loop
561	matrix[row][column] = value++;
570	invite gc
588	element += matrix[row][column];
600	!!! so that the jitter can't optimize away the whole loop
610	matrix[row][column] = 0;
618	invite gc
637	certain loops need to be constructed so that the jitter can't optimize them away and we get fantastic numbers. this involves primarly read-loops  cern.colt.Timer timer1 = new cern.colt.Timer(); cern.colt.Timer timer2 = new cern.colt.Timer(); cern.colt.Timer timer3 = new cern.colt.Timer(); cern.colt.Timer emptyLoop = new cern.colt.Timer(); cern.colt.Timer emptyLoop2 = new cern.colt.Timer();  emptyLoop.start(); int dummy = 0; for (int i=0; i<runs; i++) { for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { dummy++; } } } emptyLoop.stop(); System.out.println(dummy);  !!! so that the jitter can't optimize away the whole loop  emptyLoop2.start(); dummy = 3; int dummy2 = 0; for (int i=0; i<runs; i++) { for (int value = 0, column=0; column < columns; column++) { for (int row=0; row < rows; row++) { dummy2 += dummy; } } } emptyLoop2.stop(); System.out.println(dummy2);  !!! so that the jitter can't optimize away the whole loop  long before = Runtime.getRuntime().freeMemory(); long size = (((long)rows)columns)runs;  AbstractIntMatrix2D  matrix = null; if (kind.equals("sparse")) matrix = new SparseIntMatrix2D(rows,columns,initialCapacity,minLoadFactor,maxLoadFactor); else if (kind.equals("dense")) matrix = new DenseIntMatrix2D(rows,columns); else if (kind.equals("denseArray")) matrix = new DoubleArrayMatrix2D(rows,columns); else throw new RuntimeException("unknown kind");  System.out.println("\nNow filling..."); if (kind.equals("sparse")) ((SparseIntMatrix2D)matrix).elements.hashCollisions = 0; for (int i=0; i<runs; i++) { matrix.assign(0); matrix.ensureCapacity(initialCapacity); if (kind.equals("sparse")) ((SparseIntMatrix2D)matrix).ensureCapacity(initialCapacity); timer1.start(); int value = 0; for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { matrix.setQuick(row,column,value++); } } timer1.stop(); } timer1.display(); timer1.minus(emptyLoop).display(); System.out.println(size  timer1.minus(emptyLoop).seconds() +" elements  sec");  Runtime.getRuntime().gc();  invite gc try { Thread.currentThread().sleep(1000); } catch (InterruptedException exc) {}; long after = Runtime.getRuntime().freeMemory(); System.out.println("KB needed="+(before-after)  1024); System.out.println("bytes needed per non-zero="+(before-after)  (double)matrix.cardinality()); if (print) { System.out.println(matrix); if (kind.equals("sparse")) System.out.println("map="+((SparseIntMatrix2D)matrix).elements); } if (kind.equals("sparse")) { int hashCollisions = ((SparseIntMatrix2D)matrix).elements.hashCollisions; System.out.println("hashCollisions="+hashCollisions); System.out.println("--> "+ ((double)hashCollisions  (rowscolumns)) +" probeselement on average."); }  System.out.println("\nNow reading..."); if (kind.equals("sparse")) ((SparseIntMatrix2D)matrix).elements.hashCollisions = 0; timer2.start(); int element=0; for (int i=0; i<runs; i++) { for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { element += matrix.getQuick(row,column); } } } timer2.stop().display(); timer2.minus(emptyLoop2).display(); System.out.println(size  timer2.minus(emptyLoop2).seconds() +" elements  sec"); if (print) System.out.println(matrix); if (kind.equals("sparse")) System.out.println("hashCollisions="+((SparseIntMatrix2D)matrix).elements.hashCollisions); System.out.println(element);  !!! so that the jitter can't optimize away the whole loop  System.out.println("\nNow removing..."); before = Runtime.getRuntime().freeMemory(); if (kind.equals("sparse")) ((SparseIntMatrix2D)matrix).elements.hashCollisions = 0; for (int i=0; i<runs; i++) { initializing for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { matrix.setQuick(row,column,1); } } timer3.start(); for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { matrix.setQuick(row,column,0); } } timer3.stop(); } timer3.display(); timer3.minus(emptyLoop).display(); System.out.println(size  timer3.minus(emptyLoop).seconds() +" elements  sec"); Runtime.getRuntime().gc();  invite gc try { Thread.currentThread().sleep(1000); } catch (InterruptedException exc) {}; after = Runtime.getRuntime().freeMemory(); System.out.println("KB needed="+(before-after)1024); System.out.println("KB free="+(after1024));  if (print) System.out.println(matrix); if (kind.equals("sparse")) System.out.println("hashCollisions="+((SparseIntMatrix2D)matrix).elements.hashCollisions);   System.out.println("bye bye.");
772	certain loops need to be constructed so that the jitter can't optimize them away and we get fantastic numbers. this involves primarly read-loops cern.colt.Timer timer1 = new cern.colt.Timer(); cern.colt.Timer timer2 = new cern.colt.Timer(); cern.colt.Timer timer3 = new cern.colt.Timer(); cern.colt.Timer emptyLoop = new cern.colt.Timer(); cern.colt.Timer emptyLoop2 = new cern.colt.Timer();  emptyLoop.start(); int dummy = 0; for (int i=0; i<runs; i++) { for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { dummy++; } } } emptyLoop.stop(); System.out.println(dummy);  !!! so that the jitter can't optimize away the whole loop  emptyLoop2.start(); dummy = 3; int dummy2 = 0; for (int i=0; i<runs; i++) { for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { dummy2 += dummy; } } } emptyLoop2.stop(); System.out.println(dummy2);  !!! so that the jitter can't optimize away the whole loop  long before = Runtime.getRuntime().freeMemory(); long size = (((long)rows)columns)runs;  int[][] matrix = new int[rows][columns];  System.out.println("\nNow filling..."); for (int i=0; i<runs; i++) { timer1.start(); int value = 0; for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { matrix[row][column] = value++; } } timer1.stop(); } timer1.display(); timer1.minus(emptyLoop).display(); System.out.println(size  timer1.minus(emptyLoop).seconds() +" elements  sec");  Runtime.getRuntime().gc();  invite gc try { Thread.currentThread().sleep(1000); } catch (InterruptedException exc) {}; long after = Runtime.getRuntime().freeMemory(); System.out.println("KB needed="+(before-after)  1024); if (print) { DenseIntMatrix2D m = new DenseIntMatrix2D(rows,columns); m.assign(matrix); System.out.println(m); }  System.out.println("\nNow reading..."); timer2.start(); int element=0; for (int i=0; i<runs; i++) { for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { element += matrix[row][column]; } } } timer2.stop().display(); timer2.minus(emptyLoop2).display(); System.out.println(size  timer2.minus(emptyLoop2).seconds() +" elements  sec"); if (print) { DenseIntMatrix2D m = new DenseIntMatrix2D(rows,columns); m.assign(matrix); System.out.println(m); } System.out.println(element);  !!! so that the jitter can't optimize away the whole loop  System.out.println("\nNow removing..."); before = Runtime.getRuntime().freeMemory(); for (int i=0; i<runs; i++) { timer3.start(); for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { matrix[row][column] = 0; } } timer3.stop(); } timer3.display(); timer3.minus(emptyLoop).display(); System.out.println(size  timer3.minus(emptyLoop).seconds() +" elements  sec"); Runtime.getRuntime().gc();  invite gc try { Thread.currentThread().sleep(1000); } catch (InterruptedException exc) {}; after = Runtime.getRuntime().freeMemory(); System.out.println("KB needed="+(before-after)1024); System.out.println("KB free="+(after1024));  if (print) { DenseIntMatrix2D m = new DenseIntMatrix2D(rows,columns); m.assign(matrix); System.out.println(m); }  System.out.println("bye bye.");
890	certain loops need to be constructed so that the jitter can't optimize them away and we get fantastic numbers. this involves primarly read-loops cern.colt.Timer timer1 = new cern.colt.Timer(); cern.colt.Timer timer2 = new cern.colt.Timer(); cern.colt.Timer timer3 = new cern.colt.Timer(); cern.colt.Timer emptyLoop = new cern.colt.Timer(); cern.colt.Timer emptyLoop2 = new cern.colt.Timer();  emptyLoop.start(); int dummy = 0; for (int i=0; i<runs; i++) { for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { dummy++; } } } emptyLoop.stop(); System.out.println(dummy);  !!! so that the jitter can't optimize away the whole loop  int[][] matrix = new int[rows][columns]; emptyLoop2.start(); dummy = 3; int dummy2 = 7; System.out.println(dummy2);  !!! so that the jitter can't optimize away the whole loop for (int i=0; i<runs; i++) { for (int column=0; column < columns; column++) { for (int row=0; row < rows; row++) { dummy2 += dummy; matrix[row][column]; } } } emptyLoop2.stop(); System.out.println(dummy2);  !!! so that the jitter can't optimize away the whole loop  long before = Runtime.getRuntime().freeMemory(); long size = (((long)rows)columns)runs;   System.out.println("\nNow filling..."); for (int i=0; i<runs; i++) { timer1.start(); int value = 0; for (int row=0; row < rows; row++) { int[] r = matrix[row]; for (int column=0; column < columns; column++) { r[column] = value++; matrix[row][column] = value++; } } timer1.stop(); } timer1.display(); timer1.minus(emptyLoop).display(); System.out.println(size  timer1.minus(emptyLoop).seconds() +" elements  sec");  Runtime.getRuntime().gc();  invite gc try { Thread.currentThread().sleep(1000); } catch (InterruptedException exc) {}; long after = Runtime.getRuntime().freeMemory(); System.out.println("KB needed="+(before-after)  1024); if (print) { DenseIntMatrix2D m = new DenseIntMatrix2D(rows,columns); m.assign(matrix); System.out.println(m); }  System.out.println("\nNow reading..."); timer2.start(); int element=0; for (int i=0; i<runs; i++) { for (int row=0; row < rows; row++) { int[] r = matrix[row]; for (int column=0; column < columns; column++) { element += r[column]; element += matrix[row][column]; } } } timer2.stop().display(); timer2.minus(emptyLoop2).display(); System.out.println(size  timer2.minus(emptyLoop2).seconds() +" elements  sec"); if (print) { DenseIntMatrix2D m = new DenseIntMatrix2D(rows,columns); m.assign(matrix); System.out.println(m); } System.out.println(element);  !!! so that the jitter can't optimize away the whole loop  System.out.println("\nNow removing..."); before = Runtime.getRuntime().freeMemory(); for (int i=0; i<runs; i++) { timer3.start(); for (int row=0; row < rows; row++) { int[] r = matrix[row]; for (int column=0; column < columns; column++) { r[column] = 0; matrix[row][column] = 0; } } timer3.stop(); } timer3.display(); timer3.minus(emptyLoop).display(); System.out.println(size  timer3.minus(emptyLoop).seconds() +" elements  sec"); Runtime.getRuntime().gc();  invite gc try { Thread.currentThread().sleep(1000); } catch (InterruptedException exc) {}; after = Runtime.getRuntime().freeMemory(); System.out.println("KB needed="+(before-after)1024); System.out.println("KB free="+(after1024));  if (print) { DenseIntMatrix2D m = new DenseIntMatrix2D(rows,columns); m.assign(matrix); System.out.println(m); }  System.out.println("bye bye.");
1017	int size = Integer.parseInt(args[3]); boolean isSparse = args[4].equals("sparse");

Colt/xml/cern/colt/matrix/impl/DelegateDoubleMatrix1D.xml
21	The elements of the matrix.
25	The row this view is bound to.

Colt/xml/cern/colt/matrix/impl/DenseDoubleMatrix1D.xml
133	specialization for speed
134	x[i] = mult*x[i]
142	the general case x[i] = f(x[i])
160	overriden for performance only
167	quickest
173	should not happen
224	overriden for performance only
239	specialized for speed
240	x[i] = x[i] * y[i]
247	x[i] = x[i] / y[i]
256	x[i] = x[i] + 0*y[i]
259	x[i] = x[i] + y[i]
266	x[i] = x[i] - y[i]
273	the general case x[i] = x[i] + mult*y[i]
281	the general case x[i] = f(x[i],y[i])
316	if (debug) if (index<0 || index>=size) checkIndex(index); return elements[index(index)]; manually inlined:
342	overriden for manual inlining only return _offset(_rank(rank));
381	if (debug) if (index<0 || index>=size) checkIndex(index); elements[index(index)] = value; manually inlined:
391	overriden for performance only
469	unoptimized for (int k = min; --k >= 0;) { sum += elems[i]  yElems[j]; i += s; j += ys; }
478	optimized loop unrolling

Colt/xml/cern/colt/matrix/impl/DenseDoubleMatrix2D.xml
182	specialization for speed
183	x[i] = mult*x[i]
187	the general case
195	the general case x[i] = f(x[i])
216	overriden for performance only
221	nothing to do
224	quickest
231	should not happen
288	overriden for performance only
306	specialized for speed
307	x[i] = x[i] * y[i]
318	x[i] = x[i] / y[i]
331	x[i] = x[i] + 0*y[i]
334	x[i] = x[i] + y[i]
345	x[i] = x[i] - y[i]
356	the general case
357	x[i] = x[i] + mult*y[i]
368	the general case x[i] = f(x[i],y[i])
393	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); return elements[index(row,column)]; manually inlined:
425	return super.index(row,column); manually inlined for speed:
478	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); elements[index(row,column)] = value; manually inlined:
548	1. using only 4-5 out of the 9 cells in "function" is *not* the limiting factor for performance.
550	2. if the "function" would be hardwired into the innermost loop, a speedup of 1.5-2.0 would be seen but then the multi-purpose interface is gone...
561	nothing to do
585	in each step six cells can be remembered in registers - they don't need to be reread from slow memory
586	A02+=A_cs;
587	A12+=A_cs;
588	A22+=A_cs;
591	in each step 3 instead of 9 cells need to be read from memory.
602	move remembered cells
638	not loop unrolled for (int i=indexA, j=indexY, column=columns; --column >= 0; ) { sum += AElems[i]  yElems[j]; i += As; j += ys; }
647	loop unrolled
668	overriden for performance only
671	exploit quick sparse mult A*B = (B' * A')'
680	final RCDoubleMatrix2D transB = new RCDoubleMatrix2D(B.columns,B.rows); B.forEachNonZero( new cern.colt.function.IntIntDoubleFunction() { public double apply(int i, int j, double value) { transB.setQuick(j,i,value); return value; } } );  return transB.zMult(this.viewDice(),C.viewDice()).viewDice();
723	A is blocked to hide memory latency xxxxxxx B xxxxxxx xxxxxxx A xxx     xxxxxxx C xxx     xxxxxxx ---     ------- xxx     xxxxxxx xxx     xxxxxxx ---     ------- xxx     xxxxxxx
737	* 8 == Level 2 cache in bytes
738	if (n+p == 0) return C; int m_optimal = (BLOCK_SIZE - n*p) / (n+p);
760	not unrolled: for (int k = n; --k >= 0; ) { s += getQuick(i,k)  B.getQuick(k,j); s += AElems[kA]  BElems[kB]; kB += rB; kA += cA; }
770	loop unrolled

Colt/xml/cern/colt/matrix/impl/DenseDoubleMatrix3D.xml
158	overriden for performance only
167	should not happen
173	quickest
192	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); return elements[index(slice,row,column)]; manually inlined:
225	return _sliceOffset(_sliceRank(slice)) + _rowOffset(_rowRank(row)) + _columnOffset(_columnRank(column)); manually inlined:
272	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); elements[index(slice,row,column)] = value; manually inlined:
347	overridden for performance only
356	nothing to do
411	in each step 18 cells can be remembered in registers - they don't need to be reread from slow memory in each step 9 instead of 27 cells need to be read from memory.
439	move remembered cells

Colt/xml/cern/colt/matrix/impl/DenseObjectMatrix1D.xml
118	the general case x[i] = f(x[i])
135	overriden for performance only
142	quickest
148	should not happen
199	overriden for performance only
214	the general case x[i] = f(x[i],y[i])
233	if (debug) if (index<0 || index>=size) checkIndex(index); return elements[index(index)]; manually inlined:
259	overriden for manual inlining only return _offset(_rank(rank));
298	if (debug) if (index<0 || index>=size) checkIndex(index); elements[index(index)] = value; manually inlined:
308	overriden for performance only

Colt/xml/cern/colt/matrix/impl/DenseObjectMatrix2D.xml
162	the general case x[i] = f(x[i])
182	overriden for performance only
187	nothing to do
190	quickest
197	should not happen
254	overriden for performance only
272	the general case x[i] = f(x[i],y[i])
296	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); return elements[index(row,column)]; manually inlined:
328	return super.index(row,column); manually inlined for speed:
381	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); elements[index(row,column)] = value; manually inlined:

Colt/xml/cern/colt/matrix/impl/DenseObjectMatrix3D.xml
158	overriden for performance only
167	should not happen
173	quickest
192	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); return elements[index(slice,row,column)]; manually inlined:
225	return _sliceOffset(_sliceRank(slice)) + _rowOffset(_rowRank(row)) + _columnOffset(_columnRank(column)); manually inlined:
272	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); elements[index(slice,row,column)] = value; manually inlined:

Colt/xml/cern/colt/matrix/impl/Former.xml

Colt/xml/cern/colt/matrix/impl/FormerFactory.xml
50	private FormatStringBuffer f = (format!=null ? new corejava.FormatStringBuffer(format) : null);
52	private corejava.PrintfFormat f = (format!=null ? new corejava.PrintfFormat(format) : null);
55	value != value <==> Double.isNaN(value) Work around bug in corejava.Format.form() for inf, -inf, NaN
59	return f.format(value).toString();
61	return f.sprintf(value);
55	value != value <==> Double.isNaN(value) Work around bug in corejava.Format.form() for inf, -inf, NaN
59	return f.format(value).toString();
61	return f.sprintf(value);

Colt/xml/cern/colt/matrix/impl/NormInfinityTest.xml

Colt/xml/cern/colt/matrix/impl/QRTest.xml
22	For COLT
63	For JAMA Matrix amatrix,bmatrix,cmatrix; amatrix = new Matrix(8,2); bmatrix = new Matrix(8,1);  amatrix.set(0,0,1); amatrix.set(1,0,1); amatrix.set(2,0,1); amatrix.set(3,0,1); amatrix.set(4,0,1); amatrix.set(5,0,1); amatrix.set(6,0,1); amatrix.set(7,0,1);  amatrix.set(0,1,80); amatrix.set(1,1,220); amatrix.set(2,1,140); amatrix.set(3,1,120); amatrix.set(4,1,180); amatrix.set(5,1,100); amatrix.set(6,1,200); amatrix.set(7,1,160);  bmatrix.set(0,0,0.6); bmatrix.set(1,0,6.70); bmatrix.set(2,0,5.30); bmatrix.set(3,0,4.00); bmatrix.set(4,0,6.55); bmatrix.set(5,0,2.15); bmatrix.set(6,0,6.60); bmatrix.set(7,0,5.75);  cmatrix = amatrix.solve(bmatrix); amatrix.print(8,5); bmatrix.print(8,5); cmatrix.print(8,5);

Colt/xml/cern/colt/matrix/impl/RCDoubleMatrix2D.xml
120	The elements of the matrix.
126	protected int N;
153	we can hold rows*columns>Integer.MAX_VALUE cells !
166	overriden for performance only
176	x[i] = mult*x[i]
180	the funny definition of isNaN(). This should better not happen.
187	forEachNonZero( new cern.colt.function.IntIntDoubleFunction() { public double apply(int i, int j, double value) { return function.apply(value); } } );
212	nothing to do
214	overriden for performance only
216	return super.assign(source);
227	indexes.clear(); values.clear(); int nonZeros=0; for (int row=0; row<rows; row++) { starts[row]=nonZeros; for (int column=0; column<columns; column++) { double v = source.getQuick(row,column); if (v!=0) { values.add(v); indexes.add(column); nonZeros++; } } } starts[rows]=nonZeros;
247	even quicker
262	x[i] = x[i] + alpha*y[i]
264	nothing to do
276	x[i] = x[i] * y[i]
291	x[i] = x[i] / y[i]
394	found
441	forEachNonZero( new cern.colt.function.IntIntDoubleFunction() { public double apply(int i, int j, double value) { zElements[zi + zStridei] += value  yElements[yi + yStridej]; z.setQuick(row,z.getQuick(row) + value  y.getQuick(column)); System.out.println("["+i+","+j+"]-->"+value); return value; } } );
505	cache views

Colt/xml/cern/colt/matrix/impl/RCMDoubleMatrix2D.xml
22	The elements of the matrix.
60	overriden for performance only
137	found
157	not found

Colt/xml/cern/colt/matrix/impl/SelectedDenseDoubleMatrix1D.xml
107	if (debug) if (index<0 || index>=size) checkIndex(index); return elements[index(index)]; manually inlined:
133	return this.offset + super.index(rank); manually inlined:
172	if (debug) if (index<0 || index>=size) checkIndex(index); elements[index(index)] = value; manually inlined:

Colt/xml/cern/colt/matrix/impl/SelectedDenseDoubleMatrix2D.xml
86	be sure parameters are valid, we do not check...
128	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); return elements[index(row,column)]; manually inlined:
160	return this.offset + super.index(row,column); manually inlined:
199	this method is never called since viewRow() and viewColumn are overridden properly.
213	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); elements[index(row,column)] = value; manually inlined:
235	swap
238	flips stay unaffected

Colt/xml/cern/colt/matrix/impl/SelectedDenseDoubleMatrix3D.xml
72	be sure parameters are valid, we do not check...
131	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); return elements[index(slice,row,column)]; manually inlined:
164	return this.offset + super.index(slice,row,column); manually inlined:
196	this method is never called since viewRow() and viewColumn are overridden properly.
211	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); elements[index(slice,row,column)] = value; manually inlined:
237	swap offsets

Colt/xml/cern/colt/matrix/impl/SelectedDenseObjectMatrix1D.xml
107	if (debug) if (index<0 || index>=size) checkIndex(index); return elements[index(index)]; manually inlined:
133	return this.offset + super.index(rank); manually inlined:
172	if (debug) if (index<0 || index>=size) checkIndex(index); elements[index(index)] = value; manually inlined:

Colt/xml/cern/colt/matrix/impl/SelectedDenseObjectMatrix2D.xml
86	be sure parameters are valid, we do not check...
128	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); return elements[index(row,column)]; manually inlined:
160	return this.offset + super.index(row,column); manually inlined:
199	this method is never called since viewRow() and viewColumn are overridden properly.
213	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); elements[index(row,column)] = value; manually inlined:
235	swap
238	flips stay unaffected

Colt/xml/cern/colt/matrix/impl/SelectedDenseObjectMatrix3D.xml
72	be sure parameters are valid, we do not check...
131	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); return elements[index(slice,row,column)]; manually inlined:
164	return this.offset + super.index(slice,row,column); manually inlined:
196	this method is never called since viewRow() and viewColumn are overridden properly.
211	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); elements[index(slice,row,column)] = value; manually inlined:
237	swap offsets

Colt/xml/cern/colt/matrix/impl/SelectedSparseDoubleMatrix1D.xml
48	The elements of the matrix.
108	if (debug) if (index<0 || index>=size) checkIndex(index); return elements.get(index(index)); manually inlined:
134	return this.offset + super.index(rank); manually inlined:
173	if (debug) if (index<0 || index>=size) checkIndex(index); int i =	index(index); manually inlined:

Colt/xml/cern/colt/matrix/impl/SelectedSparseDoubleMatrix2D.xml
48	The elements of the matrix.
77	be sure parameters are valid, we do not check...
129	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); return elements.get(index(row,column)); manually inlined:
161	return this.offset + super.index(row,column); manually inlined:
200	this method is never called since viewRow() and viewColumn are overridden properly.
214	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); int index =	index(row,column); manually inlined:
241	swap
244	flips stay unaffected

Colt/xml/cern/colt/matrix/impl/SelectedSparseDoubleMatrix3D.xml
73	be sure parameters are valid, we do not check...
132	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); return elements.get(index(slice,row,column)); manually inlined:
165	return this.offset + super.index(slice,row,column); manually inlined:
197	this method is never called since viewRow() and viewColumn are overridden properly.
212	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); int index =	index(slice,row,column); manually inlined:
242	swap offsets

Colt/xml/cern/colt/matrix/impl/SelectedSparseObjectMatrix1D.xml
48	The elements of the matrix.
108	if (debug) if (index<0 || index>=size) checkIndex(index); return elements.get(index(index)); manually inlined:
134	return this.offset + super.index(rank); manually inlined:
173	if (debug) if (index<0 || index>=size) checkIndex(index); int i =	index(index); manually inlined:

Colt/xml/cern/colt/matrix/impl/SelectedSparseObjectMatrix2D.xml
48	The elements of the matrix.
77	be sure parameters are valid, we do not check...
129	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); return elements.get(index(row,column)); manually inlined:
161	return this.offset + super.index(row,column); manually inlined:
200	this method is never called since viewRow() and viewColumn are overridden properly.
214	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); int index =	index(row,column); manually inlined:
241	swap
244	flips stay unaffected

Colt/xml/cern/colt/matrix/impl/SelectedSparseObjectMatrix3D.xml
73	be sure parameters are valid, we do not check...
132	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); return elements.get(index(slice,row,column)); manually inlined:
165	return this.offset + super.index(slice,row,column); manually inlined:
197	this method is never called since viewRow() and viewColumn are overridden properly.
212	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); int index =	index(slice,row,column); manually inlined:
242	swap offsets

Colt/xml/cern/colt/matrix/impl/SparseDoubleMatrix1D.xml
53	The elements of the matrix.
113	overriden for performance only
149	if (debug) if (index<0 || index>=size) checkIndex(index); return this.elements.get(index(index)); manually inlined:
175	overriden for manual inlining only return _offset(_rank(rank));
214	if (debug) if (index<0 || index>=size) checkIndex(index); int i =	index(index); manually inlined:

Colt/xml/cern/colt/matrix/impl/SparseDoubleMatrix2D.xml
75	The elements of the matrix.
144	overriden for performance only
172	x[i] = mult*x[i]
190	overriden for performance only
195	nothing to do
198	quickest
209	x[i] = x[i] + alpha*y[i]
211	nothing to do
223	x[i] = x[i] * y[i]
237	x[i] = x[i] / y[i]
304	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); return this.elements.get(index(row,column)); manually inlined:
336	return super.index(row,column); manually inlined for speed:
389	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); int index =	index(row,column); manually inlined:
394	if (value == 0 || Math.abs(value) < TOLERANCE)
469	System.out.println("["+i+","+j+"]-->"+value);
475	forEachNonZero( new cern.colt.function.IntIntDoubleFunction() { public double apply(int i, int j, double value) { if (transposeA) { int tmp=i; i=j; j=tmp; } zElements[zi + zStridei] += value  yElements[yi + yStridej]; z.setQuick(row,z.getQuick(row) + value  y.getQuick(column)); System.out.println("["+i+","+j+"]-->"+value); return value; } } );
469	System.out.println("["+i+","+j+"]-->"+value);
516	cache views

Colt/xml/cern/colt/matrix/impl/SparseDoubleMatrix3D.xml
79	The elements of the matrix.
156	overriden for performance only
194	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); return elements.get(index(slice,row,column)); manually inlined:
221	return _sliceOffset(_sliceRank(slice)) + _rowOffset(_rowRank(row)) + _columnOffset(_columnRank(column)); manually inlined:
268	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); int index =	index(slice,row,column); manually inlined:

Colt/xml/cern/colt/matrix/impl/SparseObjectMatrix1D.xml
53	The elements of the matrix.
138	if (debug) if (index<0 || index>=size) checkIndex(index); return this.elements.get(index(index)); manually inlined:
164	overriden for manual inlining only return _offset(_rank(rank));
203	if (debug) if (index<0 || index>=size) checkIndex(index); int i =	index(index); manually inlined:

Colt/xml/cern/colt/matrix/impl/SparseObjectMatrix2D.xml
75	The elements of the matrix.
169	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); return this.elements.get(index(row,column)); manually inlined:
201	return super.index(row,column); manually inlined for speed:
254	if (debug) if (column<0 || column>=columns || row<0 || row>=rows) throw new IndexOutOfBoundsException("row:"+row+", column:"+column); int index =	index(row,column); manually inlined:

Colt/xml/cern/colt/matrix/impl/SparseObjectMatrix3D.xml
79	The elements of the matrix.
183	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); return elements.get(index(slice,row,column)); manually inlined:
210	return _sliceOffset(_sliceRank(slice)) + _rowOffset(_rowRank(row)) + _columnOffset(_columnRank(column)); manually inlined:
257	if (debug) if (slice<0 || slice>=slices || row<0 || row>=rows || column<0 || column>=columns) throw new IndexOutOfBoundsException("slice:"+slice+", row:"+row+", column:"+column); int index =	index(slice,row,column); manually inlined:

Colt/xml/cern/colt/matrix/impl/TestMatrix2D.xml
48	make a 4*5 matrix
51	set all cells to 1
53	set [2,1] .. [3,3] to 2
57	modify an independent copy
59	has changed
60	master has not changed
62	[0,3] .. [3,4]
63	a view from a view
77	if (i%1000 == 0) {
79	}
88	if (i%1000 == 0) {
90	}
101	make a 4*5 matrix
102	DoubleMatrix2D master = new DenseDoubleMatrix2D(rows,columns);
104	Basic.ascending(master); master.assign(1);  set all cells to 1
108	master.viewPart(2,0,2,3).assign(2); // set [2,1] .. [3,3] to 2 System.out.println("\n"+master);
127	Basic.ascending(view3);
130	view2.assign(-1);
141	make a 1*1 matrix
186	Sum( x[i]*x[i] )
192	--> 14
194	Sum( x[i]*x[i] )
196	--> 14
198	Sum( x[i]*x[i]*x[i] )
200	--> 36
202	Sum( x[i] )
204	--> 6
206	Min( x[i] )
208	--> 0
210	Max( Sqrt(x[i]) / 2 )
212	--> 0.8660254037844386
214	Number of all cells with 0 <= value <= 2
216	--> 3
218	Number of all cells with 0.8 <= Log2(value) <= 1.2
220	--> 1
222	Product( x[i] )
224	--> 0
226	Product( x[i] ) of all x[i] > limit
232	--> 6
234	Sum( (x[i]+y[i])^2 )
237	--> 56
242	otherMatrix1D.zMult(3);
245	Sum(Math.PI * Math.log(otherMatrix1D[i] / matrix[i]))
247	or, perhaps less error prone and more readable:
258	Sum( x[slice,row,col]*x[slice,row,col] )
260	--> 140
264	Sum( (x[i]+y[i])^2 )
266	--> 560
280	System.out.println(a); System.out.println(b); System.out.println(Basic.product(a,b));
301	DoubleMatrix2D A = Factory2D.make(values);
309	DoubleMatrix2D A = Factory2D.makeIdentity(size,size);
312	DoubleMatrix2D A = Factory2D.makeAscending(size,size).assign(new cern.jet.random.engine.MersenneTwister());
320	timer.reset().start(); for (int run=0; run<runs; run++) { new Jama.Matrix(A.toArray()).inverse(); } timer.stop().display();
327	System.out.println("A="+A); System.out.println("inverse(A)="+inv); System.out.println("formatted inverse(A)="+ new Jama.Matrix(inv.toArray()));
331	-1.0000000000000018, 2.000000000000007, -1.0000000000000047 2.000000000000007, -6.750000000000024, 4.500000000000016 -1.000000000000004, 3.7500000000000133, -2.500000000000009
342	DoubleMatrix2D A = Factory2D.make(values);
350	System.out.println("\n"+A); System.out.println("\n"+B); System.out.println("\n"+C); System.out.println("\n"+Factory2D.diag(A,B,C));
357	System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(B.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(C.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(Factory2D.diagonal(A,B,C).toString()));
368	DoubleMatrix2D A = Factory2D.make(values);
373	A01 = empty;
378	A11 = Factory2D.ascending(s,s).assign(F.plus(A10.getQuick(s-1,s-1)));
380	A12 = Factory2D.ascending(s,s).assign(F.plus(A11.getQuick(s-1,s-1)));
383	A21 = Factory2D.ascending(s,s).assign(F.plus(A20.getQuick(s-1,s-1)));
385	A22 = Factory2D.ascending(s,s).assign(F.plus(A21.getQuick(s-1,s-1)));
388	B.assign(F.plus(A.zSum())); C.assign(F.plus(B.zSum()));
403	System.out.println("\n"+Factory2D.make33(A00,A01,A02,A10,A11,A12,A20,A21,A22));
406	System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A00.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A01.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A02.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A10.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A11.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A12.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A20.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A21.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A22.toString()));  System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(Factory2D.make33(A00,A01,A02,A10,A11,A12,A20,A21,A22).toString()));
444	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
460	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
476	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
493	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
509	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
526	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
542	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
555	DoubleMatrix2D A = Factory2D.make(values);
560	A01 = empty;
565	A11 = Factory2D.ascending(s,s).assign(F.plus(A10.getQuick(s-1,s-1)));
567	A12 = Factory2D.ascending(s,s).assign(F.plus(A11.getQuick(s-1,s-1)));
570	A21 = Factory2D.ascending(s,s).assign(F.plus(A20.getQuick(s-1,s-1)));
572	A22 = Factory2D.ascending(s,s).assign(F.plus(A21.getQuick(s-1,s-1)));
575	B.assign(F.plus(A.zSum())); C.assign(F.plus(B.zSum()));
590	System.out.println("\n"+Factory2D.make33(A00,A01,A02,A10,A11,A12,A20,A21,A22));
593	System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A00.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A01.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A02.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A10.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A11.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A12.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A20.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A21.toString())); System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(A22.toString()));  System.out.println("\n"+cern.colt.matrixpattern.Converting.toHTML(Factory2D.make33(A00,A01,A02,A10,A11,A12,A20,A21,A22).toString()));
610	using a map
651	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
666	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
684	System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
686	Exact eigenvalues from Westlake (1968), p.150 (ei'vectors given too):
713	System.out.println("\n\n"+LinearAlgebra.toVerboseString(A)); System.out.println(new LUDecomposition(A)); System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
742	System.out.println("\n\n"+LinearAlgebra.toVerboseString(A)); System.out.println(new LUDecomposition(A)); System.out.println("\n\nbandwidth="+k+" "+cern.colt.matrixpattern.Converting.toHTML(A.toString()));
766	A.assign(random); A.assign(F.rint);  round
771	I = Factory2D.identity(size);
775	Inv = Factory2D.make(size,size);
792	Inv.assign(I); lu.decompose(LU);
795	lu.solve(Inv);
799	System.out.println("A="+A); System.out.println("LU="+LU); System.out.println("U="+lu.getU()); System.out.println("L="+lu.getL());
835	A.zSum4Neighbors(A,alpha,beta,runs);
837	System.out.println("A="+A);
845	jnt.scimark2.SOR.execute(omega, B, runs);
938	form a matrix with the columns as training vectors
941	copy the patterns into the matrix
995	System.out.println("\n\n"); System.out.println("initializing..."); boolean dense = false; DoubleMatrix2D A; DoubleFactory2D factory; if (dense) factory = Factory2D.dense; else factory = Factory2D.sparse;  double value = 0.5;  DoubleMatrix2D C = Factory2D.dense.sample(size,size,value,1);  A = factory.make(size,size); System.out.print("A assign C... "); cern.colt.Timer timer = new cern.colt.Timer().start(); A.assign(C); timer.stop().display();  System.out.print("A getquick... "); timer.reset().start(); double sum=0; for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { sum+=A.getQuick(i,j); } } timer.stop().display(); System.out.println(sum); System.out.println(A);  System.out.print("sci set3... "); JSci.maths.DoubleSparseMatrix B = new JSci.maths.DoubleSparseMatrix(size); timer.reset().start(); for (int i=size; --i>=0; ) { for (int j=size; --j>=0; ) { for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { B.setElement3(i,j,C.getQuick(i,j)); } } System.out.println(A); timer.stop().display();  System.out.print("sci get3... "); timer.reset().start(); sum=0; for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { sum+=B.getElement3(i,j); } } System.out.println(sum); timer.stop().display();  JSci.maths.DoubleVector vec = new JSci.maths.DoubleVector(size);  System.out.print("sci mult3... "); timer.reset().start(); B.multiply3(vec); timer.stop().display();   System.out.println("done.");
1075	System.out.println(res);
1107	make a 4*5 matrix
1110	set all cells to 1
1112	set [2,1] .. [3,3] to 2
1126	DoubleMatrix2D copyPart = master.copyPart(2,1,2,3); copyPart.assign(3);  modify an independent copy copyPart.set(0,0,4); System.out.println("\n"+copyPart);  has changed System.out.println("\n"+master);  master has not changed  DoubleMatrix2D view1 = master.viewPart(0,3,4,2);  [0,3] .. [3,4] DoubleMatrix2D view2 = view1.viewPart(0,0,4,1);  a view from a view System.out.println("\n"+view1); System.out.println("\n"+view2);
1171	System.out.println("sum = "+sum);
1174	System.out.println("\n\n"); System.out.println("initializing..."); boolean dense = false; DoubleMatrix2D A; DoubleFactory2D factory; if (dense) factory = Factory2D.dense; else factory = Factory2D.sparse;  double value = 0.5;  DoubleMatrix2D C = Factory2D.dense.sample(size,size,value,0.01);  A = factory.make(size,size); cern.colt.Timer timer = new cern.colt.Timer().start(); A.assign(C); timer.stop().display();  timer.reset().start(); double sum=0; for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { sum+=A.getQuick(i,j); } } timer.stop().display(); System.out.println(sum); System.out.println(A);  JSci.maths.DoubleSparseMatrix B = new JSci.maths.DoubleSparseMatrix(size); timer.reset().start(); for (int i=size; --i>=0; ) { for (int j=size; --j>=0; ) { for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { B.setElement2(i,j,C.getQuick(i,j)); } } System.out.println(A); timer.stop().display();  timer.reset().start(); sum=0; for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { sum+=B.getElement2(i,j); } } System.out.println(sum); timer.stop().display();  System.out.println("done.");
1235	int[] values = { 0, 2};
1243	int k = list.binarySearchFromTo(val,0,l); System.out.println(list+", "+val+" --> i="+k+", -i-1="+(-k-1));
1251	System.out.println("\n\n"); System.out.println("initializing..."); boolean dense = false; DoubleMatrix2D A; DoubleFactory2D factory; if (dense) factory = Factory2D.dense; else factory = Factory2D.sparse;  double value = 0.5;  DoubleMatrix2D C = Factory2D.dense.sample(size,size,value,0.01);  A = factory.make(size,size); cern.colt.Timer timer = new cern.colt.Timer().start(); A.assign(C); timer.stop().display();  timer.reset().start(); double sum=0; for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { sum+=A.getQuick(i,j); } } timer.stop().display(); System.out.println(sum); System.out.println(A);  JSci.maths.DoubleSparseMatrix B = new JSci.maths.DoubleSparseMatrix(size); timer.reset().start(); for (int i=size; --i>=0; ) { for (int j=size; --j>=0; ) { for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { B.setElement2(i,j,C.getQuick(i,j)); } } System.out.println(A); timer.stop().display();  timer.reset().start(); sum=0; for (int i=0; i<size; i++) { for (int j=0; j<size; j++ ) { sum+=B.getElement2(i,j); } } System.out.println(sum); timer.stop().display();  System.out.println("done.");
1317	DoubleMatrix1D c = b.viewFlip(); DoubleMatrix1D d = c.viewFlip();
1357	{ { 1, 4, 0 }, { 6, 2, 5 }, { 0, 7, 3 }, { 0, 0, 8 }, { 0, 0, 0 }, { 0, 0, 0 } };
1406	final int DOF = 200; final cern.jet.random.engine.MersenneTwister RANDOM = new cern.jet.random.engine.MersenneTwister(); final Algebra ALGEBRA = new Algebra();  System.out.println("\n\n\nStarting..."); double[][] k = randomMatrix(DOF, RANDOM); DoubleMatrix2D kd = new DenseDoubleMatrix2D(k); Jama.Matrix km = new Jama.Matrix(k);      DoubleMatrix2D coltL = new LUDecomposition(kd).getL(); DoubleMatrix2D coltU = new LUDecomposition(kd).getU(); Jama.Matrix jamaL = new Jama.LUDecomposition(km).getL(); Jama.Matrix jamaU = new Jama.LUDecomposition(km).getU();  System.out.println(coltL.equals(kd.like().assign(jamaL.getArrayCopy()))); System.out.println(coltL.aggregate(F.plus,F.abs)); double s = 0; double[] temp2 = jamaL.getColumnPackedCopy(); for (int i = 0, n = temp2.length; i < n; ++i) s += Math.abs(temp2[i]); System.out.println(s);  System.out.println(coltU.equals(kd.like().assign(jamaU.getArrayCopy()))); System.out.println(coltU.aggregate(F.plus,F.abs)); s = 0; temp2 = jamaU.getColumnPackedCopy(); for (int i = 0, n = temp2.length; i < n; ++i) s += Math.abs(temp2[i]); System.out.println(s);  System.out.println("colt="+new LUDecomposition(kd).toString()); System.out.println("jama="+new Jama.LUDecomposition(km).toString());    Jama.Matrix kmi = km.inverse();  DoubleMatrix2D kdi = Algebra.DEFAULT.inverse(kd); DoubleMatrix2D checkColt = Algebra.DEFAULT.mult(kd, kdi); System.out.println("Colt checksum = " + checkColt.aggregate(F.plus,F.abs) + ", correct = " + DOF);  Jama.Matrix checkJama = kmi.times(km); double checksum = 0; double[] temp = checkJama.getColumnPackedCopy(); for (int i = 0, n = temp.length; i < n; ++i) checksum += Math.abs(temp[i]); System.out.println("Jama checksum = " + checksum + ", correct = " + DOF);  System.out.println("done\n");
1485	make a 4*5 matrix
1488	set all cells to 1
1497	DoubleMatrix2D copyPart = master.copyPart(2,1,2,3); copyPart.assign(3);  modify an independent copy copyPart.set(0,0,4); System.out.println("\n"+copyPart);  has changed System.out.println("\n"+master);  master has not changed  DoubleMatrix2D view1 = master.viewPart(0,3,4,2);  [0,3] .. [3,4] DoubleMatrix2D view2 = view1.viewPart(0,0,4,1);  a view from a view System.out.println("\n"+view1); System.out.println("\n"+view2);
1513	int rows = 4; int columns = 5;  make a 45 matrix DoubleMatrix2D master = new DenseDoubleMatrix2D(rows,columns); System.out.println(master); master.assign(1);  set all cells to 1 DoubleMatrix2D view = master.viewPart(2,0,2,3); view.assign(0); for (int i=0; i<rows; i++) { for (int j=0; j<columns; j++) { boolean hasIndex = view.hasIndex(master.index(i,j)); System.out.println("("+i+","+j+"):"+hasIndex); } } System.out.println("\n"+master); System.out.println("\n"+view); IntArrayList rowList = new IntArrayList(); IntArrayList columnList = new IntArrayList(); DoubleArrayList valueList = new DoubleArrayList(); master.getNonZeros(rowList,columnList,valueList); System.out.println(rowList); System.out.println(columnList); System.out.println(valueList); System.out.println(master.toStringSparse());
1543	make a 4*5 matrix
1545	master.assign(1); // set all cells to 1
1547	set [2,1] .. [3,3] to 2
1562	DoubleMatrix2D copyPart = master.copyPart(2,1,2,3); copyPart.assign(3);  modify an independent copy copyPart.set(0,0,4); System.out.println("\n"+copyPart);  has changed System.out.println("\n"+master);  master has not changed  DoubleMatrix2D view1 = master.viewPart(0,3,4,2);  [0,3] .. [3,4] DoubleMatrix2D view2 = view1.viewPart(0,0,4,1);  a view from a view System.out.println("\n"+view1); System.out.println("\n"+view2);
1579	make a 4*5 matrix
1581	master.assign(1); // set all cells to 1
1583	master.viewPart(2,0,2,3).assign(2); // set [2,1] .. [3,3] to 2 System.out.println("\n"+master);
1603	make a 4*5 matrix
1605	master.assign(1); // set all cells to 1
1607	master.viewPart(2,0,2,3).assign(2); // set [2,1] .. [3,3] to 2 System.out.println("\n"+master);
1625	make a 4*5 matrix
1627	master.assign(1); // set all cells to 1
1629	master.viewPart(2,0,2,3).assign(2); // set [2,1] .. [3,3] to 2 System.out.println("\n"+master);
1644	test case0...
1659	int runs = Integer.parseInt(args[0]); int size = Integer.parseInt(args[1]); double nonZeroFraction = new Double(args[2]).doubleValue(); boolean dense = args[3].equals("dense"); doubleTest23(runs, size, nonZeroFraction, dense); doubleTest24(runs, size, dense);
1670	for (int i = 0; i < dof; ++i) { for (int j = i - 1, n = i + 1; j <= n; ++j) { if (j < dof && j > -1) m[i][j] = RANDOM.nextDouble(); } }
1683	for (int i = 0; i < dof; ++i) for (int j = 0; j < dof; ++j) m[i][j] = RANDOM.nextDouble();
1688	create the matrix object DoubleMatrix2D A = new DenseDoubleMatrix2D(numpnt, 5); DoubleMatrix2D B = new DenseDoubleMatrix2D(numpnt, 1); fillout the matrix for (int i = 0; i < numpnt; i++) { A.setQuick(i, 0, x[i]  y[i]); A.setQuick(i, 1, y[i]  y[i]); A.setQuick(i, 2, x[i]); A.setQuick(i, 3, y[i]); A.setQuick(i, 4, 1.0); B.setQuick(i, 0, -x[i]  x[i]); } System.out.println(A); test the matrix condition SingularValueDecomposition svd = new SingularValueDecomposition(A); System.out.println(svd); Using Algebra to solve the equation Algebra alg = new Algebra(); DoubleMatrix2D resAlg = alg.solve(A.copy(), B.copy()); System.out.println("Using Algebra..."); System.out.println(resAlg); Using QRDecomposition to solve the problem.. QRDecomposition qrd = new QRDecomposition(A); DoubleMatrix2D resQRD = qrd.solve(B); System.out.println("Using QRDecomposition..."); System.out.println(resQRD); Using Jama.QRDecomposition to solve the problem.. Jama.QRDecomposition qrdJama = new Jama.QRDecomposition(new Jama.Matrix(A.toArray())); resQRD = new DenseDoubleMatrix2D(qrdJama.solve(new Jama.Matrix(B.toArray())).getArrayCopy()); System.out.println("Using Jama.QRDecomposition..."); System.out.println(resQRD);
1734	see values below...
1741	DoubleMatrix2D HtH = new DenseDoubleMatrix2D( 5, 5 ); DoubleMatrix2D Hplus = new DenseDoubleMatrix2D( 5, 6 ); LUDecompositionQuick LUD = new LUDecompositionQuick(); H.zMult( H, HtH, 1, 0, true, false ); DoubleMatrix2D res = Algebra.DEFAULT.inverse(HtH).zMult(H,null,1,0,false,true); LUD.decompose( HtH ); first fill Hplus with the transpose of H... for (int i = 0; i < 6; i++ ) { for ( int j = 0; j < 5; j++ ) { Hplus.set( j, i, H.get( i, j ) ); } } LUD.solve( Hplus );  DoubleMatrix2D perm = Algebra.DEFAULT.permute(Hplus, null,LUD.getPivot()); DoubleMatrix2D inv = Algebra.DEFAULT.inverse(HtH);.zMult(H,null,1,0,false,true);
1760	in matlab... Hplus = inv(H' * H) * H'
1763	System.out.println("\nLU="+LUD); System.out.println("\nHplus="+Hplus); System.out.println("\nperm="+perm); System.out.println("\ninv="+inv); System.out.println("\nres="+res);

Colt/xml/cern/colt/matrix/impl/TridiagonalDoubleMatrix2D.xml
25	The non zero elements of the matrix: {lower, diagonal, upper}.
30	The startIndexes and number of non zeros: {lowerStart, diagonalStart, upperStart, values.length, lowerNonZeros, diagonalNonZeros, upperNonZeros}. lowerStart = 0 diagonalStart = lowerStart + lower.length upperStart = diagonalStart + diagonal.length
40	protected double diagonal[]; protected double lower[]; protected double upper[];
44	protected int diagonalNonZeros; protected int lowerNonZeros; protected int upperNonZeros; protected int N;
79	{lower, diagonal, upper}
80	{lowerStart, diagonalStart, upperStart, values.length, lowerNonZeros, diagonalNonZeros, upperNonZeros}
83	diagonal = new double[d]; lower = new double[l]; upper = new double[u];
87	diagonalNonZeros = 0; lowerNonZeros = 0; upperNonZeros = 0;
97	overriden for performance only
102	for (int i=diagonal.length; --i >= 0; ) diagonal[i]=0; for (int i=upper.length; --i >= 0; ) upper[i]=0; for (int i=lower.length; --i >= 0; ) lower[i]=0;
106	diagonalNonZeros = 0; lowerNonZeros = 0; upperNonZeros = 0;
114	x[i] = mult*x[i]
118	the funny definition of isNaN(). This should better not happen.
120	double[] vals = values.elements(); for (int j=values.size(); --j >= 0; ) { vals[j] = alpha; }
150	overriden for performance only
151	nothing to do
155	quickest
181	x[i] = x[i] + alpha*y[i]
183	nothing to do
195	x[i] = x[i] * y[i]
207	x[i] = x[i] / y[i]
225	lower
226	case 1: {   } // diagonal
227	upper
237	one non zero more
269	lower diagonal
280	int k = -1; int q = 0;
283	if (i==j) { k=0; q=i; } if (i==j+1) { k=1; q=j; } if (i==j-1) { k=2; q=i; }
287	if (k<0) return 0; return values[dims[k]+q];
294	if (i==j) return diagonal[i]; if (i==j+1) return lower[j]; if (i==j-1) return upper[i];
298	return 0;
343	lower diagonal
348	one nonZero less
351	one nonZero more
359	int k = -1; int q = 0;
362	if (i==j) { k=0; q=i; } // diagonal if (i==j+1) { k=1; q=j; }  lower diagonal if (i==j-1) { k=2; q=i; }  upper diagonal
366	if (k>0) {
367	int index = dims[k]+q; if (values[index]!=0) {
369	if (isZero) dims[k+NONZERO]--; // one nonZero less
370	} else {
372	if (!isZero) dims[k+NONZERO]++; // one nonZero more
373	} values[index] = value; return;
376	}
378	if (!isZero) throw new IllegalArgumentException("Can't store non-zero value to non-tridiagonal coordinate: row="+row+", column="+column+", value="+value);
385	if (i==j) {
386	if (diagonal[i]!=0) {
387	if (isZero) diagonalNonZeros--;
388	} else {
390	if (!isZero) diagonalNonZeros++;
391	} diagonal[i] = value; return;
394	}
396	if (i==j+1) {
397	if (lower[j]!=0) {
398	if (isZero) lowerNonZeros--;
399	} else {
401	if (!isZero) lowerNonZeros++;
402	} lower[j] = value; return;
405	}
407	if (i==j-1) {
408	if (upper[i]!=0) {
409	if (isZero) upperNonZeros--;
410	} else {
412	if (!isZero) upperNonZeros++;
413	} upper[i] = value; return;
416	}
418	if (!isZero) throw new IllegalArgumentException("Can't store non-zero value to non-tridiagonal coordinate: row="+row+", column="+column+", value="+value);
457	z.setQuick(row,z.getQuick(row) + value * y.getQuick(column)); System.out.println("["+i+","+j+"]-->"+value);
457	z.setQuick(row,z.getQuick(row) + value * y.getQuick(column)); System.out.println("["+i+","+j+"]-->"+value);
488	cache views

Colt/xml/cern/colt/matrix/impl/WrapperDoubleMatrix1D.xml
21	The elements of the matrix.
159	check for "all"
186	should never get called

Colt/xml/cern/colt/matrix/impl/WrapperDoubleMatrix2D.xml
21	The elements of the matrix.
95	should never get called
343	check for "all"
379	should never be called

Colt/xml/cern/colt/matrix/linalg/Algebra.xml
247	fix for bug reported by T.J.Hunt@open.ac.uk
250	if (x.size()==0) return 0; return x.aggregate(cern.jet.math.Functions.plus,cern.jet.math.Functions.abs); double max = 0; for (int i = x.size(); --i >= 0; ) { max = Math.max(max, x.getQuick(i)); } return max;
264	max = Math.max(max, normInfinity(A.viewRow(row)));
293	check validity
297	int i=size; int a; while (--i >= 0 && (a=indexes[i])==i) if (a < 0 || a >= size) throw new IndexOutOfBoundsException("invalid permutation"); if (i<0) return;  nothing to permute
359	check validity
363	int i=size; int a; while (--i >= 0 && (a=indexes[i])==i) if (a < 0 || a >= size) throw new IndexOutOfBoundsException("invalid permutation"); if (i<0) return;  nothing to permute
371	quicker
401	matrix multiplication based on log2 method: A*A*....*A is slow, ((A * A)^2)^2 * ... is faster allocates two auxiliary matrices as work space
404	for parallel matrix mult; if not initialized defaults to sequential blas
411	temporary
412	safes one auxiliary matrix allocation
414	mult(A,A); // safes one auxiliary matrix allocation
418	index of highest bit in state "true"
420	this is the naive version: DoubleMatrix2D B = A.copy(); for (int i=0; i<p-1; i++) { B = mult(B,A); } return B;
429	here comes the optimized version: cern.colt.Timer timer = new cern.colt.Timer().start();
433	while (bit i of p == false)
434	A = mult(A,A); would allocate a lot of temporary memory
435	A.zMult(A,T);
436	swap A with T
443	A = mult(A,A); would allocate a lot of temporary memory
444	A.zMult(A,T);
445	swap A with T
447	if (bit i of p == true)
448	B = mult(B,A); would allocate a lot of temporary memory
449	B.zMult(A,T);
450	swap B with T
453	timer.stop().display();
597	determine properties
631	sort ascending by property name
646	determine padding for nice formatting
653	finally, format properties
814	StringBuffer buf = new StringBuffer(); String unknown = "Illegal operation or error: "; String constructionException = "Illegal operation or error upon construction: ";  buf.append("------------------------------------------------------------------\n"); buf.append("LUDecomposition(A) --> isNonSingular, det, pivot, L, U, inverse(A)\n"); buf.append("------------------------------------------------------------------\n");
945	cern.colt.Timer timer = new cern.colt.Timer().start();
950	timer.stop().display();

Colt/xml/cern/colt/matrix/linalg/Blas.xml

Colt/xml/cern/colt/matrix/linalg/CholeskyDecomposition.xml
48	Initialize. double[][] A = Arg.getArray();
52	L = new double[n][n];
56	precompute and cache some views to avoid regenerating them time and again
60	Main loop.
62	double[] Lrowj = L[j]; DoubleMatrix1D Lrowj = L.viewRow(j);
66	double[] Lrowk = L[k];
68	DoubleMatrix1D Lrowk = L.viewRow(k); double s = 0.0; for (int i = 0; i < k; i++) { s += Lrowk.getQuick(i)Lrowj.getQuick(i); }
111	Copy right hand side.
115	fix by MG Ferreira <mgf@webmail.co.za> old code is in method xxxSolveBuggy()
118	Solve L*Y = B;
127	Solve L'*X = Y;
155	Copy right hand side.
159	precompute and cache some views to avoid regenerating them time and again
163	Solve L*Y = B;
166	X[i,j] -= X[k,j]*L[i,k]
172	Solve L'*X = Y;
176	X[i,j] -= X[k,j]*L[k,i]

Colt/xml/cern/colt/matrix/linalg/Diagonal.xml

Colt/xml/cern/colt/matrix/linalg/EigenvalueDecomposition.xml
65	Complex scalar division.
93	Tridiagonalize.
96	Diagonalize.
110	Reduce to Hessenberg form.
113	Reduce Hessenberg to real Schur form.
177	This is derived from the Algol procedure hqr2, by Martin and Wilkinson, Handbook for Auto. Comp., Vol.ii-Linear Algebra, and the corresponding Fortran subroutine in EISPACK.
182	Initialize
192	Store roots isolated by balanc and compute matrix norm
205	Outer loop over eigenvalue index
210	Look for single small sub-diagonal element
224	Check for convergence One root found
234	Two roots found
245	Real pair
268	Row modification
276	Column modification
284	Accumulate transformations
292	Complex pair
303	No convergence yet
307	Form shift
317	Wilkinson's original ad hoc shift
329	MATLAB's new ad hoc shift
348	(Could check iteration count here.)
350	Look for two consecutive small sub-diagonal elements
382	Double QR step involving rows l:n and columns m:n
417	Row modification
429	Column modification
441	Accumulate transformations
452	(s != 0)
453	k loop
454	check convergence
455	while (n >= low)
457	Backsubstitute to find vectors of upper triangular form
467	Real vector
490	Solve real equations
505	Overflow control
516	Complex vector
521	Last vector component imaginary so matrix is triangular
555	Solve complex equations
578	Overflow control
592	Vectors of isolated roots
602	Back transformation to get eigenvectors of original matrix
618	This is derived from the Algol procedures orthes and ortran, by Martin and Wilkinson, Handbook for Auto. Comp., Vol.ii-Linear Algebra, and the corresponding Fortran subroutines in EISPACK.
628	Scale column.
636	Compute Householder transformation.
650	Apply Householder similarity transformation H = (I-u*u'/h)*H*(I-u*u')/h)
679	Accumulate transformations (Algol's ortran).
697	Double division avoids possible underflow
746	This is derived from the Algol procedures tql2, by Bowdler, Martin, Reinsch, and Wilkinson, Handbook for Auto. Comp., Vol.ii-Linear Algebra, and the corresponding Fortran subroutine in EISPACK.
761	Find small subdiagonal element
772	If m == l, d[l] is an eigenvalue, otherwise, iterate.
778	(Could check iteration count here.)
780	Compute implicit shift
797	Implicit QL transformation.
819	Accumulate transformation.
831	Check for convergence.
839	Sort eigenvalues and corresponding vectors.
865	This is derived from the Algol procedures tred2 by Bowdler, Martin, Reinsch, and Wilkinson, Handbook for Auto. Comp., Vol.ii-Linear Algebra, and the corresponding Fortran subroutine in EISPACK.
876	Householder reduction to tridiagonal form.
880	Scale to avoid under/overflow.
896	Generate Householder vector.
914	Apply similarity transformation to remaining columns.
948	Accumulate transformations.

Colt/xml/cern/colt/matrix/linalg/LUDecomposition.xml
35	zero tolerance for compatibility with Jama

Colt/xml/cern/colt/matrix/linalg/LUDecompositionQuick.xml
89	setup
94	setup pivot vector
101	nothing to do
104	precompute and cache some views to avoid regenerating them time and again
108	sparsity
109	blocked column j
112	Outer loop.
114	blocking (make copy of j-th column to localize references)
117	sparsity detection
118	== heuristic depending on speedup
123	Apply previous transformations.
135	LUcolj is a copy
136	this is the original
138	nasty bug fixed!
149	Find pivot and exchange if necessary.
167	Compute multipliers.
189	setup
194	setup pivot vector
201	nothing to do
204	if (semiBandwidth == 1) { // A is diagonal; nothing to do
205	A is tridiagonal
206	currently no pivoting !
226	avoid rounding errors
288	consider numerical instability
290	if (matrix.getQuick(j,j) == 0) return false;
411	right hand side with pivoting Matrix Xmat = B.getMatrix(piv,0,nx-1);
416	nothing to do
418	Solve L*Y = B(piv,:)
423	B[i] -= B[k]*LU[i][k];
430	Solve U*B = Y;
432	B[k] /= LU[k,k]
437	B[i] -= B[k]*LU[i][k];
461	right hand side with pivoting Matrix Xmat = B.getMatrix(piv,0,nx-1);
464	if (this.work2 == null || this.work2.length < m) this.work2 = new int[m];
467	nothing to do
470	precompute and cache some views to avoid regenerating them time and again
474	transformations
478	sparsity
479	blocked row k
481	Solve L*Y = B(piv,:)
483	blocking (make copy of k-th row to localize references)
486	sparsity detection
487	== heuristic depending on speedup
493	for (int j = 0; j < nx; j++) B[i][j] -= B[k][j]*LU[i][k]; for (int j = 0; j < nx; j++) B.set(i,j, B.get(i,j) - B.get(k,j)*LU.get(i,k));
508	Solve U*B = Y;
510	for (int j = 0; j < nx; j++) B[k][j] /= LU[k][k]; for (int j = 0; j < nx; j++) B.set(k,j, B.get(k,j) / LU.get(k,k));
515	blocking
519	sparsity detection
520	== heuristic depending on speedup
525	Browk.getNonZeros(nonZeroIndexes,null); boolean sparse = nonZeroIndexes.size() < nx/10;
529	for (int j = 0; j < nx; j++) B[i][j] -= B[k][j]*LU[i][k]; for (int j = 0; j < nx; j++) B.set(i,j, B.get(i,j) - B.get(k,j)*LU.get(i,k));
559	Copy right hand side with pivoting
563	if (this.work2 == null || this.work2.length < m) this.work2 = new int[m];
566	Solve L*Y = B(piv,:) --> Y (Y is modified B)
572	B[i][j] -= B[k][j]*LU[i,k];
578	Solve U*X = Y; --> X (X is modified B)
583	B[k][j] /= LU[k][k];
591	B[i][j] -= B[k][j]*LU[i][k];

Colt/xml/cern/colt/matrix/linalg/Matrix2DMatrix2DFunction.xml

Colt/xml/cern/colt/matrix/linalg/Property.xml
193	just to be on the safe side
247	if (!(A.getQuick(i) == value)) return false; if (Math.abs(value - A.getQuick(i)) > epsilon) return false;
275	if (!(getQuick(i) == B.getQuick(i))) return false; if (Math.abs(A.getQuick(i) - B.getQuick(i)) > epsilon) return false;
302	if (!(A.getQuick(row,column) == value)) return false; if (Math.abs(value - A.getQuick(row,column)) > epsilon) return false;
333	if (!(A.getQuick(row,column) == B.getQuick(row,column))) return false; if (Math.abs((A.getQuick(row,column) - B.getQuick(row,column)) > epsilon) return false;
362	if (!(A.getQuick(slice,row,column) == value)) return false; if (Math.abs(value - A.getQuick(slice,row,column)) > epsilon) return false;
396	if (!(A.getQuick(slice,row,column) == B.getQuick(slice,row,column))) return false; if (Math.abs(A.getQuick(slice,row,column) - B.getQuick(slice,row,column)) > epsilon) return false;
442	if (row!=column && A.getQuick(row,column) != 0) return false;
514	if (A.getQuick(row,column) != 0) return false;
531	if (A.getQuick(row,column) != 0) return false;
592	if (A.getQuick(row,column) != -A.getQuick(column,row)) return false;
614	if (A.getQuick(row,column) != 0) return false;
629	if (A.getQuick(i,i) != 0) return false;
644	if (A.getQuick(row,column) != 0) return false;
676	if (A.getQuick(row,column) != 0) return false;
692	if (A.getQuick(i,i) != 1) return false;
708	if (A.getQuick(row,column) != 0) return false;
725	if (A.getQuick(row,column) != 0) return false;
756	if (A.getQuick(j,i) != 0) return k;
913	if (A.getQuick(j,i) != 0) return k+1; if (A.getQuick(i,j) != 0) return k+1;
928	throw new UnsupportedOperationException("Attempted to modify object."); // since JDK1.2
977	determine properties
982	determine properties
987	determine properties
992	determine properties
1086	sort ascending by property name
1101	determine padding for nice formatting
1108	finally, format properties
1142	if (A.getQuick(i,j) != 0) return k;

Colt/xml/cern/colt/matrix/linalg/QRDecomposition.xml
32	private double[][] QR;
56	Initialize.
61	Rdiag = new double[n];
64	precompute and cache some views to avoid regenerating them time and again
72	Main loop.
74	DoubleMatrix1D QRcolk = QR.viewColumn(k).viewPart(k,m-k); Compute 2-norm of k-th column without under/overflow.
77	if (k<m) nrm = QRcolumnsPart[k].aggregate(hypot,F.identity);
79	fixes bug reported by hong.44@osu.edu
85	Form k-th Householder vector.
88	for (int i = k; i < m; i++) { QR[i][k] = nrm; }
96	Apply transformation to remaining columns.
100	fixes bug reported by John Chambers DoubleMatrix1D QRcolj = QR.viewColumn(j).viewPart(k,m-k); double s = QRcolumnsPart[k].zDotProduct(QRcolumns[j]); double s = 0.0; for (int i = k; i < m; i++) { s += QR[i][k]QR[i][j]; }
110	QRcolumnsPart[j].assign(QRcolumns[k], F.plusMult(s));
135	double[][] Q = X.getArray();
194	Copy right hand side
198	Compute Y = transpose(Q)*B
211	Solve R*X = Y;

Colt/xml/cern/colt/matrix/linalg/SeqBlas.xml
141	B.swap(A); not yet implemented

Colt/xml/cern/colt/matrix/linalg/SingularValueDecomposition.xml
54	Derived from LINPACK code. Initialize.
68	Reduce A to bidiagonal form, storing the diagonal elements in s and the super-diagonal elements in e.
76	Compute the transformation for the k-th column and place the k-th diagonal in s[k]. Compute 2-norm of k-th column without under/overflow.
97	Apply the transformation.
109	Place the k-th row of A into e for the subsequent calculation of the row transformation.
116	Place the transformation in U for subsequent back multiplication.
125	Compute the k-th row transformation and place the k-th super-diagonal in e[k]. Compute 2-norm without under/overflow.
144	Apply the transformation.
163	Place the transformation in V for subsequent back multiplication.
173	Set up the final bidiagonal matrix or order p.
187	If required, generate U.
224	If required, generate V.
247	Main iteration loop for the singular values.
255	Here is where a test for too many iterations would go.
257	This section of the program inspects for negligible elements in the s and e arrays.  On completion the variables kase and k are set as follows.
261	kase = 1     if s(p) and e[k-1] are negligible and k<p kase = 2     if s(k) is negligible and k<p kase = 3     if e[k-1] is negligible, k<p, and s(k), ..., s(p) are not negligible (qr step). kase = 4     if e(p-1) is negligible (convergence).
302	Perform the task indicated by kase.
306	Deflate negligible s(p).
331	Split at negligible s(k).
354	Perform one qr step.
358	Calculate the shift.
381	Chase zeros.
422	Convergence.
426	Make the singular values positive.
437	Order the singular values.
497	return new DoubleMatrix2D(U,m,Math.min(m+1,n));

Colt/xml/cern/colt/matrix/linalg/Smp.xml
18	a very efficient and light weight thread pool
30	avoid parallel overhead
48	System.out.print(".");
53	run tasks and wait for completion
48	System.out.print(".");
65	determine how to split and parallelize best into blocks if more B.columns than tasks --> split B.columns, as follows:  xx|xx|xxx B xx|xx|xxx xx|xx|xxx A xxx     xx|xx|xxx C xxx		xx|xx|xxx xxx		xx|xx|xxx xxx		xx|xx|xxx xxx		xx|xx|xxx  if less B.columns than tasks --> split A.rows, as follows:  xxxxxxx B xxxxxxx xxxxxxx A xxx     xxxxxxx C xxx     xxxxxxx ---     ------- xxx     xxxxxxx xxx     xxxxxxx ---     ------- xxx     xxxxxxx
94	long flops = 2L*A.rows()*A.columns()*A.columns();
95	each thread should process at least 30000 flops
97	boolean splitHoriz = (A.columns() >= noOfTasks);
101	parallelization doesn't pay off (too much start up overhead)
105	set up concurrent tasks
110	last span may be a bit larger
113	split B along columns into blocks
116	split A along rows into blocks
131	determine how to split and parallelize best into blocks if more B.columns than tasks --> split B.columns, as follows:  xx|xx|xxx B xx|xx|xxx xx|xx|xxx A xxx     xx|xx|xxx C xxx		xx|xx|xxx xxx		xx|xx|xxx xxx		xx|xx|xxx xxx		xx|xx|xxx  if less B.columns than tasks --> split A.rows, as follows:  xxxxxxx B xxxxxxx xxxxxxx A xxx     xxxxxxx C xxx     xxxxxxx ---     ------- xxx     xxxxxxx xxx     xxxxxxx ---     ------- xxx     xxxxxxx
160	long flops = 2L*A.rows()*A.columns()*A.columns();
161	each thread should process at least 30000 flops
163	boolean splitHoriz = (A.columns() >= noOfTasks);
167	parallelization doesn't pay off (too much start up overhead)
171	set up concurrent tasks
176	last span may be a bit larger
180	split B along columns into blocks
184	split A along rows into blocks

Colt/xml/cern/colt/matrix/linalg/SmpBlas.xml
67	blocks are operated on in parallel; for each block this seq algo is used.
81	Smp.smp = new Smp(maxThreads);
91	no need to change anything?
141	determine how to split and parallelize best into blocks if more B.columns than tasks --> split B.columns, as follows:  xx|xx|xxx B xx|xx|xxx xx|xx|xxx A xxx     xx|xx|xxx C xxx		xx|xx|xxx xxx		xx|xx|xxx xxx		xx|xx|xxx xxx		xx|xx|xxx  if less B.columns than tasks --> split A.rows, as follows:  xxxxxxx B xxxxxxx xxxxxxx A xxx     xxxxxxx C xxx     xxxxxxx ---     ------- xxx     xxxxxxx xxx     xxxxxxx ---     ------- xxx     xxxxxxx
190	each thread should process at least 30000 flops
195	parallelization doesn't pay off (too much start up overhead)
200	set up concurrent tasks
205	last span may be a bit larger
209	split B along columns into blocks
215	split A along rows into blocks
224	System.out.println("Hello "+offset);
229	run tasks and wait for completion
224	System.out.println("Hello "+offset);
241	split A, as follows:  x x x x A xxx     x y xxx     x ---     - xxx     x xxx     x ---     - xxx     x
264	each thread should process at least 30000 flops
268	parallelization doesn't pay off (too much start up overhead)
273	set up concurrent tasks
278	last span may be a bit larger
280	split A along rows into blocks
287	System.out.println("Hello "+offset);
292	run tasks and wait for completion
287	System.out.println("Hello "+offset);
339	blocks = this.smp.splitStridedNN(A, B, NN_THRESHOLD, A.rows()*A.columns());
343	too small --> sequential
348	parallel
356	blocks = this.smp.splitStridedNN(A, NN_THRESHOLD, A.rows()*A.columns());
360	too small -> sequential
365	parallel

Colt/xml/cern/colt/matrix/objectalgo/Formatter.xml
170	determine how many rows and columns are needed
181	make larger matrix holding original matrix and naming strings
184	insert original matrix into larger matrix
187	insert column axis name in leading row
190	insert row axis name in leading column
196	insert row names in next leading columns
199	insert vertical "---------" separator line in next leading column
202	convert the large matrix to a string
208	insert horizontal "--------------" separator line
219	insert line for column axis name
229	insert title

Colt/xml/cern/colt/matrix/objectalgo/ObjectMatrix1DComparator.xml

Colt/xml/cern/colt/matrix/objectalgo/ObjectMatrix2DComparator.xml

Colt/xml/cern/colt/matrix/objectalgo/Partitioning.xml
114	this one knows how to swap two row indexes (a,b)
122	compare splitter[a] with columnView[rowIndexes[b]]
133	compare columnView[rowIndexes[a]] with columnView[rowIndexes[b]]
143	compare splitter[a] with splitter[b]
153	generic partitioning does the main work of reordering row indexes
220	row indexes to reorder instead of matrix itself
225	take all columns in the original order
229	view the matrix according to the reordered row indexes
287	Object splitter;  int, Object --> template type dependent  if (splitFrom>splitTo) return;  nothing to do if (from>to) {  all bins are empty from--; for (int i = splitFrom; i<=splitTo; ) splitIndexes[i++] = from; return; }  Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation. int medianIndex; if (splitFrom==splitTo) {  we don't really have a choice medianIndex = splitFrom; } else {  we do have a choice int m = (from+to)  2;        Small arrays, middle element int len = to-from+1; if (len > SMALL) { int l = from; int n = to; if (len > MEDIUM) {         Big arrays, pseudomedian of 9 int s = len8; l = med3(column, l,     l+s, l+2s); m = med3(column, m-s,   m,   m+s); n = med3(column, n-2s, n-s, n); } m = med3(column, l, m, n);  Mid-size, pseudomedian of 3 }  Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists. medianIndex = cern.colt.Sorting.binarySearchFromTo(splitters,column.getQuick(m),splitFrom,splitTo); if (medianIndex < 0) medianIndex = -medianIndex - 1;  not found if (medianIndex > splitTo) medianIndex = splitTo;  not found, one past the end  } splitter = splitters[medianIndex];  Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to int	splitIndex = xPartitionOld(matrix,column,from,to,splitter); splitIndexes[medianIndex] = splitIndex;  Optimization: Handle special cases to cut down recursions. if (splitIndex < from) {  no element falls into this bin all bins with splitters[i] <= splitter are empty int i = medianIndex-1; while (i>=splitFrom && (!(splitter < splitters[i]))) splitIndexes[i--] = splitIndex; splitFrom = medianIndex+1; } else if (splitIndex >= to) {  all elements fall into this bin all bins with splitters[i] >= splitter are empty int i = medianIndex+1; while (i<=splitTo && (!(splitter > splitters[i]))) splitIndexes[i++] = splitIndex; splitTo = medianIndex-1; }  recursively partition left half if (splitFrom <= medianIndex-1) { xPartitionOld(matrix, column, from,         splitIndex, splitters, splitFrom, medianIndex-1,  splitIndexes); }  recursively partition right half if (medianIndex+1 <= splitTo) { xPartitionOld(matrix, column, splitIndex+1, to,         splitters, medianIndex+1,  splitTo,   splitIndexes); }
377	Object element;   int, Object --> template type dependent for (int i=from-1; ++i<=to; ) { element = column.getQuick(i); if (element < splitter) { swap x[i] with x[from] matrix.swapRows(i,from); from++; } } return from-1;

Colt/xml/cern/colt/matrix/objectalgo/Sorting.xml
44	already has quicksort implemented
90	row indexes to reorder instead of matrix itself
130	row indexes to reorder instead of matrix itself
184	row indexes to reorder instead of matrix itself
199	view the matrix according to the reordered row indexes take all columns in the original order
227	row indexes to reorder instead of matrix itself
230	precompute views for speed
235	return c.compare(matrix.viewRow(a), matrix.viewRow(b));
242	view the matrix according to the reordered row indexes take all columns in the original order
235	return c.compare(matrix.viewRow(a), matrix.viewRow(b));
271	indexes to reorder instead of matrix itself
286	view the matrix according to the reordered slice indexes take all rows and columns in the original order
314	indexes to reorder instead of matrix itself
317	precompute views for speed
322	return c.compare(matrix.viewSlice(a), matrix.viewSlice(b));
329	view the matrix according to the reordered slice indexes take all rows and columns in the original order
322	return c.compare(matrix.viewSlice(a), matrix.viewSlice(b));

Colt/xml/cern/colt/matrix/ObjectFactory1D.xml
53	concatenate

Colt/xml/cern/colt/matrix/ObjectFactory2D.xml
92	force both to have maximal shared number of rows.
96	concatenate
123	force both to have maximal shared number of columns.
127	concatenate
271	determine maximum column width of each column
286	determine row height of each row
302	shape of result
310	copy
438	determine maximum column width of each column
453	determine row height of each row
469	shape of result parts
477	copy

Colt/xml/cern/colt/matrix/ObjectFactory3D.xml

Colt/xml/cern/colt/matrix/ObjectMatrix1D.xml
222	delta
240	delta
512	check for "all"

Colt/xml/cern/colt/matrix/ObjectMatrix1DProcedure.xml

Colt/xml/cern/colt/matrix/ObjectMatrix2D.xml
59	last cell already done
103	last cell already done
266	delta
284	delta
704	check for "all"
765	take all columns

Colt/xml/cern/colt/matrix/ObjectMatrix2DProcedure.xml

Colt/xml/cern/colt/matrix/ObjectMatrix3D.xml
62	last cell already done
114	last cell already done
294	delta
312	delta
551	int sliceOffset = index(0,0,column);
622	int sliceOffset = index(0,row,0);
661	check for "all"
723	take all rows and columns
753	int sliceOffset = index(slice,0,0);

Colt/xml/cern/colt/matrix/ObjectMatrix3DProcedure.xml

Colt/xml/cern/colt/Partitioning.xml
46	benchmark only
76	key found
78	key not found.
85	int, double --> template type dependent
87	nothing to do
88	all bins are empty
94	Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation.
98	we don't really have a choice
101	we do have a choice
102	Small arrays, middle element
107	Big arrays, pseudomedian of 9
113	Mid-size, pseudomedian of 3
116	Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists.
118	not found
119	not found, one past the end
124	Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to
129	Optimization: Handle special cases to cut down recursions.
130	no element falls into this bin
131	all bins with splitters[i] <= splitter are empty
136	all elements fall into this bin
137	all bins with splitters[i] >= splitter are empty
143	recursively partition left half
148	recursively partition right half
158	int, double --> template type dependent
162	swap x[i] with x[from]
192	int, double --> template type dependent
194	nothing to do
195	all bins are empty
201	Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation.
205	we don't really have a choice
208	we do have a choice
209	Small arrays, middle element
214	Big arrays, pseudomedian of 9
220	Mid-size, pseudomedian of 3
223	Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists.
225	not found
226	not found, one past the end
231	Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to
236	Optimization: Handle special cases to cut down recursions.
237	no element falls into this bin
238	all bins with splitters[i] <= splitter are empty
243	all elements fall into this bin
244	all bins with splitters[i] >= splitter are empty
250	recursively partition left half
255	recursively partition right half
270	int, double --> template type dependent
274	swap x[i] with x[from]
343	int, double --> template type dependent
345	nothing to do
346	all bins are empty
352	Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation.
356	we don't really have a choice
359	we do have a choice
360	Small arrays, middle element
365	Big arrays, pseudomedian of 9
371	Mid-size, pseudomedian of 3
374	Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists.
376	not found
377	not found, one past the end
382	Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to
388	Optimization: Handle special cases to cut down recursions.
389	no element falls into this bin
390	all bins with splitters[i] <= splitter are empty
395	all elements fall into this bin
396	all bins with splitters[i] >= splitter are empty
403	recursively partition left half
408	recursively partition right half
420	swap x[i] with x[from]
470	int, double --> template type dependent
472	nothing to do
473	all bins are empty
479	Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation.
483	we don't really have a choice
486	we do have a choice
487	Small arrays, middle element
492	Big arrays, pseudomedian of 9
498	Mid-size, pseudomedian of 3
501	Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists.
503	not found
504	not found, one past the end
509	Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to
514	Optimization: Handle special cases to cut down recursions.
515	no element falls into this bin
516	all bins with splitters[i] <= splitter are empty
521	all elements fall into this bin
522	all bins with splitters[i] >= splitter are empty
528	recursively partition left half
533	recursively partition right half
543	int, double --> template type dependent
547	swap x[i] with x[from]
627	int, double --> template type dependent
629	nothing to do
630	all bins are empty
636	Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation.
640	we don't really have a choice
643	we do have a choice
644	Small arrays, middle element
649	Big arrays, pseudomedian of 9
655	Mid-size, pseudomedian of 3
658	Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists.
661	int key = list[m];
662	if (splitTo-splitFrom+1 < 5) {  on short lists linear search is quicker int i=splitFrom-1; while (++i <= splitTo && list[i] < key); if (i > splitTo || list[i] > key) i = -i-1;  not found medianIndex = i; }
670	else {
671	int low = splitFrom; int high = splitTo; int comparison;  int mid=0; while (low <= high) { mid = (low + high)  2; comparison = splitters[mid]-key; if (comparison < 0) low = mid + 1; else if (comparison > 0) high = mid - 1; else break; return mid;  key found } medianIndex = mid; if (low > high) medianIndex = -(medianIndex + 1);   key not found. }
691	not found
692	not found, one past the end
697	System.out.println("medianIndex="+medianIndex); Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to Could simply call:
702	but for speed the code is manually inlined.
703	steps += to-from+1; int head = from; for (int i=from-1; ++i<=to; ) {  swap all elements < splitter to front element = list[i]; if (element < splitter) { list[i] = list[head]; list[head++] = element; swappedElements++; } } int splitIndex = head-1;
723	System.out.println("splitIndex="+splitIndex);
726	if (splitFrom == splitTo) return; // done
728	Optimization: Handle special cases to cut down recursions.
729	no element falls into this bin
730	all bins with splitters[i] <= splitter are empty
735	all elements fall into this bin
736	all bins with splitters[i] >= splitter are empty
742	recursively partition left half
744	System.out.println("1.recursive: from="+from+", to="+splitIndex+", splitFrom="+splitFrom+", splitTo="+(medianIndex-1));
748	recursively partition right half
750	System.out.println("2.recursive: from="+(splitIndex+1)+", to="+to+", splitFrom="+(medianIndex+1)+", splitTo="+splitTo);
753	System.out.println("BACK TRACKING\n\n");
802	System.out.println(); if (from<=to) { System.out.println("SORT WORKING: from="+from+", to="+to+", splitter="+splitter); } else { System.out.println("SORT WORKING: NOTHING TO DO."); }
816	returns index of last element < splitter
819	for (int i=from-1; ++i<=to; ) { if (list[i] < splitter) { int element = list[i]; list[i] = list[from]; list[from++] = element; } }
836	swap x[i] with x[from]
839	swappedElements++;
842	if (from<=to) System.out.println("Swapped "+(head-from)+" elements");
845	JAL: int first = from; int last = to+1; --first; while (true) { while (++first < last && list[first] < splitter); while (first < --last && !(list[last] < splitter)); if (first >= last) return first-1; int tmp = list[first]; list[first] = list[last]; list[last] = tmp; }
862	System.out.println("splitter="+splitter); System.out.println("before="+new IntArrayList(list)); int head = from; int trail = to; int element; while (head<=trail) { head--; while (++head < trail && list[head] < splitter);  trail++; while (--trail > head && list[trail] >= splitter);  if (head != trail) { element = list[head]; list[head] = list[trail]; list[trail] = element; } head++; trail--; System.out.println("after ="+new IntArrayList(list)+", head="+head); }
887	System.out.println("splitter="+splitter); System.out.println("before="+new IntArrayList(list)); to++; int head = from; int element; int oldHead; while (--to >= from) { element = list[to]; if (element < splitter) { from--; while (++from < to && list[from] < splitter); if (head != to) { list[to] = list[from]; list[from++] = element; oldHead = list[head]; list[head] = element; list[i] = oldHead;  head++; } head++; } System.out.println("after ="+new IntArrayList(list)+", head="+head); }
914	int i=from-1; int head = from; int trail = to; while (++i <= trail) { int element = list[i]; if (element < splitter) { if (head == i) head++; else { swap list[i] with list[from] int oldHead = list[head]; int oldTrail = list[trail]; list[head++] = element; list[i--] = oldTrail; list[trail--] = oldHead; } } System.out.println(new IntArrayList(list));  }
938	return head-1;
945	int, double --> template type dependent
947	nothing to do
948	all bins are empty
954	Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation.
958	we don't really have a choice
961	we do have a choice
962	Small arrays, middle element
967	Big arrays, pseudomedian of 9
973	Mid-size, pseudomedian of 3
976	Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists.
978	not found
979	not found, one past the end
984	Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to
989	Optimization: Handle special cases to cut down recursions.
990	no element falls into this bin
991	all bins with splitters[i] <= splitter are empty
996	all elements fall into this bin
997	all bins with splitters[i] >= splitter are empty
1003	recursively partition left half
1008	recursively partition right half
1018	int, double --> template type dependent
1022	swap x[i] with x[from]
1047	int, double --> template type dependent
1049	nothing to do
1050	all bins are empty
1056	Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation.
1060	we don't really have a choice
1063	we do have a choice
1064	Small arrays, middle element
1069	Big arrays, pseudomedian of 9
1075	Mid-size, pseudomedian of 3
1078	Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists.
1080	not found
1081	not found, one past the end
1086	Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to
1091	Optimization: Handle special cases to cut down recursions.
1092	no element falls into this bin
1093	all bins with splitters[i] <= splitter are empty
1098	all elements fall into this bin
1099	all bins with splitters[i] >= splitter are empty
1105	recursively partition left half
1110	recursively partition right half
1120	int, double --> template type dependent
1124	swap x[i] with x[from]
1159	int, double --> template type dependent
1161	nothing to do
1162	all bins are empty
1168	Choose a partition (pivot) index, m Ideally, the pivot should be the median, because a median splits a list into two equal sized sublists. However, computing the median is expensive, so we use an approximation.
1172	we don't really have a choice
1175	we do have a choice
1176	Small arrays, middle element
1181	Big arrays, pseudomedian of 9
1187	Mid-size, pseudomedian of 3
1190	Find the splitter closest to the pivot, i.e. the splitter that best splits the list into two equal sized sublists.
1192	not found
1193	not found, one past the end
1198	Partition the list according to the splitter, i.e. Establish invariant: list[i] < splitter <= list[j] for i=from..medianIndex and j=medianIndex+1 .. to
1203	Optimization: Handle special cases to cut down recursions.
1204	no element falls into this bin
1205	all bins with splitters[i] <= splitter are empty
1210	all elements fall into this bin
1211	all bins with splitters[i] >= splitter are empty
1217	recursively partition left half
1222	recursively partition right half
1237	int, double --> template type dependent
1241	swap x[i] with x[from]

Colt/xml/cern/colt/PersistentObject.xml
35	should never happen since we are cloneable

Colt/xml/cern/colt/Sorting.xml
71	key found
73	key not found.
105	key found
107	key not found.
139	key found
141	key not found.
173	key found
175	key not found.
207	key found
209	key not found.
211	even for very short lists (0,1,2,3 elems) this is only 10% faster while (from<=to && list[from++] < key) ; if (from<=to) { if (list[--from] == key) return from; } return -(from + 1);
250	key found
252	key not found.
296	key found
298	key not found.
330	key found
332	key not found.
364	key found
366	key not found.
419	rotate(array, firstCut, middle, secondCut); is manually inlined for speed (jitter inlining seems to work only for small call depths, even if methods are "static private") speedup = 1.7 begin inline
433	end inline
952	Insertion sort on smallest arrays
960	Recursively sort halves of dest into src
965	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
972	Merge sorted halves (now in src) into dest
983	Insertion sort on smallest arrays
991	Recursively sort halves of dest into src
996	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1003	Merge sorted halves (now in src) into dest
1014	Insertion sort on smallest arrays
1022	Recursively sort halves of dest into src
1027	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1034	Merge sorted halves (now in src) into dest
1045	Insertion sort on smallest arrays
1053	Recursively sort halves of dest into src
1058	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1065	Merge sorted halves (now in src) into dest
1076	Insertion sort on smallest arrays
1084	Recursively sort halves of dest into src
1089	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1096	Merge sorted halves (now in src) into dest
1107	Insertion sort on smallest arrays
1115	Recursively sort halves of dest into src
1120	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1127	Merge sorted halves (now in src) into dest
1138	Insertion sort on smallest arrays
1146	Recursively sort halves of dest into src
1151	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1158	Merge sorted halves (now in src) into dest
1169	Insertion sort on smallest arrays
1177	Recursively sort halves of dest into src
1182	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1189	Merge sorted halves (now in src) into dest
1200	Insertion sort on smallest arrays
1208	Recursively sort halves of dest into src
1213	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1220	Merge sorted halves (now in src) into dest
1231	Insertion sort on smallest arrays
1239	Recursively sort halves of dest into src
1244	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1251	Merge sorted halves (now in src) into dest
1262	Insertion sort on smallest arrays
1270	Recursively sort halves of dest into src
1275	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1282	Merge sorted halves (now in src) into dest
1293	Insertion sort on smallest arrays
1301	Recursively sort halves of dest into src
1306	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1313	Merge sorted halves (now in src) into dest
1324	Insertion sort on smallest arrays
1332	Recursively sort halves of dest into src
1337	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1344	Merge sorted halves (now in src) into dest
1355	Insertion sort on smallest arrays
1363	Recursively sort halves of dest into src
1368	If list is already sorted, just copy from src to dest.  This is an optimization that results in faster sorts for nearly ordered lists.
1375	Merge sorted halves (now in src) into dest
1386	The sort is done in three phases to avoid the expense of using NaN and -0.0 aware comparisons during the main sort.
1391	Preprocessing phase:  Move any NaN's to end of array, count the number of -0.0's, and turn them into 0.0's.
1410	Main sort phase: mergesort everything but the NaN's
1414	Postprocessing phase: change 0.0's to -0.0's as required
1416	posn of ANY zero
1421	j is now one less than the index of the FIRST zero
1429	The sort is done in three phases to avoid the expense of using NaN and -0.0 aware comparisons during the main sort.
1434	Preprocessing phase:  Move any NaN's to end of array, count the number of -0.0's, and turn them into 0.0's.
1453	Main sort phase: mergesort everything but the NaN's
1457	Postprocessing phase: change 0.0's to -0.0's as required
1459	posn of ANY zero
1464	j is now one less than the index of the FIRST zero
1493	Insertion sort on smallest arrays
1503	Recursively sort halves
1508	If list is already sorted, nothing left to do.  This is an optimization that results in faster sorts for nearly ordered lists.
1512	Merge sorted halves jal.INT.Sorting.inplace_merge(a, fromIndex, mid, toIndex);
1838	Insertion sort on smallest arrays
1846	Choose a partition element, v
1847	Small arrays, middle element
1851	Big arrays, pseudomedian of 9
1857	Mid-size, med of 3
1861	Establish Invariant: v* (<v)* (>v)* v*
1880	Swap partition elements back to middle
1885	Recursively sort non-partition-elements
1895	Insertion sort on smallest arrays
1903	Choose a partition element, v
1904	Small arrays, middle element
1908	Big arrays, pseudomedian of 9
1914	Mid-size, med of 3
1918	Establish Invariant: v* (<v)* (>v)* v*
1937	Swap partition elements back to middle
1942	Recursively sort non-partition-elements
1952	Insertion sort on smallest arrays
1960	Choose a partition element, v
1961	Small arrays, middle element
1965	Big arrays, pseudomedian of 9
1971	Mid-size, med of 3
1975	Establish Invariant: v* (<v)* (>v)* v*
1994	Swap partition elements back to middle
1999	Recursively sort non-partition-elements
2009	Insertion sort on smallest arrays
2017	Choose a partition element, v
2018	Small arrays, middle element
2022	Big arrays, pseudomedian of 9
2028	Mid-size, med of 3
2032	Establish Invariant: v* (<v)* (>v)* v*
2051	Swap partition elements back to middle
2056	Recursively sort non-partition-elements
2066	Insertion sort on smallest arrays
2074	Choose a partition element, v
2075	Small arrays, middle element
2079	Big arrays, pseudomedian of 9
2085	Mid-size, med of 3
2089	Establish Invariant: v* (<v)* (>v)* v*
2108	Swap partition elements back to middle
2113	Recursively sort non-partition-elements
2123	Insertion sort on smallest arrays
2131	Choose a partition element, v
2132	Small arrays, middle element
2136	Big arrays, pseudomedian of 9
2142	Mid-size, med of 3
2146	Establish Invariant: v* (<v)* (>v)* v*
2165	Swap partition elements back to middle
2170	Recursively sort non-partition-elements
2180	Insertion sort on smallest arrays
2188	Choose a partition element, v
2189	Small arrays, middle element
2193	Big arrays, pseudomedian of 9
2199	Mid-size, med of 3
2203	Establish Invariant: v* (<v)* (>v)* v*
2222	Swap partition elements back to middle
2227	Recursively sort non-partition-elements
2237	Insertion sort on smallest arrays
2245	Choose a partition element, v
2246	Small arrays, middle element
2250	Big arrays, pseudomedian of 9
2256	Mid-size, med of 3
2260	Establish Invariant: v* (<v)* (>v)* v*
2279	Swap partition elements back to middle
2284	Recursively sort non-partition-elements
2294	Insertion sort on smallest arrays
2302	Choose a partition element, v
2303	Small arrays, middle element
2307	Big arrays, pseudomedian of 9
2313	Mid-size, med of 3
2317	Establish Invariant: v* (<v)* (>v)* v*
2336	Swap partition elements back to middle
2341	Recursively sort non-partition-elements

Colt/xml/cern/colt/Swapper.xml

Colt/xml/cern/colt/Timer.xml
47	we are started
118	benchmark this piece
130	do something we do not want to benchmark
138	benchmark another piece and add to last benchmark
148	benchmark yet another piece independently
149	set timer to zero

Colt/xml/cern/colt/Version.xml
45	String s = "1.2.3.56 (Tue Apr 11 11:50:39 CEST 2000)";
94	int[] numbers = new int[w];
97	if (getPackage()==null) return numbers; String s = getPackage().getImplementationVersion(); if (s==null) return numbers; int k = s.indexOf('('); s = s.substring(0,k); s = s.trim(); s = s.replace('.', ' '); s = ViolinStrings.Strings.stripBlanks(s); s = ViolinStrings.Strings.translate(s, ".", " "); String[] words = s.split(".");  requires jdk 1.4.x for (int i=0; i<w; i++) { numbers[i] = Integer.parseInt(words[i]); numbers[i] = Integer.parseInt(ViolinStrings.Strings.word(s, i)); System.out.println(numbers[i]); } return numbers;

Colt/xml/cern/jet/math/Algebraic.xml

Colt/xml/cern/jet/math/Arithmetic.xml
16	for method stirlingCorrection(...)
36	for method logFactorial(...) log(k!) for k = 0, ..., 29
51	k! for k = 0, ..., 20
76	k! for k = 21, ..., 170
250	binomial(n,k) = (n * n-1 * ... * n-k+1 ) / ( 1 * 2 * ... * k )
275	try quick version and see whether we get numeric overflows. factorial(..) is O(1); requires no loop; only a table lookup.
279	if (n! < inf && k! < inf)
284	no numeric overflow?
285	now this is completely safe and accurate
289	quicker
292	binomial(n,k) = (n * n-1 * ... * n-k+1 ) / ( 1 * 2 * ... * k )
423	1.0 / Math.log(10) == 0.43429448190325176
430	1.0 / Math.log(2) == 1.4426950408889634
482	+1/12
483	-1/360
484	+1/1260
485	-1/1680

Colt/xml/cern/jet/math/Bessel.xml
16	COEFFICIENTS FOR METHODS i0, i0e
97	COEFFICIENTS FOR METHODS i1, i1e
138	Chebyshev coefficients for exp(-x) sqrt(x) I1(x) in the inverted interval [8,infinity].  lim(x->inf){ exp(-x) sqrt(x) I1(x) } = 1sqrt(2pi).
197	Chebyshev coefficients for exp(x) sqrt(x) K0(x) in the inverted interval [2,infinity].  lim(x->inf){ exp(x) sqrt(x) K0(x) } = sqrt(pi2).
255	Chebyshev coefficients for exp(x) sqrt(x) K1(x) in the interval [2,infinity].  lim(x->inf){ exp(x) sqrt(x) K1(x) } = sqrt(pi2).
606	Algorithm for Kn. n-1 -n   -  (n-k-1)!    2   k K (x)  =  0.5 (x2)     >  -------- (-x 4) n                      -     k! k=0  inf.                                   2   k n         n   -                                   (x 4) + (-1)  0.5(x2)    >  {p(k+1) + p(n+k+1) - 2log(x2)} --------- -                                  k! (n+k)! k=0  where  p(m) is the psi function: p(1) = -EUL and  m-1 - p(m)  =  -EUL +  >  1k - k=1  For large x, 2        2     2 u-1     (u-1 )(u-3 ) K (z)  =  sqrt(pi2z) exp(-z) { 1 + ------- + ------------ + ...} v                                        1            2 1! (8z)     2! (8z) asymptotically, where  2 u = 4 v .

Colt/xml/cern/jet/math/Complex.xml

Colt/xml/cern/jet/math/Constants.xml
16	machine constants
31	MACHEP =  1.38777878078144567553E-17       2-56 MAXLOG =  8.8029691931113054295988E1       log(2127) MINLOG = -8.872283911167299960540E1        log(2-128) MAXNUM =  1.701411834604692317316873e38    2127  For IEEE arithmetic (IBMPC): MACHEP =  1.11022302462515654042E-16       2-53 MAXLOG =  7.09782712893383996843E2         log(21024) MINLOG = -7.08396418532264106224E2         log(2-1022) MAXNUM =  1.7976931348623158E308           21024  The global symbols for mathematical constants are PI     =  3.14159265358979323846           pi PIO2   =  1.57079632679489661923           pi2 PIO4   =  7.85398163397448309616E-1        pi4 SQRT2  =  1.41421356237309504880           sqrt(2) SQRTH  =  7.07106781186547524401E-1        sqrt(2)2 LOG2E  =  1.4426950408889634073599         1log(2) SQ2OPI =  7.9788456080286535587989E-1      sqrt( 2pi ) LOGE2  =  6.93147180559945309417E-1        log(2) LOGSQ2 =  3.46573590279972654709E-1        log(2)2 THPIO4 =  2.35619449019234492885           3pi4 TWOOPI =  6.36619772367581343075535E-1     2pi

Colt/xml/cern/jet/math/Elliptic.xml

Colt/xml/cern/jet/math/Exponential.xml

Colt/xml/cern/jet/math/ExponentialIntegral.xml

Colt/xml/cern/jet/math/Functions.xml
167	<H3>Unary functions<H3>
184	Function that returns <tt>com.imsl.math.Sfun.acosh(a)<tt>.
187	public static final DoubleFunction acosh = new DoubleFunction() { public final double apply(double a) { return Sfun.acosh(a); } };
200	Function that returns <tt>com.imsl.math.Sfun.asinh(a)<tt>.
203	public static final DoubleFunction asinh = new DoubleFunction() { public final double apply(double a) { return Sfun.asinh(a); } };
216	Function that returns <tt>com.imsl.math.Sfun.atanh(a)<tt>.
219	public static final DoubleFunction atanh = new DoubleFunction() { public final double apply(double a) { return Sfun.atanh(a); } };
239	Function that returns <tt>com.imsl.math.Sfun.cosh(a)<tt>.
242	public static final DoubleFunction cosh = new DoubleFunction() { public final double apply(double a) { return Sfun.cosh(a); } };
248	Function that returns <tt>com.imsl.math.Sfun.cot(a)<tt>.
251	public static final DoubleFunction cot = new DoubleFunction() { public final double apply(double a) { return Sfun.cot(a); } };
257	Function that returns <tt>com.imsl.math.Sfun.erf(a)<tt>.
260	public static final DoubleFunction erf = new DoubleFunction() { public final double apply(double a) { return Sfun.erf(a); } };
266	Function that returns <tt>com.imsl.math.Sfun.erfc(a)<tt>.
269	public static final DoubleFunction erfc = new DoubleFunction() { public final double apply(double a) { return Sfun.erfc(a); } };
289	Function that returns <tt>com.imsl.math.Sfun.gamma(a)<tt>.
292	public static final DoubleFunction gamma = new DoubleFunction() { public final double apply(double a) { return Sfun.gamma(a); } };
319	Function that returns <tt>com.imsl.math.Sfun.log10(a)<tt>.
322	public static final DoubleFunction log10 = new DoubleFunction() { public final double apply(double a) { return Sfun.log10(a); } };
336	Function that returns <tt>com.imsl.math.Sfun.logGamma(a)<tt>.
339	public static final DoubleFunction logGamma = new DoubleFunction() { public final double apply(double a) { return Sfun.logGamma(a); } };
373	Function that returns <tt>com.imsl.math.Sfun.sinh(a)<tt>.
376	public static final DoubleFunction sinh = new DoubleFunction() { public final double apply(double a) { return Sfun.sinh(a); } };
403	Function that returns <tt>com.imsl.math.Sfun.tanh(a)<tt>.
406	public static final DoubleFunction tanh = new DoubleFunction() { public final double apply(double a) { return Sfun.tanh(a); } };
412	Function that returns <tt>Math.toDegrees(a)<tt>.
415	public static final DoubleFunction toDegrees = new DoubleFunction() { public final double apply(double a) { return Math.toDegrees(a); } };
421	Function that returns <tt>Math.toRadians(a)<tt>.
424	public static final DoubleFunction toRadians = new DoubleFunction() { public final double apply(double a) { return Math.toRadians(a); } };
432	<H3>Binary functions<H3>
443	Function that returns <tt>com.imsl.math.Sfun.logBeta(a,b)<tt>.
446	public static final DoubleDoubleFunction logBeta = new DoubleDoubleFunction() { public final double apply(double a, double b) { return Sfun.logBeta(a,b); } };
541	new DoubleDoubleFunction() { public final double apply(double a, double b) { return a - b; } };
565	new DoubleDoubleFunction() { public final double apply(double a, double b) { return a + b; } };
685	DoubleDoubleFunction f = F.chain(plus,sin,F.chain(square,cos));
705	double v = Math.sin(a) + Math.pow(Math.cos(b),2); double v = a + b;
709	DoubleDoubleFunction f = F.chain(F.plus,F.identity,F.identity);
711	DoubleDoubleFunction f = F.chain(F.plus,F.sin,F.chain(F.square,F.cos)); DoubleDoubleFunction f = F.plus;
717	public final double apply(double x, double y) { return x+y; }
721	emptyLoop
738	sum += a + b;
853	cached for speed
863	demo1();
912	return new DoubleFunction() { public final double apply(double a) { return a  b; } };
933	return new DoubleDoubleFunction() { public final double apply(double a, double b) { return a + bconstant; } };

Colt/xml/cern/jet/math/IntFunctions.xml
41	<H3>Unary functions<H3>
112	<H3>Binary functions<H3>

Colt/xml/cern/jet/math/Misc.xml

Colt/xml/cern/jet/math/Mult.xml

Colt/xml/cern/jet/math/NumericalIntegration.xml

Colt/xml/cern/jet/math/PlusMult.xml

Colt/xml/cern/jet/math/Polynomial.xml

Colt/xml/cern/jet/random/AbstractContinousDistribution.xml

Colt/xml/cern/jet/random/AbstractDiscreteDistribution.xml

Colt/xml/cern/jet/random/AbstractDistribution.xml

Colt/xml/cern/jet/random/Benchmark.xml
33	Gamma distribution
35	define distribution parameters
41	for tests and debugging use a random engine with CONSTANT seed --> deterministic and reproducible results
44	your favourite distribution goes here
47	collect random numbers and print statistics
77	int large = 100000000;
79	= new MersenneTwister();
86	randomInstance(size,print,new Zeta(10.0, 10.0,(RandomEngine)gen.clone())); randomInstance(size,print,new Zeta(1.0, 1.0, (RandomEngine)gen.clone())); randomInstance(size,print,new Zeta(mean, mean, (RandomEngine)gen.clone())); randomInstance(size,print,new Zeta(mean, 1mean, (RandomEngine)gen.clone())); randomInstance(size,print,new Zeta(1mean, mean, (RandomEngine)gen.clone()));
94	randomInstance(size,print,new Beta(10.0, 10.0,(RandomEngine)gen.clone())); randomInstance(size,print,new Beta(1.0, 1.0, (RandomEngine)gen.clone())); randomInstance(size,print,new Beta(mean, mean, (RandomEngine)gen.clone())); randomInstance(size,print,new Beta(mean, 1mean, (RandomEngine)gen.clone())); randomInstance(size,print,new Beta(1mean, mean, (RandomEngine)gen.clone()));  randomInstance(size,print,new Uniform((RandomEngine)gen.clone()));
105	randomInstance(size,print,new PoissonSlow(mean,(RandomEngine)gen.clone()));  randomInstance(size,print,new Poisson(3.0,(RandomEngine)gen.clone())); randomInstance(size,print,new PoissonSlow(3.0,(RandomEngine)gen.clone()));  randomInstance(size,print,new Binomial(1,0.5,(RandomEngine)gen.clone())); randomInstance(size,print,new Binomial(5,0.3,(RandomEngine)gen.clone())); randomInstance(size,print,new Binomial((int)mean,0.999999999,(RandomEngine)gen.clone())); randomInstance(size,print,new Binomial((int)mean,1.0mean,(RandomEngine)gen.clone()));  randomInstance(size,print,new Exponential(1.0,(RandomEngine)gen.clone())); randomInstance(size,print,new Exponential(3.0,(RandomEngine)gen.clone()));  randomInstance(size,print,new Normal(0.0,1.0,(RandomEngine)gen.clone())); randomInstance(size,print,new Normal(3.0,1.0,(RandomEngine)gen.clone())); randomInstance(size,print,new Normal(mean,largeVariance,(RandomEngine)gen.clone()));  randomInstance(size,print,new BreitWigner(1.0, 0.2, Double.NEGATIVE_INFINITY, (RandomEngine)gen.clone())); randomInstance(size,print,new BreitWigner(1.0, 0.2, 1.0, (RandomEngine)gen.clone()));  randomInstance(size,print,new BreitWignerMeanSquare(1.0, 0.2, Double.NEGATIVE_INFINITY, (RandomEngine)gen.clone())); randomInstance(size,print,new BreitWignerMeanSquare(1.0, 0.2, 1.0, (RandomEngine)gen.clone()));  randomInstance(size,print,new ChiSquare(1.0,(RandomEngine)gen.clone())); randomInstance(size,print,new ChiSquare(5.0,(RandomEngine)gen.clone())); randomInstance(size,print,new ChiSquare(mean,(RandomEngine)gen.clone()));  randomInstance(size,print,new Gamma(0.2,1.0,(RandomEngine)gen.clone())); randomInstance(size,print,new Gamma(1.0,1.0,(RandomEngine)gen.clone())); randomInstance(size,print,new Gamma(3.0,0.5,(RandomEngine)gen.clone())); randomInstance(size,print,new Gamma(mean,0.5,(RandomEngine)gen.clone())); randomInstance(size,print,new Gamma(mean,1.0mean,(RandomEngine)gen.clone())); randomInstance(size,print,new Gamma(mean,mean,(RandomEngine)gen.clone()));  randomInstance(size,print,new StudentT(1.0,(RandomEngine)gen.clone())); randomInstance(size,print,new StudentT(2.5,(RandomEngine)gen.clone())); randomInstance(size,print,new StudentT(mean,(RandomEngine)gen.clone())); randomInstance(size,print,new StudentT(1.0mean,(RandomEngine)gen.clone()));  int probs = 10000; double[] pdf = new double[probs]; for (int i=0; i<probs; i++) pdf[i]=ii;  prepare f(x)=x^2 distrib. randomInstance(size,print,new Empirical(pdf,Empirical.NO_INTERPOLATION, (RandomEngine)gen.clone())); randomInstance(size,print,new Empirical(pdf,Empirical.LINEAR_INTERPOLATION, (RandomEngine)gen.clone()));
201	System.out.println(binA); System.out.println(binB); System.out.println(binA.compareWith(binB));
213	System.out.println(distinct); System.out.println(freq);
216	timer.reset(); timer.start(); binA.xfrequencies2(distinct,freq); timer.stop().display(); System.out.println(distinct); System.out.println(freq);
225	distinct.shuffle(); timer.reset().start(); distinct.sort(); timer.stop().display();  timer.reset().start(); binA.frequencies(distinct,freq); timer.stop().display(); System.out.println(distinct); System.out.println(freq);

Colt/xml/cern/jet/random/Beta.xml
47	cache to speed up pdf()
49	cached values shared by bXX
53	cached values for b00
56	chached values for b01
59	chached values for b1prs
65	The uniform random number generated shared by all <b>static</b> methods.
86	b(1-b) / a(1-a)
87	t = t_opt
89	f(t) = fa * fb
91	0 < X < t
92	t < X < 1
96	X < t
98	squeeze accept:   L(x) = 1 + (1 - b)x
100	squeeze reject:   U(x) = 1 + ((1 - t)^(b-1) - 1)/t * x
102	quotient accept:  q(x) = (1 - x)^(b-1) / fb
106	X > t
108	squeeze accept:   L(x) = 1 + (1 - a)(1 - x)
110	squeeze reject:   U(x) = 1 + (t^(a-1) - 1)/(1 - t) * (1 - x)
112	quotient accept:  q(x) = x^(a-1) / fa
131	one step Newton * start value t
135	f(t) = fa * fb
137	ml = -m1
138	mu = -m2 * t
144	0 < X < t
145	t < X < 1
149	X < t
151	squeeze accept:   L(x) = 1 + m1*x,  ml = -m1
153	squeeze reject:   U(x) = 1 + m2*x,  mu = -m2 * t
155	quotient accept:  q(x) = (1 - x)^(b-1)
159	X > t
161	squeeze accept:   L(x) = 1 + (1 - a)(1 - x)
163	squeeze reject:   U(x) = 1 + (t^(a-1) - 1)/(1 - t) * (1 - x)
165	quotient accept:  q(x) = (x)^(a-1) / fa
201	z1 = x1 - ll
216	z5 = x5 + lr
220	x1 < X < m
221	m  < X < x5
222	X < x1
223	x5 < X
228	immediate accept:  x2 < X < m, - f(x2) < W < 0
230	immediate accept:  x1 < X < x2, 0 < W < f(x1)
232	candidates for acceptance-rejection-test
235	squeeze accept:    L(x) = f(x2) (x - z2) / (x2 - z2)
238	squeeze accept:    L(x) = f(x2) + (1 - f(x2))(x - x2)/(m - x2)
240	quotient accept:   x2 < Y < m,   W >= 2f2 - f(Y)
246	immediate accept:  m < X < x4, - f(x4) < W < 0
248	immediate accept:  x4 < X < x5, 0 < W < f(x5)
250	candidates for acceptance-rejection-test
253	squeeze accept:    L(x) = f(x4) (z4 - x) / (z4 - x4)
256	squeeze accept:    L(x) = f(x4) + (1 - f(x4))(x4 - x)/(x4 - m)
258	quotient accept:   m < Y < x4,   W >= 2f4 - f(Y)
262	X < x1
264	X > 0!!
266	squeeze accept:    L(x) = f(x1) (x - z1) / (x1 - z1) z1 = x1 - ll,   W <= 1 + (X - x1)/ll
271	x5 < X
273	X < 1!!
275	squeeze accept:    L(x) = f(x5) (z5 - x) / (z5 - x5) z5 = x5 + lr,   W <= 1 + (x5 - X)/lr
280	density accept:  f(x) = (x/m)^a ((1 - x)/(1 - m))^b
303	Beta Distribution - Stratified RejectionPatchwork Rejection   For parameters a < 1 , b < 1  and  a < 1 < b   or  b < 1 < a the stratified rejection methods b00 and b01 of Sakasegawa are used. Both procedures employ suitable two-part power functions from which samples can be obtained by inversion. If a > 1 , b > 1 (unimodal case) the patchwork rejection method b1prs of ZechnerStadlober is utilized: The area below the density function f(x) in its body is rearranged by certain point reflections. Within a large center interval variates are sampled efficiently by rejection from uniform hats. Rectangular immediate acceptance regions speed up the generation. The remaining tails are covered by exponential functions. If (a-1)(b-1) = 0  sampling is done by inversion if either a or b are not equal to one. If  a = b = 1  a uniform random variate is delivered.    FUNCTION :   - bsprc samples a random variate from the beta distribution with parameters  a > 0, b > 0. REFERENCES : - H. Sakasegawa (1983): Stratified rejection and squeeze method for generating beta random numbers, Ann. Inst. Statist. Math. 35 B, 291-302. - H. Zechner, E. Stadlober (1993): Generating beta variates via patchwork rejection, Computing 50, 1-18.  SUBPROGRAMS: - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed. - b00(seed,a,b) ... Beta generator for a<1, b<1 - b01(seed,a,b) ... Beta generator for a<1<b or b<1<a - b1prs(seed,a,b) ... Beta generator for a>1, b>1 with unsigned long integer seed, double a, b.

Colt/xml/cern/jet/random/Binomial.xml
37	cache vars for method generateBinomial(...)
43	cache vars for method pdf(...)
46	The uniform random number generated shared by all <b>static</b> methods.
129	set-up
136	Check for invalid input values
141	mode, integer
143	Chop-down
148	recurr. relat.
149	variance
150	i = p1 - 0.5
152	limit left
153	limit right
156	parallelogram
157	height
159	probabilities
160	of regions 1-4
165	Inversion Chop-down
188	triangular region
190	immediate accept
192	parallelogram
197	left tail
202	right tail
207	acceptance test :  two cases, depending on |K - m|
210	computation of p(K) via recurrence relationship from the mode
211	f(m)
214	multiply  f
219	multiply  V
222	acceptance test
226	lower and upper squeeze tests, based on lower bounds for log p(K)
242	computation of log f(K) via Stirling's formula final acceptance-rejection test

Colt/xml/cern/jet/random/BreitWigner.xml
31	The uniform random number generated shared by all <b>static</b> methods.
55	don't cut

Colt/xml/cern/jet/random/BreitWignerMeanSquare.xml
26	helper
28	The uniform random number generated shared by all <b>static</b> methods.
55	don't cut

Colt/xml/cern/jet/random/ChiSquare.xml
42	cached vars for method nextDouble(a) (for performance only)
45	The uniform random number generated shared by all <b>static</b> methods.
75	Chi Distribution - Ratio of Uniforms  with shift    FUNCTION :   - chru samples a random number from the Chi distribution with parameter  a > 1. REFERENCE :  - J.F. Monahan (1987): An algorithm for generating chi random variables, ACM Trans. Math. Software 13, 168-172. SUBPROGRAM : - anEngine  ... pointer to a (0,1)-Uniform engine  Implemented by R. Kremer, 1990
94	if( a < 1 )  return (-1.0); // Check for invalid input value

Colt/xml/cern/jet/random/Distributions.xml
71	Burr II, VII, VIII, X Distributions - Inversion    FUNCTION :   - burr1 samples a random number from one of the Burr II, VII, VIII, X distributions with parameter  r > 0 , where the no. of the distribution is indicated by a pointer variable. REFERENCE :  - L. Devroye (1986): Non-Uniform Random Variate Generation, Springer Verlag, New York. SUBPROGRAM : - drand(seed) ... (0,1)-uniform generator with unsigned long integer seed.
92	BURR II
95	BURR VII
98	BURR VIII
101	BURR X
120	Burr III, IV, V, VI, IX, XII Distribution - Inversion    FUNCTION :   - burr2 samples a random number from one of the Burr III, IV, V, VI, IX, XII distributions with parameters r > 0 and k > 0, where the no. of the distribution is indicated by a pointer variable. REFERENCE :  - L. Devroye (1986): Non-Uniform Random Variate Generation, Springer Verlag, New York. SUBPROGRAM : - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed.
138	U(0/1)
139	u^(-1/r) - 1
141	BURR III
142	y^(-1/k)
144	BURR IV
145	y^k + 1
149	BURR V
150	arctan[log(y/k)]
153	BURR VI
158	BURR IX
160	y^(1/r) -1
163	BURR XII
164	y^(1/k)
206	Geometric Distribution - Inversion    On generating random numbers of a discrete distribution by Inversion normally sequential search is necessary, but in the case of the Geometric distribution a direct transformation is possible because of the special parallel to the continuous Exponential distribution Exp(t): X - Exp(t): G(x)=1-exp(-tx) Geo(p): pk=G(k+1)-G(k)=exp(-tk)(1-exp(-t)) p=1-exp(-t) A random number of the Geometric distribution Geo(p) is obtained by k=(long int)x, where x is from Exp(t) with parameter t=-log(1-p).    FUNCTION:    - geo samples a random number from the Geometric distribution with parameter 0<p<1. SUBPROGRAMS: - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed.
247	sign(l)
250	U(0/1)
294	Triangular Distribution - Inversion: x = +-(1-sqrt(u))    FUNCTION :   - tra samples a random number from the standard Triangular distribution in (-1,1) SUBPROGRAM : - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed.
318	Polar method. See Simulation, Modelling & Analysis by Law & Kelton, pp259
333	Algorithm from page 551 of: Devroye, Luc (1986) `Non-uniform random variate generation', Springer-Verlag: Berlin.   ISBN 3-540-96305-7 (also 0-387-96305-7)

Colt/xml/cern/jet/random/Empirical.xml
38	cumulative distribution function
85	Non-existing pdf
87	binary search in cumulative distribution function:
89	largest k such that I[k] is known to be <= rand
90	largest k such that I[k] is known to be >  rand
93	div 2
97	after this binary search, nabove is always nbelow+1 and they straddle rand:
104	binMeasure is always aProbFunc[nbelow], but we don't have aProbFunc any more so we subtract.
108	rand lies right in a bin of measure 0.  Simply return the center of the range of that bin.  (Any value between k/N and (k+1)/N is equally good, in this rare case.)
117	illegal interpolation type
124	if (x < 0 || x > cdf.length-2) return 0.0; int k = (int) x; return cdf[k-1] - cdf[k];
155	throw new IllegalArgumentException("Non-existing pdf");
159	compute cumulative distribution function (cdf) from probability distribution function (pdf)
173	cdf is now cached...

Colt/xml/cern/jet/random/EmpiricalWalker.xml
49	cumulative distribution function
50	James Theiler, jt@lanl.gov, the author of the GSL routine this port is based on, describes his approach as follows:  Based on: Alastair J Walker, An efficient method for generating discrete random variables with general distributions, ACM Trans Math Soft 3, 253-256 (1977).  See also: D. E. Knuth, The Art of Computer Programming, Volume 2 (Seminumerical algorithms), 3rd edition, Addison-Wesley (1997), p120.  Walker's algorithm does some preprocessing, and provides two arrays: floating point F[k] and integer A[k].  A value k is chosen from 0..K-1 with equal likelihood, and then a uniform random number u is compared to F[k].  If it is less than F[k], then k is returned.  Otherwise, A[k] is returned.  Walker's original paper describes an O(K^2) algorithm for setting up the F and A arrays.  I found this disturbing since I wanted to use very large values of K.  I'm sure I'm not the first to realize this, but in fact the preprocessing can be done in O(K) steps.  A figure of merit for the preprocessing is the average value for the F[k]'s (that is, SUM_k F[k]K); this corresponds to the probability that k is returned, instead of A[k], thereby saving a redirection.  Walker's O(K^2) preprocessing will generally improve that figure of merit, compared to my cheaper O(K) method; from some experiments with a perl script, I get values of around 0.6 for my method and just under 0.75 for Walker's.  Knuth has pointed out that finding _the_ optimum lookup tables, which maximize the average F[k], is a combinatorially difficult problem.  But any valid preprocessing will still provide O(1) time for the call to gsl_ran_discrete().  I find that if I artificially set F[k]=1 -- ie, better than optimum! -- I get a speedup of maybe 20%, so that's the maximum I could expect from the most expensive preprocessing. Folding in the difference of 0.6 vs 0.75, I'd estimate that the speedup would be less than 10%.  I've not implemented it here, but one compromise is to sort the probabilities once, and then work from the two ends inward.  This requires O(K log K), still lots cheaper than O(K^2), and from my experiments with the perl script, the figure of merit is within about 0.01 for K up to 1000, and no sign of diverging (in fact, they seemed to be converging, but it's hard to say with just a handful of runs).  The O(K) algorithm goes through all the p_k's and decides if they are "smalls" or "bigs" according to whether they are less than or greater than the mean value 1K.  The indices to the smalls and the bigs are put in separate stacks, and then we work through the stacks together.  For each small, we pair it up with the next big in the stack (Walker always wanted to pair up the smallest small with the biggest big).  The small "borrows" from the big just enough to bring the small up to mean.  This reduces the size of the big, so the (smaller) big is compared again to the mean, and if it is smaller, it gets "popped" from the big stack and "pushed" to the small stack.  Otherwise, it stays put.  Since every time we pop a small, we are able to deal with it right then and there, and we never have to pop more than K smalls, then the algorithm is O(K).  This implementation sets up two separate stacks, and allocates K elements between them.  Since neither stack ever grows, we do an extra O(K) pass through the data to determine how many smalls and bigs there are to begin with and allocate appropriately.  In all there are 2Ksizeof(double) transient bytes of memory that are used than returned, and K(sizeof(int)+sizeof(double)) bytes used in the lookup table.  Walker spoke of using two random numbers (an integer 0..K-1, and a floating point u in [0,1]), but Knuth points out that one can just use the integer and fractional parts of Ku where u is in [0,1]. In fact, Knuth further notes that taking F'[k]=(k+F[k])K, one can directly compare u to F'[k] without having to explicitly set u=Ku-int(Ku).  Usage:  Starting with an array of probabilities P, initialize and do preprocessing with a call to:  gsl_rng r; gsl_ran_discrete_t f; f = gsl_ran_discrete_preproc(K,P);  Then, whenever a random index 0..K-1 is desired, use  k = gsl_ran_discrete(r,f);  Note that several different randevent struct's can be simultaneously active.  Aside: A very clever alternative approach is described in Abramowitz and Stegun, p 950, citing: Marsaglia, Random variables and computers, Proc Third Prague Conference in Probability Theory, 1962.  A more accesible reference is: G. Marsaglia, Generating discrete random numbers in a computer, Comm ACM 6, 37-38 (1963). If anybody is interested, I (jt) have also coded up this version as part of another software package.  However, I've done some comparisons, and the Walker method is both faster and more stingy with memory.  So, in the end I decided not to include it with the GSL package.  Written 26 Jan 1999, James Theiler, jt@lanl.gov Adapted to GSL, 30 Jan 1999, jt
201	#if KNUTH_CONVENTION c = (int)(u*(g->K)); #else
207	#endif
209	fprintf(stderr,"c,f,u: %d %.4f %f\n",c,f,u);
241	compute cumulative distribution function (cdf) from probability distribution function (pdf)
251	now normalize to 1 (relative probabilities).
255	cdf is now cached...
277	if (size < 1) { throw new IllegalArgumentException("must have size greater than zero"); }
280	Make sure elements of ProbArray[] are positive. Won't enforce that sum is unity; instead will just normalize
284	if (pdf[k] < 0) {
285	throw new IllegalArgumentException("Probabilities must be >= 0: "+pdf[k]);
286	}
295	normalize to relative probability
331	#if DEBUG fprintf(stderr,"s=%2d, A=%2d, F=%.4f\n",s,(g->A)[s],(g->F)[s]); #endif
359	#if 0
360	if 1, then artificially set all F[k]'s to unity.  This will give wrong answers, but you'll get them faster.  But, not that much faster (I get maybe 20%); that's an upper bound on what the optimal preprocessing would give.
365	for (k=0; k<size; ++k) { F[k] = 1.0; } #endif
372	#if KNUTH_CONVENTION
374	This saves some arithmetic in gsl_ran_discrete(); I find that it doesn't actually make much difference.
377	for (k=0; k<size; ++k) { F[k] += k; F[k] = size; } #endif
384	free_stack(Bigs); free_stack(Smalls); free((char )E);  return g;

Colt/xml/cern/jet/random/engine/Benchmark.xml
97	no operation
117	gen = new edu.stanford.mt.MersenneTwister(); System.out.println("\n edu.stanford.mt.MersenneTwister:"); timer.reset().start(); for (int i=times; --i>=0; ) gen.raw(); timer.stop().display(); System.out.println(times(timer.elapsedTime()-emptyLoop)+ " numbers per second.");
138	nextDouble() is slower
142	gen = new edu.cornell.lassp.houle.RngPack.Ranecu(); System.out.println("\nRanecu:"); timer.reset().start(); for (int i=times; --i>=0; ) gen.raw(); timer.stop().display(); System.out.println(times(timer.elapsedTime()-emptyLoop)+ " numbers per second.");  gen = new edu.cornell.lassp.houle.RngPack.Ranmar(); System.out.println("\nRanmar:"); timer.reset().start(); for (int i=times; --i>=0; ) gen.raw(); timer.stop().display(); System.out.println(times(timer.elapsedTime()-emptyLoop)+ " numbers per second.");  gen = new edu.cornell.lassp.houle.RngPack.Ranlux(); System.out.println("\nRanlux:"); timer.reset().start(); for (int i=times; --i>=0; ) gen.raw(); timer.stop().display(); System.out.println(times(timer.elapsedTime()-emptyLoop)+ " numbers per second.");
176	testRandomFromTo(from,to,times); benchmark(1000000); benchmark(1000000);
181	benchmarkSync(times);
190	System.out.println("raw():"); random = (RandomEngine) randomEngine.clone(); cern.colt.Timer timer = new cern.colt.Timer().start(); for (int j=0, i=size; --i>=0; j++) { System.out.print(" "+random.raw()); if (j%8==7) System.out.println(); }  System.out.println("\n\nfloat():"); random = (RandomEngine) randomEngine.clone(); for (int j=0, i=size; --i>=0; j++) { System.out.print(" "+random.nextFloat()); if (j%8==7) System.out.println(); }  System.out.println("\n\ndouble():"); random = (RandomEngine) randomEngine.clone(); for (int j=0, i=size; --i>=0; j++) { System.out.print(" "+random.nextDouble()); if (j%8==7) System.out.println(); }
220	timer.stop().display();
229	cern.colt.set.OpenMultiFloatHashSet multiset = new cern.colt.set.OpenMultiFloatHashSet();
232	edu.cornell.lassp.houle.RngPack.RandomElement random = new edu.cornell.lassp.houle.RngPack.Ranecu(); edu.cornell.lassp.houle.RngPack.RandomElement random = new edu.cornell.lassp.houle.RngPack.MT19937B(); edu.cornell.lassp.houle.RngPack.RandomElement random = new edu.stanford.mt.MersenneTwister();
239	randomJava.nextInt(10000); Integers.randomFromTo(_from,_to);
243	multiset.add(nextIntFromTo(_from,_to));
247	System.out.println(multiset); //check the distribution

Colt/xml/cern/jet/random/engine/DRand.xml
71	a == 0x278DDE6D == 663608941
83	--> 536870911

Colt/xml/cern/jet/random/engine/MersenneTwister.xml
131	private static final int[] mag01=new int[] {0x0, MATRIX_A};
172	OPTIMIZED only 5-10% faster ? int y;  int kk; int[] cache = mt;  cached for speed int kkM; int limit = N-M; for (kk=0,kkM=kk+M; kk<limit; kk++,kkM++) { y = (cache[kk]&UPPER_MASK)|(cache[kk+1]&LOWER_MASK); cache[kk] = cache[kkM] ^ (y >>> 1) ^ ((y & 0x1) == 0 ? mag0 : mag1); } limit = N-1; for (kkM=kk+(M-N); kk<limit; kk++,kkM++) { y = (cache[kk]&UPPER_MASK)|(cache[kk+1]&LOWER_MASK); cache[kk] = cache[kkM] ^ (y >>> 1) ^ ((y & 0x1) == 0 ? mag0 : mag1); } y = (cache[N-1]&UPPER_MASK)|(cache[0]&LOWER_MASK); cache[N-1] = cache[M-1] ^ (y >>> 1) ^ ((y & 0x1) == 0 ? mag0 : mag1);  this.mt = cache; this.mti = 0;
199	******************** UNOPTIMIZED **********************
223	generate N ints at one time
226	y ^= TEMPERING_SHIFT_U(y );
227	y ^= TEMPERING_SHIFT_S(y) & TEMPERING_MASK_B;
228	y ^= TEMPERING_SHIFT_T(y) & TEMPERING_MASK_C;
229	y &= 0xffffffff; //you may delete this line if word size = 32
230	y ^= TEMPERING_SHIFT_L(y);
249	System.out.println("init done");
252	old version was: for (int i = 0; i < N; i++) { mt[i] = seed & 0xffff0000; seed = 69069  seed + 1; mt[i] |= (seed & 0xffff0000) >>> 16; seed = 69069  seed + 1; } System.out.println("init done"); mti = N;

Colt/xml/cern/jet/random/engine/MersenneTwister64.xml

Colt/xml/cern/jet/random/engine/RandomEngine.xml
36	public abstract class RandomEngine extends edu.cornell.lassp.houle.RngPack.RandomSeedable implements cern.colt.function.DoubleFunction, cern.colt.function.IntFunction {
70	-9.223372036854776E18 == (double) Long.MIN_VALUE 5.421010862427522E-20 == 1 / Math.pow(2,64) == 1 / ((double) Long.MAX_VALUE - (double) Long.MIN_VALUE);
74	catch loss of precision of long --> double conversion
77	--> in (0.0,1.0)
80	nextLong == Long.MAX_VALUE         --> 1.0 nextLong == Long.MIN_VALUE         --> 0.0 nextLong == Long.MAX_VALUE-1       --> 1.0 nextLong == Long.MAX_VALUE-100000L --> 0.9999999999999946 nextLong == Long.MIN_VALUE+1       --> 0.0 nextLong == Long.MIN_VALUE-100000L --> 0.9999999999999946 nextLong == 1L                     --> 0.5 nextLong == -1L                    --> 0.5 nextLong == 2L                     --> 0.5 nextLong == -2L                    --> 0.5 nextLong == 2L+100000L             --> 0.5000000000000054 nextLong == -2L-100000L            --> 0.49999999999999456
99	catch loss of precision of double --> float conversion
104	--> in (0.0f,1.0f)
115	concatenate two 32-bit strings into one 64-bit string
124	accept anything but zero
125	in [Integer.MIN_VALUE,Integer.MAX_VALUE]-interval
128	transform to (0.0,1.0)-interval 2.3283064365386963E-10 == 1.0 / Math.pow(2,32)
132	nextInt == Integer.MAX_VALUE   --> 0.49999999976716936 nextInt == Integer.MIN_VALUE   --> 0.5 nextInt == Integer.MAX_VALUE-1 --> 0.4999999995343387 nextInt == Integer.MIN_VALUE+1 --> 0.5000000002328306 nextInt == 1                   --> 2.3283064365386963E-10 nextInt == -1                  --> 0.9999999997671694 nextInt == 2                   --> 4.6566128730773926E-10 nextInt == -2                  --> 0.9999999995343387

Colt/xml/cern/jet/random/engine/RandomGenerator.xml

Colt/xml/cern/jet/random/engine/RandomSeedGenerator.xml

Colt/xml/cern/jet/random/engine/RandomSeedTable.xml
30	a m*n matrix, just stored as one-dim array 215 * 2 entries
261	the table is limited; let's snap the unbounded input parameters to the table's actual size.
269	"randomize" the seed (in some ways comparable to hash functions)
271	cycle==0 --> mask = 0
272	cycle==0 --> seed stays unaffected
273	now, each sequence has a period of 10**9 numbers.

Colt/xml/cern/jet/random/Exponential.xml
30	The uniform random number generated shared by all <b>static</b> methods.

Colt/xml/cern/jet/random/ExponentialPower.xml
36	cached vars for method nextDouble(tau) (for performance only)
39	The uniform random number generated shared by all <b>static</b> methods.
63	SET-UP
70	GENERATOR
72	U(0/1)
73	U(-1.0/1.0)
74	u1=|u|
75	U(0/1)
77	Uniform hat-function for x <= (1-1/tau)
80	Exponential hat-function for x > (1-1/tau)
81	U(0/1)
87	Acceptance/Rejection
90	Random sign

Colt/xml/cern/jet/random/Fun.xml
143	while (!NULL) {
171	otherwise numerical integration of the function defined above
178	while (!NULL) {
186	while (!NULL) {
283	long i,prod;  prod = 1; if (n != 0) { for (i = 2; i <= n; i++) prod = i; } return prod;
309	if (x > Math.log(Double.MAX_VALUE)) return Double.MAX_VALUE;

Colt/xml/cern/jet/random/Gamma.xml
55	The uniform random number generated shared by all <b>static</b> methods.
82	Gamma Distribution - Acceptance Rejection combined with Acceptance Complement    FUNCTION:    - gds samples a random number from the standard gamma distribution with parameter  a > 0. Acceptance Rejection  gs  for  a < 1 , Acceptance Complement gd  for  a >= 1 . REFERENCES:  - J.H. Ahrens, U. Dieter (1974): Computer methods for sampling from gamma, beta, Poisson and binomial distributions, Computing 12, 223-246. - J.H. Ahrens, U. Dieter (1982): Generating gamma variates by a modified rejection technique, Communications of the ACM 25, 47-54. SUBPROGRAMS: - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed - NORMAL(seed) ... Normal generator N(0,1).
120	Check for invalid input values
125	CASE A: Acceptance rejection algorithm gs
126	Step 1
129	Step 2. Case gds <= 1
133	Step 3. Case gds > 1
140	CASE B: Acceptance complement algorithm gd (gaussian distribution, box muller transformation)
141	Step 1. Preparations
147	Step 2. Normal deviate
156	Immediate acceptance
158	Step 3. Uniform random number
159	Squeeze acceptance
161	Step 4. Set-up for hat case
184	Step 5. Calculation of q
185	Step 6.
192	Step 7. Quotient acceptance
196	Step 8. Double exponential deviate t
203	Step 9. Rejection of t
204	Step 10. New q(t)
212	Step 11.
219	Step 12. Hat acceptance

Colt/xml/cern/jet/random/Hyperbolic.xml
37	cached values shared for generateHyperbolic(...)
43	The uniform random number generated shared by all <b>static</b> methods.
62	Hyperbolic Distribution - Non-Universal Rejection    FUNCTION   : - hyplc.c samples a random number from the hyperbolic distribution with shape parameter a and b valid for a>0 and |b|<a using the non-universal rejection method for log-concave densities. REFERENCE :  - L. Devroye (1986): Non-Uniform Random Variate Generation, Springer Verlag, New York. SUBPROGRAM : - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed.
82	SET-UP
87	a^2 - b^2
88	-log(f(mode))
89	mode
92	fr^-1(exp(-sqrt(a^2 - b^2) - 1.0))
93	fl^-1(exp(-sqrt(a^2 - b^2) - 1.0))
100	lower border
101	upper border
112	GENERATOR
116	Rejection with a uniform majorizing function over the body of the distribution
122	Rejection with an exponential envelope on the right side of the mode
128	Rejection with an exponential envelope on the left side of the mode

Colt/xml/cern/jet/random/HyperGeometric.xml
44	cached vars shared by hmdu(...) and hprs(...)
48	cached vars for hmdu(...)
52	cached vars for hprs(...)
58	The uniform random number generated shared by all <b>static</b> methods.
78	set-up           */
143	main parameters
145	approximate deviation of reflection points k2, k4 from nu - 1/2
148	mode m, reflection points k2 and k4, and points k1 and k5, which delimit the centre region of h(x) k2 = ceil (nu - 1/2 - U),    k1 = 2*k2 - (m - 1 + delta_ml) k4 = floor(nu - 1/2 + U),    k5 = 2*k4 - (m + 1 - delta_mr)
156	delta_ml = 0
157	delta_mr = 1
159	range width of the critical left and right centre region
163	recurrence constants r(k) = p(k)/p(k-1) at k = k1, k2, k4+1, k5+1
169	reciprocal values of the scale parameters of expon. tail envelopes
170	expon. tail left  //
171	expon. tail right //
173	hypergeom. constant, necessary for computing function values f(k)
176	function values f(k) = p(k)/p(m)  at  k = k2, k4, k1, k5
182	area of the two centre and the two exponential tail regions area of the two immediate acceptance regions between k2, k4
184	immed. left
185	centre left
186	immed. right
187	centre right
188	expon. tail left
189	expon. tail right
193	generate uniform number U -- U(0, p6) case distinction corresponding to U
195	centre left
197	immediate acceptance region R2 = [k2, m) *[0, f2),  X = k2, ... m -1
199	immediate acceptance region R1 = [k1, k2)*[0, f1),  X = k1, ... k2-1
202	computation of candidate X < k2, and its counterpart V > k2 either squeeze-acceptance of X or acceptance-rejection of V
205	quick accept of
206	X = k2 - Dk
208	quick reject of V
210	quick accept of
211	V = k2 + Dk
214	final accept of V
219	centre right
221	immediate acceptance region R3 = [m, k4+1)*[0, f4), X = m, ... k4
223	immediate acceptance region R4 = [k4+1, k5+1)*[0, f5)
226	computation of candidate X > k4, and its counterpart V < k4 either squeeze-acceptance of X or acceptance-rejection of V
229	quick accept of
230	X = k4 + Dk
232	quick reject of V
234	quick accept of
235	V = k4 - Dk
238	final accept of V
245	expon. tail left
247	0 <= X <= k1 - 1
248	Y -- U(0, h(x))
250	quick accept of X
253	expon. tail right
255	k5 + 1 <= X <= n
256	Y -- U(0, h(x))   /
258	quick accept of X
263	acceptance-rejection test of candidate X from the original area test, whether  Y <= f(X),    with  Y = U*h(x)  and  U -- U(0, 1) log f(X) = log( m! (M - m)! (n - m)! (N - M - n + m)! ) - log( X! (M - X)! (n - X)! (N - M - n + X)! ) by using an external function for log k!
287	Hypergeometric Distribution - Patchwork RejectionInversion    The basic algorithms work for parameters 1 <= n <= M <= N2. Otherwise parameters are re-defined in the set-up step and the random number K is adapted before delivering. For l = m-max(0,n-N+M) < 10  Inversion method hmdu is applied: The random numbers are generated via modal down-up search, starting at the mode m. The cumulative probabilities are avoided by using the technique of chop-down. For l >= 10  the Patchwork Rejection method  hprs is employed: The area below the histogram function f(x) in its body is rearranged by certain point reflections. Within a large center interval variates are sampled efficiently by rejection from uniform hats. Rectangular immediate acceptance regions speed up the generation. The remaining tails are covered by exponential functions.    FUNCTION :   - hprsc samples a random number from the Hypergeometric distribution with parameters N (number of red and black balls), M (number of red balls) and n (number of trials) valid for N >= 2, M,n <= N. REFERENCE :  - H. Zechner (1994): Efficient sampling from continuous and discrete unimodal distributions, Doctoral Dissertation, 156 pp., Technical University Graz, Austria. SUBPROGRAMS: - flogfak(k)  ... log(k!) with long integer k - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed. - hmdu(seed,N,M,n) ... Hypergeometric generator for l<10 - hprs(seed,N,M,n) ... Hypergeometric generator for l>=10 with unsigned long integer seed, long integer  N , M , n.

Colt/xml/cern/jet/random/Logarithmic.xml
37	cached vars for method nextDouble(a) (for performance only)
40	The uniform random number generated shared by all <b>static</b> methods.
59	Logarithmic Distribution - InversionTransformation    The algorithm combines Inversion and Transformation. It is based on the following fact: A random variable X from the Logarithmic distribution has the property that X for fixed Y=y is Geometric distributed with P(X=x|Y=y)=(1-y)y^(x-1) () where Y has distribution function F(y)=ln(1-y)ln(1-p). So first random numbers y are generated by simple Inversion, then k=(long int) (1+ln(u)ln(y)) is a Geometric random number and because of () a Logarithmic one. To speed up the algorithm squeezes are used as well as the fact, that many of the random numbers are 1 or 2 (depending on special circumstances). On an IBMPC 486 optimal performance is achieved, if for p<.97 simple inversion is used and otherwise the transformation. On an IBMPC 286 inversion should be restricted to p<.90.    FUNCTION:    - lsk  samples a random number from the Logarithmic distribution with parameter  0 < p < 1 . REFERENCE:   - A.W. Kemp (1981): Efficient generation of logarithmically distributed pseudo-random variables, Appl. Statist. 30, 249-253. SUBPROGRAMS: - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed.
95	Set-up
102	Inversion/Chop-down
106	System.out.println("u="+u+", p="+p);
114	Transformation

Colt/xml/cern/jet/random/NegativeBinomial.xml
38	The uniform random number generated shared by all <b>static</b> methods.
83	Negative Binomial Distribution - Compound method    FUNCTION:    - nbp  samples a random number from the Negative Binomial distribution with parameters r (no. of failures given) and p (probability of success) valid for  r > 0, 0 < p < 1. If G from Gamma(r) then K  from Poiss(pG(1-p)) is NB(r,p)--distributed. REFERENCE:   - J.H. Ahrens, U. Dieter (1974): Computer methods for sampling from gamma, beta, Poisson and binomial distributions, Computing 12, 223--246. SUBPROGRAMS: - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed - Gamma(seed,a) ... Gamma generator for a > 0 unsigned long seed, double a - Poisson(seed,a) ...Poisson generator for a > 0 unsigned long seed, double a.

Colt/xml/cern/jet/random/Normal.xml
47	cache for Box-Mueller algorithm
48	Box-Mueller
50	performance cache
52	The uniform random number generated shared by all <b>static</b> methods.
78	Uses polar Box-Muller transformation.

Colt/xml/cern/jet/random/Poisson.xml
47	precomputed and cached values (for performance only) cache for < SWITCH_MEAN
54	cache for >= SWITCH_MEAN
61	cache for both;
65	for all means larger than that, we don't try to compute a poisson deviation, but return the mean.
66	switch from method A to method B
69	The uniform random number generated shared by all <b>static</b> methods.
109	Poisson Distribution - Patchwork RejectionInversion    For parameter  my < 10  Tabulated Inversion is applied. For my >= 10  Patchwork Rejection is employed: The area below the histogram function f(x) is rearranged in its body by certain point reflections. Within a large center interval variates are sampled efficiently by rejection from uniform hats. Rectangular immediate acceptance regions speed up the generation. The remaining tails are covered by exponential functions.
133	static double p,q,p0,pp[36]; static long ll,m;
138	CASE B: Inversion- start new table and calculate p0
145	for (k=pp.length; --k >=0; ) pp[k] = 0;
149	Step U. Uniform sample
152	Step T. Table comparison
157	Step C. Creation of new prob.
168	end my < SWITCH_MEAN
169	CASE A: acceptance complement
170	static double        my_last = -1.0; static long int      m,  k2, k4, k1, k5; static double        dl, dr, r1, r2, r4, r5, ll, lr, l_my, c_pm, f1, f2, f4, f5, p1, p2, p3, p4, p5, p6;
178	set-up
181	approximate deviation of reflection points k2, k4 from my - 1/2
184	mode m, reflection points k2 and k4, and points k1 and k5, which delimit the centre region of h(x)
191	range width of the critical left and right centre region
195	recurrence constants r(k) = p(k)/p(k-1) at k = k1, k2, k4+1, k5+1
201	reciprocal values of the scale parameters of expon. tail envelopes
202	expon. tail left
203	expon. tail right
205	Poisson constants, necessary for computing function values f(k)
209	function values f(k) = p(k)/p(m) at k = k2, k4, k1, k5
215	area of the two centre and the two exponential tail regions area of the two immediate acceptance regions between k2, k4
217	immed. left
218	centre left
219	immed. right
220	centre right
221	expon. tail left
222	expon. tail right
223	end set-up
226	generate uniform number U -- U(0, p6) case distinction corresponding to U
228	centre left
230	immediate acceptance region R2 = [k2, m) *[0, f2),  X = k2, ... m -1
232	immediate acceptance region R1 = [k1, k2)*[0, f1),  X = k1, ... k2-1
235	computation of candidate X < k2, and its counterpart Y > k2 either squeeze-acceptance of X or acceptance-rejection of Y
238	quick accept of
239	X = k2 - Dk
241	quick reject of Y
243	quick accept of
244	Y = k2 + Dk
246	final accept of Y
250	centre right
251	immediate acceptance region R3 = [m, k4+1)*[0, f4), X = m, ... k4
253	immediate acceptance region R4 = [k4+1, k5+1)*[0, f5)
256	computation of candidate X > k4, and its counterpart Y < k4 either squeeze-acceptance of X or acceptance-rejection of Y
259	quick accept of
260	X = k4 + Dk
262	quick reject of Y
264	quick accept of
265	Y = k4 - Dk
267	final accept of Y
273	expon. tail left
275	0 <= X <= k1 - 1
276	W -- U(0, h(x))
277	quick accept of X
279	expon. tail right
281	X >= k5 + 1
282	W -- U(0, h(x))
283	quick accept of X
287	acceptance-rejection test of candidate X from the original area test, whether  W <= f(k),    with  W = U*h(x)  and  U -- U(0, 1) log f(X) = (X - m)*log(my) - log X! + log m!
293	mean is too large
303	Overflow sensitive: return (Math.pow(mean,k) / cephes.Arithmetic.factorial(k)) * Math.exp(-this.mean);

Colt/xml/cern/jet/random/PoissonSlow.xml
36	precomputed and cached values (for performance only)
41	for all means larger than that, we don't try to compute a poisson deviation, but return the mean.
42	switch from method A to method B
49	The uniform random number generated shared by all <b>static</b> methods.
87	Adapted from "Numerical Recipes in C".
93	not defined
101	bug in CLHEP 1.4.0: was "} while ( product > g );"
117	faster than em = Math.floor(em); (em>=0.0)
122	mean is too large
136	detected endless loop due to rounding errors
145	not defined

Colt/xml/cern/jet/random/sampling/RandomSampler.xml
111	public class RandomSampler extends Object implements java.io.Serializable {
116	static long negalphainv; // just to determine once and for all the best value for negalphainv
156	testNegAlphaInv(args);
173	nothing to do
200	This algorithm is applicable if a large percentage (90%..100%) of N shall be sampled. In such cases it is more efficient than sampleMethodA() and sampleMethodD(). The idea is that it is more efficient to express sample(n,N,count) in terms of reject(N-n,N,count) and then invert the result. For example, sampling 99% turns into sampling 1% plus inversion.  This algorithm is the same as method sampleMethodD(...) with the exception that sampled elements are rejected, and not sampled elements included in the result set.
209	IMPORTANT !!!
213	long threshold;
217	tuning paramter, determines when to switch from method D to method A. Dependent on programming language, platform, etc.
222	threshold = -negalphainv * n;
224	&& threshold<N) {
227	step D2: generate U and X
234	step D3: Accept?
237	break inner loop
239	step D4: Accept?
253	accept !
255	break inner loop
258	end for
260	step D5: reject the (S+1)st record !
261	int iter = (int) (Math.min(S,count));
271	threshold += negalphainv;
272	end while
275	special case n==1
276	reject the (S+1)st record !
279	int iter = (int) (Math.min(S,count));
287	fill the rest
317	rare case treated quickly
324	|| Math.min(count,N-n)>maxTmpMemoryAllowed) {
327	More than 95% of all numbers shall be sampled.
375	special case n==1
404	tuning paramter, determines when to switch from method D to method A. Dependent on programming language, platform, etc.
414	step D2: generate U and X
421	step D3: Accept?
424	break inner loop
426	step D4: Accept?
440	accept !
442	break inner loop
445	end for
447	step D5: select the (S+1)st record !
450	invert for (int iter=0; iter<S && count > 0; iter++) { values[fromIndex++] = ++chosen; count--; } chosen++;
464	end while
468	faster to use method A to finish the sampling
472	special case n==1
493	Log.print("Chunk #"+i+" = ["); for (int j=0; j<chunkSize-1; j++) Log.print(values[j]+", "); Log.print(String.valueOf(values[chunkSize-1])); Log.println("]");
503	sample remaining part, if necessary
506	Log.print("Chunk #"+chunks+" = ["); for (int j=0; j<toDo-1; j++) Log.print(values[j]+", "); Log.print(String.valueOf(values[toDo-1])); Log.println("]");
525	long N = Long.parseLong(args[0]); int chunkSize = Integer.parseInt(args[1]);  long[] alphas = {-104, -52, -26, -13, -8, -4, -2}; for (int i=0; i<alphas.length; i++) { negalphainv = alphas[i]; System.out.println("\n\nnegalphainv="+negalphainv);  System.out.print(" n="+N80+" --> "); test(N80,N,0,chunkSize);  System.out.print(" n="+N40+" --> "); test(N40,N,0,chunkSize);  System.out.print(" n="+N20+" --> "); test(N20,N,0,chunkSize);  System.out.print(" n="+N10+" --> "); test(N10,N,0,chunkSize);  System.out.print(" n="+N5+" --> "); test(N5,N,0,chunkSize);  System.out.print(" n="+N2+" --> "); test(N2,N,0,chunkSize);  System.out.print(" n="+(N-3)+" --> "); test(N-3,N,0,chunkSize); }

Colt/xml/cern/jet/random/sampling/RandomSamplingAssistant.xml
26	public class RandomSamplingAssistant extends Object implements java.io.Serializable {
46	start with the right offset
81	test(n,N);
102	reject
103	reject
105	accept
152	System.out.print("\nElements = ["); for (int i=0; i<N-1; i++) System.out.print(elements[i]+", "); System.out.print(elements[N-1]); System.out.println("]");   System.out.print("\nSample = ["); for (int i=0; i<n-1; i++) System.out.print(sample[i]+", "); System.out.print(sample[n-1]); System.out.println("]");
173	manually inlined
180	reject
184	reject
186	accept

Colt/xml/cern/jet/random/sampling/WeightedRandomSampler.xml
27	public class BlockedRandomSampler extends Object implements java.io.Serializable {
76	reject
82	tuned for speed
88	reject
93	accept
131	manually inlined
135	reject
142	tuned for speed
148	reject
154	accept

Colt/xml/cern/jet/random/Stack.xml
24	indicates stack is empty
26	static stack_t new_stack(int N) { stack_t s; s = (stack_t )malloc(sizeof(stack_t)); s->N = N; s->i = -1;                   indicates stack is empty s->v = (int )malloc(sizeof(int)N); return s; } static void push_stack(stack_t s, int v) { s->i += 1; if ((s->i) >= (s->N)) { fprintf(stderr,"Cannot push stack!\n"); exit(0);                 fatal!! } (s->v)[s->i] = v; } static int pop_stack(stack_t s) { if ((s->i) < 0) { fprintf(stderr,"Cannot pop stack!\n"); exit(0); } s->i -= 1; return ((s->v)[s->i + 1]); } static inline int size_stack(const stack_t s) { return s->i + 1; } static void free_stack(stack_t s) { free((char )(s->v)); free((char )s); }

Colt/xml/cern/jet/random/StudentT.xml
41	performance cache for pdf()
42	The uniform random number generated shared by all <b>static</b> methods.
72	The polar method of BoxMuller for generating Normal variates is adapted to the Student-t distribution. The two generated variates are not independent and the expected no. of uniforms per variate is 2.5464.  REFERENCE :  - R.W. Bailey (1994): Polar generation of random variates with the t-distribution, Mathematics of Computation 62, 779-781.

Colt/xml/cern/jet/random/Uniform.xml
28	The uniform random number generated shared by all <b>static</b> methods.
101	Doing the thing turns out to be more tricky than expected. avoids overflows and underflows. treats cases like from=-1, to=1 and the like right. the following code would NOT solve the problem: return (long) (Doubles.randomFromTo(from,to));  rounding avoids the unsymmetric behaviour of casts from double to long: (long) -0.7 = 0, (long) 0.7 = 0. checking for overflows and underflows is also necessary.
110	first the most likely and also the fastest case.
115	would we get a numeric overflow? if not, we can still handle the case rather efficient.
122	now the pathologic boundary cases. they are handled rather slow.
127	return Math.round(nextDoubleFromTo(from,to));

Colt/xml/cern/jet/random/VonMises.xml
37	cached vars for method nextDouble(a) (for performance only)
41	The uniform random number generated shared by all <b>static</b> methods.
63	Von Mises Distribution - Acceptance Rejection    FUNCTION :  - mwc samples a random number from the von Mises distribution ( -Pi <= x <= Pi) with parameter k > 0  via  rejection from the wrapped Cauchy distibution. REFERENCE:  - D.J. Best, N.I. Fisher (1979): Efficient simulation of the von Mises distribution, Appl. Statist. 28, 152-157. SUBPROGRAM: - drand(seed) ... (0,1)-Uniform generator with unsigned long integer seed.  Implemented by F. Niederl, August 1992
85	SET-UP
92	GENERATOR
94	U(0/1)
95	U(0/1)
99	Acceptance/Rejection
101	Random sign //
102	0 <= x <= Pi : -Pi <= x <= 0 //

Colt/xml/cern/jet/random/Zeta.xml
41	cached values (for performance)
45	The uniform random number generated shared by all <b>static</b> methods.
58	Zeta Distribution - Acceptance Rejection    To sample from the Zeta distribution with parameters ro and pk it suffices to sample variates x from the distribution with density function  f(x)=B{[x+0.5]+pk}^(-(1+ro)) ( x > .5 ) and then deliver k=[x+0.5]. 1B=Sum[(j+pk)^-(ro+1)]  (j=1,2,...) converges for ro >= .5 . It is not necessary to compute B, because variates x are generated by acceptance rejection using density function g(x)=ro(c+0.5)^ro(c+x)^-(ro+1).  Integer overflow is possible, when ro is small (ro <= .5) and pk large. In this case a new sample is generated. If ro and pk satisfy the inequality   ro > .14 + pk1.85e-8 + .02ln(pk) the percentage of overflow is less than 1%, so that the result is reliable. NOTE: The comment above is likely to be nomore valid since the C-version operated on 32-bit integers, while this Java version operates on 64-bit integers. However, the following is still valid:  If either ro > 100  or  k > 10000 numerical problems in computing the theoretical moments arise, therefore ro<=100 and k<=10000 are recommended.    FUNCTION:    - zeta  samples a random number from the Zeta distribution with parameters  ro > 0  and pk >= 0. REFERENCE:   - J. Dagpunar (1988): Principles of Random Variate  Generation, Clarendon Press, Oxford.
99	Set-up

Colt/xml/cern/jet/stat/Descriptive.xml
79	Both covariance versions yield the same results but the one above is faster
74	Exercise for the reader: Why does this give us the right answer?
145	determine run length (number of equal elements)
163	this version would easily results in overflows return Math.pow(product, 1/size);
224	read current values
239	double oldDeviation = element - mean; mean += oldDeviation  (N+1); sumSquaredDeviations += (element-mean)oldDeviation;  cool, huh?
245	double oldMean = mean; mean += (element - mean)(N+1); if (N > 0) { sumSquaredDeviations += (element-mean)(element-oldMean);  cool, huh? }
255	store new values
261	At this point of return the following postcondition holds: data.size()-from elements have been consumed by this call.
306	optimized for common parameters
307	handle quicker
316	if (element < min) min = element; else if (element > max) max = element;
333	if (element < min) min = element; else if (element > max) max = element;
341	handle quicker
353	if (element < min) min = element; else if (element > max) max = element;
364	handle quicker
372	now the most general case: optimized for maximum speed, but still not quite quick
388	At this point of return the following postcondition holds: data.size()-fromIndex elements have been consumed by this call.
429	read current values
445	store new values
449	At this point of return the following postcondition holds: data.size()-from elements have been consumed by this call.
527	double[] sortedElements = sortedData.elements(); int n = sortedData.size(); int lhs = (n - 1)  2 ; int rhs = n  2 ;  if (n == 0) return 0.0 ;  double median; if (lhs == rhs) median = sortedElements[lhs] ; else median = (sortedElements[lhs] + sortedElements[rhs])2.0 ;  return median;
575	sum += sign *
579	for (int i=0; i<=k; i++) { sum += sign  cern.jet.math.Arithmetic.binomial(k,i)  Math.pow(c, i)  sumOfPowers[k-i]; sign = -sign; }
709	element found
710	skip to the right over multiple occurances of element.
717	element not found
723	linear interpolation
751	(y-ymean)^2/(n-1)
752	(y-ymean)^4
788	sqrt( (y-ymean)^2/(n-1) )
789	(y-ymean)^3
825	The standard deviation calculated as the sqrt of the variance underestimates the unbiased standard deviation.
828	It needs to be multiplied by this correction factor.
830	Cn = 1+1/(4*(n-1));
856	find the sum of the squares
906	assertion: data is sorted ascending. assertion: splitValues is sorted ascending.
919	splitValue not found
924	splitValue found
925	For multiple identical elements ("runs"), binarySearch does not define which of all valid indexes is returned. Thus, skip over to the first element of a run.
937	now fill the remainder
1009	optimized for speed

Colt/xml/cern/jet/stat/Gamma.xml
82	double MAXGAM = 171.624376956302725; double LOGPI  = 1.14472988584940017414;
203	Multiply w by the factor a      b   _             _     _
553	if( x > 1.0e8 ) return( q );

Colt/xml/cern/jet/stat/Probability.xml
51	Approximation for interval z = sqrt(-2 log y ) between 2 and 8 i.e., y between exp(-2) = .135 and exp(-32) = 1.27e-14.
77	Approximation for interval z = sqrt(-2 log y ) between 8 and 64 i.e., y between exp(-32) = 1.27e-14 and exp(-2048) = 3.67e-890.
287	1.00000000000000000000E0,
337	1.0
357	1.00000000000000000000E0,
693	fixes bug reported by stefan.bentink@molgen.mpg.de
711	Cumulative probability
716	Cumulative probability
719	Return inverse of normal for large size
724	Find a pair of x1,x2 that braket zero
736	Find better approximation Pegasus-method
739	Calculate slope of secant and t value for which it is 0.
743	Calculate function value at x3
745	This criteria needs to be very tight!
746	We found a perfect value -> return

Colt/xml/cern/jet/stat/quantile/Buffer.xml

Colt/xml/cern/jet/stat/quantile/BufferSet.xml

Colt/xml/cern/jet/stat/quantile/DoubleBuffer.xml
32	lazy buffer allocation can safe memory.
40	lazy buffer allocation can safe memory.
118	IMPORTANT: TO DO : replace mergeSort with quickSort! currently it is mergeSort only for debugging purposes (JDK 1.2 can't be imported into VisualAge).
121	values.mergeSort();
133	", v=" + values.toString();

Colt/xml/cern/jet/stat/quantile/DoubleBufferSet.xml
17	tmp var only
47	count buffers
53	collect buffers
69	count buffers
75	collect buffers
163	determine W
164	sum of all weights
167	determine outputTriggerPositions
172	do the main work: determine values at given positions in sorted sequence
175	mark all full buffers as empty, except the first, which will contain the output
216	if (buffers.length==0) { throw new IllegalArgumentException("Oops! buffer.length==0."); }
221	System.out.println("triggers="+cern.it.util.Arrays.toString(positions));
223	new DoubleArrayList(outputValues).fillFromToWith(0, outputValues.length-1, 0.0f); delte the above line, it is only for testing
226	cern.it.util.Log.println("\nEntering getValuesAtPositions..."); cern.it.util.Log.println("hitPositions="+cern.it.util.Arrays.toString(positions));
229	sort buffers.
234	collect some infos into fast cache; for tuning purposes only.
242	cern.it.util.Log.println("buffer["+i+"]="+buffers[i].values);
245	prepare merge of equi-distant elements within buffers into output values
247	first collect some infos into fast cache; for tuning purposes only.
251	now prepare the important things.
252	current position in collapsed values
253	current position in each buffer; init with zeroes
254	current position in sorted sequence
255	next position in sorted sequence to trigger output population
259	nothing to output, because no elements have been filled (we are empty). return meaningless values
267	fill all output values with equi-distant elements.
269	System.out.println("\nj="+j); System.out.println("counter="+counter); System.out.println("nextHit="+nextHit);
273	determine buffer with smallest value at cursor position.
278	DoubleBuffer buffer = buffers[b]; if (cursors[b] < buffer.length) {
281	/double value = buffer.values[cursors[b]];
292	trigger copies into output sequence, if necessary.
296	System.out.println("adding to output="+minValue);
301	that element has now been treated, move further.
303	System.out.println("cursors="+cern.it.util.Arrays.toString(cursors));
305	end while (j<k)
307	cern.it.util.Log.println("returning output="+cern.it.util.Arrays.toString(outputValues));
335	is W odd?
339	W is even
340	alternate between both possible next hit positions upon successive invocations

Colt/xml/cern/jet/stat/quantile/DoubleQuantileEstimator.xml
17	abstract class ApproximateDoubleQuantileFinder extends Object implements DoubleQuantileFinder {
34	System.out.println("adding "+value);
59	the obvious version, but we can do quicker... double[] theValues = values.elements(); int theSize=values.size(); for (int i=0; i<theSize; ) add(theValues[i++]);
77	full
87	full
195	check parameter DoubleArrayList sortedPhiList = phis.copy(); sortedPhiList.sort(); if (! phis.equals(sortedPhiList)) { throw new IllegalArgumentException("Phis must be sorted ascending."); }
204	System.out.println("starting to augment missing values, if necessary...");
214	System.out.println("triggerPositions="+cern.colt.Arrays.toString(triggerPositions)); System.out.println("starting to determine quantiles..."); System.out.println(bufferSet);
221	do the main work: determine values at given positions in sorted sequence

Colt/xml/cern/jet/stat/quantile/DoubleQuantileFinder.xml
19	public interface DoubleQuantileFinder extends com.objy.db.iapp.PersistentEvents, java.io.Serializable {

Colt/xml/cern/jet/stat/quantile/EquiDepthHistogram.xml
48	element found.
49	last bin is a closed interval.
52	element not found.
53	index = -index-1; now index is the insertion point.
97	int index = new FloatArrayList(binBoundaries).binarySearch(element);
98	found
102	do linear interpolation

Colt/xml/cern/jet/stat/quantile/ExactDoubleQuantileFinder.xml
20	class ExactDoubleQuantileFinder extends Object implements DoubleQuantileFinder {
122	int bufferSize = (int) this.size(); double[] quantileElements = new double[phis.size()]; for (int i=phis.size(); --i >=0;) { int rank=(int)Utils.epsilonCeiling(phis.get(i)bufferSize) -1; quantileElements[i]=buffer.get(rank); } return new DoubleArrayList(quantileElements);
143	IMPORTANT: TO DO : replace mergeSort with quickSort! currently it is mergeSort because JDK 1.2 can't be imported into VisualAge.
146	this.buffer.mergeSort();

Colt/xml/cern/jet/stat/quantile/KnownDoubleQuantileEstimator.xml
42	correction factor for phis
47	see method sampleNextElement()
48	see method sampleNextElement()
77	switch off sampler
78	double[] infinities = new double[missingInfinities];
85	if (even) {infinities[i]=Double.MAX_VALUE;} else	  {infinities[i]=-Double.MAX_VALUE;}
88	if (even) {this.add(Double.MAX_VALUE);} else	  {this.add(-Double.MAX_VALUE);}
93	buffer.values.addAllOfFromTo(new DoubleArrayList(infinities),0,missingInfinities-1);
95	this.totalElementsFilled -= infinities;
97	switch on sampler again
114	this.setSamplingRate(samplingRate,N);
136	DoubleBuffer[] emptyBuffers = this.bufferSet._getEmptyBuffers();
146	for (int i=0; i<emptyBuffers.length; i++) { emptyBuffers[i].level = 0; }
152	currentBufferToFill.state = DoubleBuffer.PARTIAL;
178	The KNOWN quantile finder reads off quantiles from FULL buffers only. Since there might be a partially full buffer, this method first satisfies this constraint by temporarily filling a few +infinity, -infinity elements to make up a full block. This is in full conformance with the explicit approximation guarantees.  For those of you working on online apps: The approximation guarantees are given for computing quantiles AFTER N elements have been filled, not for intermediate displays. If you have one thread filling and another thread displaying concurrently, you will note that in the very beginning the infinities will dominate the display. This could confuse users, because, of course, they don't expect any infinities, even if they "disappear" after a short while. To prevent panic exclude phi's close to zero or one in the early phases of processing.
191	any auxiliary infinities needed?
195	System.out.println("adding "+missingValues+" infinity elements...");
198	determine beta (N + Infinity values = beta * N)
207	restore state we were in before. remove the temporarily added infinities.
211	now you can continue filling the remaining values, if any.
226	count them (this is not very clever but it's safe)
236	this.totalElementsFilled -= infinities;
244	This is a KNOWN N quantile finder! One should not try to fill more than N elements, because otherwise we can't give explicit approximation guarantees anymore. Use an UNKNOWN quantile finder instead if your app may fill more than N elements.  However, to make this class meaningful even under wired use cases, we actually do allow to fill more than N elements (without explicit approx. guarantees, of course). Normally, elements beyond N will not get sampled because the sampler is exhausted. Therefore the histogram will no more change no matter how much you fill. This might not be what the user expects. Therefore we use a new (unexhausted) sampler with the same parametrization.  If you want this class to ignore any elements beyong N, then comment the following line.
258	if ((totalElementsFilled-1) % N == 0) setSamplingRate(samplingRate, N); // delete if appropriate

Colt/xml/cern/jet/stat/quantile/Quantile1Test.xml
25	Get the number of examples from the first argument
39	Get N from the second argument
59	Set up the QuantileBin1D object
75	Use a new random number generator to generate numExamples random gaussians, and add them to the QuantileBin1D
86	print out the percentiles
91	int step = 1;

Colt/xml/cern/jet/stat/quantile/QuantileCalc.xml
25	since binomial(n,k)==binomial(n,n-k), we can enforce the faster variant, which is also the variant minimizing number overflows.
75	no way around exact quantile search
88	for each b, determine maximum height, i.e. the height for which x<=0 and x is a maximum with x = binomial(b+h-2, h-1) - binomial(b+h-3, h-3) + binomial(b+h-3, h-2) - N * epsilon * 2.0
93	skip heights until x<=0
99	from now on x is monotonically growing...
100	skip heights until x>0
106	go back to last height
108	was x>0 or did we loop without finding anything?
121	safe some space
122	end for
125	for each b, determine the smallest k satisfying the constraints, i.e. for each b, determine kMin, with kMin = N/binomial(b+hMax-2,hMax-1)
141	from all b's, determine b that minimizes b*kMin
155	epsilon large enough?
159	epsilon is very small or zero.
160	the only possible solution without violating the
161	approximation guarantees is exact quantile search.
182	delta can be set to zero, i.e., all quantiles should be approximate with probability 1
184	no way around exact quantile search
197	One possibility is to use one buffer of size N
205	Otherwise, there are at least two buffers (b >= 2) and the height of the tree is at least three (h >= 3)  We restrict the search for b and h to MAX_BINOM, a large enough value for practical values of    epsilon >= 0.001   and    delta >= 0.00001
231	From our SIGMOD 98 paper, we have two equantions to satisfy: t  <= u * alpha/(1-alpha)^2 kv >= w/(1-alpha)^2  Denoting 1/(1-alpha)    by x, we see that the first inequality is equivalent to t/u <= x^2 - x which is satisfied by x >= 0.5 + 0.5 * sqrt (1 + 4t/u) Plugging in this value into second equation yields k >= wx^2/v
337	delta can be set to zero, i.e., all quantiles should be approximate with probability 1
339	no way around exact quantile search
359	double logDelta =  Math.log(2.0/(quantiles*delta)) / (2.0*epsilon*epsilon);
361	until we find a solution
362	identify that combination of b and h that minimizes b*k. exhaustive search.
369	now we have k>=c*(1-alpha)^-2. let's compute c. double c = Math.log(2.0/(delta/quantiles)) / (2.0*epsilon*epsilon*Math.min(Ld, 8.0*Ls/3.0));
374	now we have k>=d/alpha. let's compute d.
380	double d = (Ld(h+max_H-1.0)  +  Ls((h+1)pow - 2.0(h+max_H)))      (Ld + Ls(pow-2.0)); d = (d + 2.0)  (2.0epsilon);
385	now we have c*(1-alpha)^-2 == d/alpha. we solve this equation for alpha yielding two solutions alpha_1,2 = (c + 2*d  +-  Sqrt(c*c + 4*c*d))/(2*d)
389	non real solution to equation
394	any alpha must satisfy 0<alpha<1 to yield valid solutions
402	take the alpha that minimizes d/alpha
409	now we have k=Ceiling(Max(d/alpha, (h+1)/(2*epsilon)))
411	valid solution?
414	found a solution requiring less memory
422	end for h
423	end for b
427	no solution found so far. very unlikely. Anyway, try again.
432	end while
436	no solution found. no way around exact quantile search.

Colt/xml/cern/jet/stat/quantile/QuantileFinderFactory.xml
115	no way around exact quantile search
122	can make any error we wish
149	for each b, determine maximum height, i.e. the height for which x<=0 and x is a maximum with x = binomial(b+h-2, h-1) - binomial(b+h-3, h-3) + binomial(b+h-3, h-2) - N * epsilon * 2.0
154	skip heights until x<=0
160	from now on x is monotonically growing...
161	skip heights until x>0
167	go back to last height
169	was x>0 or did we loop without finding anything?
182	safe some space
183	end for
186	for each b, determine the smallest k satisfying the constraints, i.e. for each b, determine kMin, with kMin = N/binomial(b+hMax-2,hMax-1)
202	from all b's, determine b that minimizes b*kMin
216	epsilon large enough?
220	epsilon is very small or zero.
221	the only possible solution without violating the
222	approximation guarantees is exact quantile search.
247	One possibility is to use one buffer of size N
255	Otherwise, there are at least two buffers (b >= 2) and the height of the tree is at least three (h >= 3)  We restrict the search for b and h to MAX_BINOM, a large enough value for practical values of    epsilon >= 0.001   and    delta >= 0.00001
281	From our SIGMOD 98 paper, we have two equantions to satisfy: t  <= u * alpha/(1-alpha)^2 kv >= w/(1-alpha)^2  Denoting 1/(1-alpha)    by x, we see that the first inequality is equivalent to t/u <= x^2 - x which is satisfied by x >= 0.5 + 0.5 * sqrt (1 + 4t/u) Plugging in this value into second equation yields k >= wx^2/v
327	boolean known_N = true; if (N==Long.MAX_VALUE) known_N = false; check parameters. if they are illegal, keep quite and return an exact finder.
355	if (N==Long.MAX_VALUE) { // no maximum N provided by user.
357	if (true) fixes bug reported by LarryPeranich@fairisaac.com
358	no maximum N provided by user.
363	determine whether UnknownFinder or KnownFinder with maximum N requires less memory.
366	IMPORTANT: for known finder, switch sampling off (delta == 0) !!! with knownN-sampling we can only guarantee the errors if the input sequence has EXACTLY N elements. with knownN-no sampling we can also guarantee the errors for sequences SMALLER than N elements.
374	the KnownFinder is smaller
379	the UnknownFinder is smaller
405	move stuff from _raw(..) here and delete _raw(...)
407	long[] result_1 = unknown_N_compute_B_and_K_raw(epsilon,delta,quantiles); long b1 = result_1[0]; long k1 = result_1[1];   int quantilesToPrecompute = (int) Doubles.ceiling(1.0  epsilon);  if (quantiles>quantilesToPrecompute) { try if precomputing quantiles requires less memory. long[] result_2 = unknown_N_compute_B_and_K_raw(epsilon2.0,delta,quantilesToPrecompute);  long b2 = result_2[0]; long k2 = result_2[1]; if (b2k2 < b1k1) { result_2[3] = 1; precomputation is better result_1 = result_2; } } return result_1;
440	delta can be set to zero, i.e., all quantiles should be approximate with probability 1
450	can make any error we wish
459	no way around exact quantile search
480	double logDelta =  Math.log(2.0/(quantiles*delta)) / (2.0*epsilon*epsilon);
482	until we find a solution
483	identify that combination of b and h that minimizes b*k. exhaustive search.
490	now we have k>=c*(1-alpha)^-2. let's compute c. double c = Math.log(2.0/(delta/quantiles)) / (2.0*epsilon*epsilon*Math.min(Ld, 8.0*Ls/3.0));
495	now we have k>=d/alpha. let's compute d.
501	double d = (Ld(h+max_H-1.0)  +  Ls((h+1)pow - 2.0(h+max_H)))      (Ld + Ls(pow-2.0)); d = (d + 2.0)  (2.0epsilon);
506	now we have c*(1-alpha)^-2 == d/alpha. we solve this equation for alpha yielding two solutions alpha_1,2 = (c + 2*d  +-  Sqrt(c*c + 4*c*d))/(2*d)
510	non real solution to equation
515	any alpha must satisfy 0<alpha<1 to yield valid solutions
523	take the alpha that minimizes d/alpha
530	now we have k=Ceiling(Max(d/alpha, (h+1)/(2*epsilon)))
532	valid solution?
535	found a solution requiring less memory
543	end for h
544	end for b
548	no solution found so far. very unlikely. Anyway, try again.
553	end while
558	no solution found. no way around exact quantile search.

Colt/xml/cern/jet/stat/quantile/QuantileFinderTest.xml
27	not found
44	System.out.println("\n"); System.out.println("s="+size+", rank="+rank+", phi="+phi+", eps="+Math.abs((rank)/s - phi)); System.out.println("\n");
65	testQuantileCalculation(args); testCollapse();
78	System.out.println("exactRank="+exactRank);
79	just to ensure exactFinder is sorted
81	System.out.println("approxElem="+approxElement);
121	String b="5";
144	String delta = "0.0001";
160	boolean known_N; if (args==null) known_N = false; else known_N = new Boolean(args[0]).booleanValue();
165	int[] quantiles = {1,100,10000};
170	double[] deltas = {0.0, 0.001, 0.00001, 0.000001};
172	double[] epsilons = {0.0, 0.01, 0.001, 0.0001, 0.00001};
177	if (! known_N) sizes = new long[] {0};
179	if (known_N) System.out.println("Computing b's and k's for KNOWN N"); else System.out.println("Computing b's and k's for UNKNOWN N");
207	System.out.println(finder.getClass().getName());
208	double[] returnSamplingRate = new double[1]; long[] result; if (known_N) { result = QuantileFinderFactory.known_N_compute_B_and_K(N, epsilon, delta, p, returnSamplingRate); } else { result = QuantileFinderFactory.unknown_N_compute_B_and_K(epsilon, delta, p); long b1 = result[0]; long k1 = result[1];  if (N>=0) { long[] resultKnown = QuantileFinderFactory.known_N_compute_B_and_K(N, epsilon, delta, p, returnSamplingRate); long b2 = resultKnown[0]; long k2 = resultKnown[1];  if (b2  k2 < b1  k1) {  the KnownFinder is smaller result = resultKnown; } } }   long b = result[0]; long k = result[1];
237	else if (mem==0 && !known_N && N<0) mem = Long.MAX_VALUE; // actually infinity else if (mem==0 && !known_N && N>=0) mem = N; System.out.print("         (e,d,N,p)=("+epsilon+","+delta+","+N+","+p+") --> ");
241	System.out.print("(mem,b,k,memF");
243	if (known_N) System.out.print(",sampling"); System.out.print(")=("+(Math.round(b*k/1000.0))+","+b+","+k+", "+Math.round(b*k*8/1024.0/1024.0)); System.out.print(")=("+b*k/1000.0+","+b+","+k+", "+b*k*8/1024.0/1024.0+", "+Math.round(b*k*8/1024.0/1024.0));
247	if (known_N) System.out.print(","+returnSamplingRate[0]);
264	Timer timer = new Timer().start(); for (int i=0; i<size; i++) { for (int j=0; j<size; j++) { DoubleBuffer buffer=null; int val=10; double f=1.0f; } } System.out.println(timer.stop());
299	cern.it.util.Log.enableLogging(args[3].equals("log"));
314	int quantiles = phis.length;
322	new UnknownApproximateDoubleQuantileFinder(b,k); approxFinder = new ApproximateDoubleQuantileFinder(b,k);
324	double[] returnSamplingRate = new double[1]; long[] result = ApproximateQuantileFinder.computeBestBandK(sizechunks, epsilon, delta, quantiles, returnSamplingRate); approxFinder = new ApproximateQuantileFinder((int) result[0], (int) result[1]); System.out.println("epsilon="+epsilon); System.out.println("delta="+delta); System.out.println("samplingRate="+returnSamplingRate[0]);
350	System.out.println("unshuffled="+list);
357	System.out.println("shuffled="+list); list.sort(); System.out.println("sorted="+list);
373	System.out.println("free="+Runtime.getRuntime().freeMemory()); System.out.println("total="+Runtime.getRuntime().totalMemory());
378	approxFinder.close();
386	System.out.println("MaxLevel of full buffers="+maxLevelOfFullBuffers(approxFinder.bufferSet));
388	System.out.println("total buffers filled="+ approxFinder.totalBuffersFilled); System.out.println("free="+Runtime.getRuntime().freeMemory()); System.out.println("total="+Runtime.getRuntime().totalMemory());
398	exactFinder.close();
405	double[] errors1 = errors1(exactQuantiles.elements(), approxQuantiles.elements()); System.out.println("Error1="+new DoubleArrayList(errors1));
408	final DoubleArrayList buffer = new DoubleArrayList((int)exactFinder.size()); exactFinder.forEach( new cern.colt.function.DoubleFunction() { public void apply(double element) { buffer.add(element); } } );
438	System.out.println(rankOfWithin(5.0f, list));

Colt/xml/cern/jet/stat/quantile/UnknownDoubleQuantileEstimator.xml
69	if there is only one buffer at the lowest level, then increase its level so that there are at least two at the lowest level.
110	delta for unknown finder
126	if (phis.size() > quantilesToPrecompute) { illegal use case! we compute results, but loose explicit approximation guarantees. return super.quantileElements(phis); }
134	select that quantile from the precomputed set that corresponds to a position closest to phi.
139	finds closest

Colt/xml/cern/jet/stat/quantile/Utils.xml

Colt/xml/corejava/Format.xml
643	one of cdeEfgGiosxXos
101	0 = prefix, 1 = flags, 2 = width, 3 = precision, 4 = format, 5 = end
287	integer part
288	fractional part
289	exponent of fractional part
290	0 = int part, 1 = frac part
486	regression test to confirm fix of reported bugs
502	2000-06-09
563	remove trailing zeroes and decimal point
570	fractional part
581	CSH 10-25-97
605	2000-06-09

Colt/xml/hep/aida/bin/AbstractBin.xml
111	buf.append("\nValue: "+value()); buf.append("\nError: "+error()); buf.append("\nRMS: "+rms()+"\n");

Colt/xml/hep/aida/bin/AbstractBin1D.xml
152	buf.append("\nValue: "+value()); buf.append("\nError(0): "+error(0));

Colt/xml/hep/aida/bin/BinBinFunction1D.xml

Colt/xml/hep/aida/bin/BinFunction1D.xml

Colt/xml/hep/aida/bin/BinFunctions1D.xml

Colt/xml/hep/aida/bin/DynamicBin1D.xml
35	Never ever use "this.size" as it would be intuitive! This class abuses "this.size". "this.size" DOES NOT REFLECT the number of elements contained in the receiver! Instead, "this.size" reflects the number of elements incremental stats computation has already processed.
54	cached parameters protected double skew = 0.0; protected double kurtosis = 0.0;
59	cache states
62	protected boolean isSkewValid = true; protected boolean isKurtosisValid = true;
67	protected boolean isSumOfPowersValid = true;
149	this.skew = 0.0; this.kurtosis = 0.0;
202	safe since we are already synchronized.
301	cern.colt.map.OpenDoubleIntHashMap.hashCollisions = 0; fill a map that collects frequencies
304	cern.colt.Timer timer = new cern.colt.Timer().start();
307	double element = i; // benchmark only TODO double element = i%1000;  benchmark only TODO
311	timer.stop(); System.out.println("filling map took = "+timer); System.out.println("collisions="+cern.colt.map.OpenDoubleIntHashMap.hashCollisions);
342	this.isSkewValid = false; this.isKurtosisValid = false;
379	currently no caching for this parameter
443	without
450	with
585	since "resamples" can be quite large, we care about performance and memory
590	prepare auxiliary bins and buffers
600	resampling steps
625	if (size() > 0) throw new RuntimeException("must be called before starting to add elements.");
635	Never ever use "this.size" as it would be intuitive! This class abuses "this.size". "this.size" DOES NOT REFLECT the number of elements contained in the receiver! Instead, "this.size" reflects the number of elements incremental stats computation has already processed.
650	Call updateIncrementalStats() because after sorting we no more know what elements are still to be done by updateIncrementalStats() and would therefore later need to rebuild incremental stats from scratch.
671	safe since we are already synchronized.
739	no chaching for this measure
759	don't cause unintended floods
789	no caching for this parameter.
812	prepare arguments
821	store the new parameters back
828	next time we don't need to redo the stuff we have just done...
854	this.isSkewValid = true; this.isKurtosisValid = true;

Colt/xml/hep/aida/bin/MightyStaticBin1D.xml
17	Sum( Log(x[i]) )
20	Sum( 1/x[i] )
22	Sum( x[i]^3 ) .. Sum( x[i]^max_k )
65	int max_k = this.min_k + this.sumOfPowers.length-1;
140	order 0..2 is always recorded. order 0 is size() order 1 is sum() order 2 is sum_xx()
220	checkOrder(k);
250	if (max_k < ) throw new IllegalArgumentException();
274	if (! this.hasSumOfInversions) throw new IllegalOperationException("You must specify upon instance construction that the sum of inversions shall be computed.");
284	if (! this.hasSumOfLogarithms) throw new IllegalOperationException("You must specify upon instance construction that the sum of logarithms shall be computed.");
295	checkOrder(k);
320	don't print tons of measures
344	if (! isLegalOrder(k)) return Double.NaN; if (! xisLegalOrder(k)) throw new IllegalOperationException("Illegal order of sum of powers: k="+k+". Upon instance construction legal range was fixed to be "+getMinOrderForSumOfPowers()+" <= k <= "+getMaxOrderForSumOfPowers());

Colt/xml/hep/aida/bin/QuantileBin1D.xml
814	percentages = [p0, p1, p2, ..., p(size-2), p(size-1)] defines bins [p0,p1), [p1,p2), ..., [p(size-2),p(size-1)) each bin is divided into k equi-percent-distant sub bins (subintervals). e.g. k = 2 means "compute" with a resolution (accuracy) of 2 subbins (subintervals) per bin,  percentages = [0.1, 0.2, 0.3, ..., 0.9, 1.0] means bin 0 holds the first 0.1-0.0=10% of the sorted elements, bin 1 holds the next  0.2-0.1=10% of the sorted elements, ...  bins =          [0.1, 0.2), [0.2, 0.3), ..., [0.9, 1.0) subBins = [0.1,    0.15,     0.2,     0.25,    0.3,    ....]  [0.1, 0.15) [0.15, 0.2)             [0.3, 0.35) [0.35, 0.4)  [0.2, 0.25) [0.25, 0.3)
840	construct subintervals
852	compute quantile elements;
855	collect summary statistics for each bin. one bin's statistics are the integrated statistics of its subintervals.
859	don't compute tons of measures
863	for each bin
878	integrate all subintervals
899	example: bin(0) contains (0.2-0.1) == 10% of all elements
904	fill statistics
916	double binMean = binSum  binSize; System.out.println("size="+binSize); System.out.println("min="+binMin); System.out.println("max="+binMax); System.out.println("mean="+binMean); System.out.println("sum_x="+binSum); System.out.println("sum_xx="+binSumOfSquares); System.out.println("rms="+Math.sqrt(binSumOfSquares  binSize)); System.out.println();
956	buf.append("10%, 25%, 50%, 75%, 90% Quantiles: "+quantile(0.1) + ", "+ quantile(0.25) + ", "+ quantile(0.5) + ", " + quantile(0.75) + ", " + quantile(0.9));

Colt/xml/hep/aida/bin/StaticBin1D.xml
34	cached parameters
35	Min( x[i] )
36	Max( x[i] )
37	Sum( x[i] )
38	Sum( x[i]*x[i] )
66	prototyping implementation; inefficient; TODO
68	sumSquares += element  element; if (this.done == 0) {  initial setup this.min = element; this.max = element; } else { if (element < this.min) this.min = element; if (element > this.max) this.max = element;  double oldMean = this.mean; this.mean += (element - this.mean)(done+1); this.sumsq += (element-this.mean)(element-oldMean);  cool, huh? } this.done++;
94	if (this.arguments == null) setUpCache();
96	prepare arguments
104	store the new parameters back

Colt/xml/hep/aida/IAxis.xml

Colt/xml/hep/aida/IHistogram.xml

Colt/xml/hep/aida/IHistogram1D.xml

Colt/xml/hep/aida/IHistogram2D.xml

Colt/xml/hep/aida/IHistogram3D.xml

Colt/xml/hep/aida/ref/AbstractHistogram1D.xml
36	return entries[xAxis.under] + entries[xAxis.over];
85	return heights[xAxis.under] + heights[xAxis.over];

Colt/xml/hep/aida/ref/AbstractHistogram2D.xml
146	return internalSliceX(newTitle,yAxis.under,yAxis.over);
152	return internalSliceY(newTitle,xAxis.under,xAxis.over);
157	int start = yAxis.map(indexY);
164	int start = yAxis.map(indexY1); int stop = yAxis.map(indexY2);
173	int start = xAxis.map(indexX);
180	int start = xAxis.map(indexX1); int stop = xAxis.map(indexX2);

Colt/xml/hep/aida/ref/AbstractHistogram3D.xml

Colt/xml/hep/aida/ref/Converter.xml
141	"X";
143	{hep.aida.bin.BinFunctions1D.sum};
145	String format = "%1.2G";
166	cern.colt.matrix.DoubleMatrix2D errors = new cern.colt.matrix.impl.DenseDoubleMatrix2D(1,h.xAxis().bins()); errors.viewRow(0).assign(toArrayErrors(h));
173	+ sep + "Errors:" + sep + new cern.colt.matrix.doublealgo.Formatter().toTitleString( errors,yEdges,xEdges,rowAxisName,columnAxisName,null,aggr);
189	String format = "%1.2G";
215	keep coord. system
218	keep the histo coord. system
219	heights = heights.viewPart(1,1,heights.rows()-2,heights.columns()-2); // ignore under&overflows
221	cern.colt.matrix.DoubleMatrix2D errors = new cern.colt.matrix.impl.DenseDoubleMatrix2D(toArrayErrors(h)); errors = errors.viewDice().viewRowFlip();  keep the histo coord system errors = errors.viewPart(1,1,errors.rows()-2,errors.columns()-2);  ignore under&overflows
229	+ sep + "Errors:" + sep + new cern.colt.matrix.doublealgo.Formatter().toTitleString( errors,yEdges,xEdges,rowAxisName,columnAxisName,null,aggr);
246	String format = "%1.2G";
278	keep coord. system
282	keep coord. system
285	keep the histo coord. system
286	heights = heights.viewPart(1,1,heights.rows()-2,heights.columns()-2); // ignore under&overflows
288	cern.colt.matrix.DoubleMatrix2D errors = new cern.colt.matrix.impl.DenseDoubleMatrix2D(toArrayErrors(h)); errors = errors.viewDice().viewRowFlip();  keep the histo coord system errors = errors.viewPart(1,1,errors.rows()-2,errors.columns()-2);  ignore under&overflows
296	+ sep + "Errors:" + sep + new cern.colt.matrix.doublealgo.Formatter().toTitleString( errors,yEdges,xEdges,rowAxisName,columnAxisName,null,aggr);
374	out.append("<statistics>"); out.append(sep); out.append("<statistic name=\"Entries\" value=\""+h.entries()+"\"/>"); out.append(sep); out.append("<statistic name=\"MeanX\" value=\""+h.meanX()+"\"/>"); out.append(sep); out.append("<statistic name=\"RmsX\" value=\""+h.rmsX()+"\"/>"); out.append(sep); out.append("<statistic name=\"MeanY\" value=\""+h.meanY()+"\"/>"); out.append(sep); out.append("<statistic name=\"RmsY\" value=\""+h.rmsY()+"\"/>"); out.append(sep); out.append("</statistics>"); out.append(sep);

Colt/xml/hep/aida/ref/FixedAxis.xml
17	Package private for ease of use in Histogram1D and Histogram2D
30	Note, for internal consistency we save only min and binWidth and always use these quantities for all calculations. Due to rounding errors the return value from upperEdge is not necessarily exactly equal to max
39	our internal definition of overflow/underflow differs from that of the outside world this.under = 0; this.over = bins+1;

Colt/xml/hep/aida/ref/Histogram.xml

Colt/xml/hep/aida/ref/Histogram1D.xml
19	total number of times fill called
20	Sum of all weights
21	Sum of the squares of the weights
68	return entries[xAxis.map(index)];
73	return Math.sqrt(errors[xAxis.map(index)]);
78	return heights[xAxis.map(index)];
87	int bin = xAxis.getBin(x);
100	int bin = xAxis.getBin(x);
147	TODO: Can we do anything sensible/useful with the other statistics?

Colt/xml/hep/aida/ref/Histogram2D.xml
20	total number of times fill called
21	Sum of all weights
22	Sum of the squares of the weights
81	return entries[xAxis.map(indexX)][yAxis.map(indexY)];
86	return Math.sqrt(errors[xAxis.map(indexX)][yAxis.map(indexY)]);
91	return heights[xAxis.map(indexX)][yAxis.map(indexY)];
100	int xBin = xAxis.getBin(x); int yBin = xAxis.getBin(y);
117	int xBin = xAxis.getBin(x); int yBin = xAxis.getBin(y);
144	Attention: our internal definition of bins has been choosen so that this works properly even if the indeces passed in include the underflow or overflow bins
154	for (int i=xAxis.under; i<=xAxis.over; i++)
180	Attention: our internal definition of bins has been choosen so that this works properly even if the indeces passed in include the underflow or overflow bins
192	for (int j=yAxis.under; j<=yAxis.over; j++)
252	TODO: Can we do anything sensible/useful with the other statistics?

Colt/xml/hep/aida/ref/Histogram3D.xml
20	total number of times fill called
21	Sum of all weights
22	Sum of the squares of the weights
153	Attention: our internal definition of bins has been choosen so that this works properly even if the indeces passed in include the underflow or overflow bins
192	Attention: our internal definition of bins has been choosen so that this works properly even if the indeces passed in include the underflow or overflow bins
231	Attention: our internal definition of bins has been choosen so that this works properly even if the indeces passed in include the underflow or overflow bins

Colt/xml/hep/aida/ref/Test.xml
26	Write the results as a PlotML files!
30	Try some projections
100	out.println("<statistics>"); out.println("<statistic name=\"Entries\" value=\""+h.entries()+"\"/>"); out.println("<statistic name=\"MeanX\" value=\""+h.meanX()+"\"/>"); out.println("<statistic name=\"RmsX\" value=\""+h.rmsX()+"\"/>"); out.println("<statistic name=\"MeanY\" value=\""+h.meanY()+"\"/>"); out.println("<statistic name=\"RmsY\" value=\""+h.rmsY()+"\"/>"); out.println("</statistics>");

Colt/xml/hep/aida/ref/Test2.xml
25	Write the results as a PlotML files!
29	Try some projections
39	IHistogram1D h1 = new Histogram1D("AIDA 1D Histogram",2,-3,3);
43	IHistogram2D h2 = new Histogram2D("AIDA 2D Histogram",2,-3,3, 2,-3,3);
46	IHistogram3D h3 = new Histogram3D("AIDA 3D Histogram",new VariableAxis(bounds),new VariableAxis(bounds),new VariableAxis(bounds));
50	Write the results as a PlotML files!
55	Try some projections
63	System.out.println(new Converter().toXML(h));
64	try { PrintWriter out = new PrintWriter(new FileWriter(filename)); out.println(new Converter().toXML(h)); out.close(); } catch (IOException x) { x.printStackTrace(); }
77	System.out.println(new Converter().toXML(h));
78	try { PrintWriter out = new PrintWriter(new FileWriter(filename)); out.println(new Converter().toXML(h)); out.close(); } catch (IOException x) { x.printStackTrace(); }
91	System.out.println(new Converter().toXML(h));
92	try { PrintWriter out = new PrintWriter(new FileWriter(filename)); out.println(new Converter().toXML(h)); out.close(); } catch (IOException x) { x.printStackTrace(); }

Colt/xml/hep/aida/ref/Util.xml

Colt/xml/hep/aida/ref/VariableAxis.xml
28	check if really sorted and has no multiple identical elements
68	int index = new DoubleArrayList(this.edges).binarySearch(coord); // just for debugging
69	not found
70	else index++; // found

