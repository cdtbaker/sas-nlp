EJML/xml/org/ejml/alg/block/BlockInnerMultiplication.xml
45	for( int i = 0; i < heightA; i++ ) { for( int k = 0; k < widthA; k++ ) { for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += dataA[i*widthA + k + indexA] * dataB[k*widthC + j + indexB]; } } }
60	for( int k = 0; k < widthA; k++ ) {
65	for( int j = 0; j < widthC; j++ ) {
82	for( int i = 0; i < widthA; i++ ) { for( int k = 0; k < heightA; k++ ) { double valA = dataA[k*widthA + i + indexA]; for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += valA * dataB[k*widthC + j + indexB]; } } }
97	for( int k = 0; k < heightA; k++ ) {
104	for( int j = 0; j < widthC; j++ ) {
146	for( int i = 0; i < heightA; i++ ) { for( int k = 0; k < widthA; k++ ) { for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += dataA[i*widthA + k + indexA] * dataB[k*widthC + j + indexB]; } } }
161	for( int k = 0; k < widthA; k++ ) {
166	for( int j = 0; j < widthC; j++ ) {
183	for( int i = 0; i < widthA; i++ ) { for( int k = 0; k < heightA; k++ ) { double valA = dataA[k*widthA + i + indexA]; for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += valA * dataB[k*widthC + j + indexB]; } } }
198	for( int k = 0; k < heightA; k++ ) {
205	for( int j = 0; j < widthC; j++ ) {
247	for( int i = 0; i < heightA; i++ ) { for( int k = 0; k < widthA; k++ ) { for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += dataA[i*widthA + k + indexA] * dataB[k*widthC + j + indexB]; } } }
262	for( int k = 0; k < widthA; k++ ) {
268	for( int j = 0; j < widthC; j++ ) {
272	for( int j = 0; j < widthC; j++ ) {
290	for( int i = 0; i < widthA; i++ ) { for( int k = 0; k < heightA; k++ ) { double valA = dataA[k*widthA + i + indexA]; for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += valA * dataB[k*widthC + j + indexB]; } } }
305	for( int k = 0; k < heightA; k++ ) {
312	for( int j = 0; j < widthC; j++ ) {
360	for( int i = 0; i < heightA; i++ ) { for( int k = 0; k < widthA; k++ ) { for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += dataA[i*widthA + k + indexA] * dataB[k*widthC + j + indexB]; } } }
375	for( int k = 0; k < widthA; k++ ) {
380	for( int j = 0; j < widthC; j++ ) {
397	for( int i = 0; i < widthA; i++ ) { for( int k = 0; k < heightA; k++ ) { double valA = dataA[k*widthA + i + indexA]; for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += valA * dataB[k*widthC + j + indexB]; } } }
412	for( int k = 0; k < heightA; k++ ) {
419	for( int j = 0; j < widthC; j++ ) {
461	for( int i = 0; i < heightA; i++ ) { for( int k = 0; k < widthA; k++ ) { for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += dataA[i*widthA + k + indexA] * dataB[k*widthC + j + indexB]; } } }
476	for( int k = 0; k < widthA; k++ ) {
482	for( int j = 0; j < widthC; j++ ) {
486	for( int j = 0; j < widthC; j++ ) {
504	for( int i = 0; i < widthA; i++ ) { for( int k = 0; k < heightA; k++ ) { double valA = dataA[k*widthA + i + indexA]; for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] += valA * dataB[k*widthC + j + indexB]; } } }
519	for( int k = 0; k < heightA; k++ ) {
526	for( int j = 0; j < widthC; j++ ) {

EJML/xml/org/ejml/alg/block/BlockInnerRankUpdate.xml
123	only the upper portion of this block needs to be modified since it is along a diagonal
193	for( int i = 0; i < widthA; i++ ) { for( int k = 0; k < heightA; k++ ) {  double valA = dataA[k*widthA + i + indexA]; for( int j = 0; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] -= valA * dataA[k*widthC + j + indexB]; } } }
207	for( int k = 0; k < heightA; k++ ) {
236	for( int i = 0; i < widthA; i++ ) { for( int k = 0; k < heightA; k++ ) {  double valA = dataA[k*widthA + i + indexA]; for( int j = i; j < widthC; j++ ) { dataC[ i*widthC + j + indexC ] -= valA * dataA[k*widthC + j + indexB]; } } }
256	for( int j = i; j < widthC; j++ ) {
273	for( int i = 0; i < heightA; i++ ) { for( int j = 0; j < widthC; j++ ) { double sum = 0; for( int k = 0; k < widthA; k++ ) { sum += dataA[i*widthA + k + indexA] * dataA[j*widthA + k + indexB]; } dataC[ i*widthC + j + indexC ] -= sum; } }
290	for( int j = 0; j < widthC; j++  ) {
315	for( int i = 0; i < heightA; i++ ) { for( int j = 0; j <= i; j++ ) { double sum = 0; for( int k = 0; k < widthA; k++ ) { sum += dataA[i*widthA + k + indexA] * dataA[j*widthA + k + indexB]; } dataC[ i*widthC + j + indexC ] -= sum; } }

EJML/xml/org/ejml/alg/block/BlockInnerTriangularSolver.xml
190	for( int j = 0; j < n; j++ ) { for( int i = 0; i < m; i++ ) { double sum = b[offsetB + j*m+i]; for( int k=0; k<i; k++ ) { sum -= L[offsetL + i*m+k]* b[offsetB + j*m+k]; } b[offsetB + j*m+i] = sum / L[offsetL + i*m+i]; } }
206	for( int k=0; k<i; k++ ) {

EJML/xml/org/ejml/alg/block/BlockMatrixOps.xml
214	This can be speed up by inlining the multBlock* calls, reducing number of multiplications and other stuff.  doesn't seem to have any speed advantage over mult_reorder()

EJML/xml/org/ejml/alg/block/BlockMultiplication.xml
103	checkInput( blockLength,A,B,C);

EJML/xml/org/ejml/alg/block/BlockTriangularSolver.xml
212	number of rows in a block.  The submatrix can be smaller than a block
328	width and height of the inner T(i,i) block
337	solve the top row block B(i,:) = T(i,i)^-1 Y(i,:)
348	Y[i,:] = Y[i,:] - sum j=1:i-1 { T[i,j] B[j,i] } where i is the next block down The summation is a block inner product
355	Tinner.col1 = Tinner.col1;
357	Binner.row0 = Binner.row0;
366	Tinner.col1 = Tinner.col1;
369	Binner.row1 = Binner.row1;
375	step through each block column
385	Y = Y - T^T * B
389	Y = Y - T * B
451	width and height of the inner T(i,i) block
460	solve the top row block B(i,:) = T(i,i)^-1 Y(i,:)
471	Y[i,:] = Y[i,:] - sum j=1:i-1 { T[i,j] B[j,i] } where i is the next block down The summation is a block inner product
478	Rinner.row1 = Rinner.row1;
481	Binner.row1 = Binner.row1;
490	Binner.row0 = Binner.row0;
497	step through each block column
507	Y = Y - T^T * B
510	Y = Y - T * B

EJML/xml/org/ejml/alg/block/BlockVectorOps.xml
66	handle the case where offset is more than a block
70	handle rows in any block
125	handle the case where offset is more than a block
129	handle rows in any block
190	handle the case where offset is more than a block
246	handle the case where offset is more than a block
255	handle rows in any block
314	handle the case where offset is more than a block
323	handle rows in any block

EJML/xml/org/ejml/alg/block/decomposition/bidiagonal/BidiagonalHelper.xml
45	System.out.println("---------- Orig"); A.original.print();
54	--- Apply reflector to the column
56	compute the householder vector
60	apply to rest of the columns in the column block
63	apply to the top row block
69	-- Apply reflector to the row
73	apply to rest of the rows in the row block
79	apply to the left column block TODO THIS WON'T WORK!!!!!!!!!!!!! Needs the whole matrix to have been updated by the left reflector to compute the correct solution
82	rank1UpdateMultL_LeftCol(blockLength,A,i,i+1,gammasV[A.row0+i]);

EJML/xml/org/ejml/alg/block/decomposition/chol/BlockCholeskyOuterForm.xml
43	if it should compute an upper or lower triangular matrix
45	The decomposed matrix.
95	cholesky on inner block A
99	on the last block these operations are not needed.
101	B = L^-1 B
104	C = C - B * B^T
134	cholesky on inner block A
138	on the last block these operations are not needed.
140	B = U^-1 B
143	C = C - B^T * B

EJML/xml/org/ejml/alg/block/decomposition/chol/BlockInnerCholesky.xml
30	TODO merge with CholeskyBlockHelper
66	todo optimize
72	is it positive-definite?
106	todo optimize
112	is it positive-definite?

EJML/xml/org/ejml/alg/block/decomposition/hessenberg/TridiagonalBlockHelper.xml
65	step through rows in the block
67	compute the new reflector and save it in a row in 'A'
71	compute y
74	compute v from y
77	Apply the reflectors to the next row in 'A' only
114	W = -beta*v(1)
119	set up rest of the rows
121	w=-beta*(I + W*Y^T)*u
124	w = w -beta*W*(Y^T*u)
130	w=w -beta*u + stuff above
158	compute y
161	compute v from y
190	for each previously computed reflector
200	take in account the leading one
204	grab only the relevant row from A = A + u*v^T + v*u^T
230	Elements in 'y' before 'row' are known to be zero and the element at 'row' is not used. Thus only elements after row and after are computed. y = A*u
236	y = y + u_i*v_i^t*u + v_i*u_i^t*u
238	v_i^t*u
241	u_i^t*u
244	y = y + u_i*(v_i^t*u) the ones in these 'u' are skipped over since the next submatrix of A is only updated
249	y = y + v_i*(u_i^t*u) the 1 in U is taken account above
254	y = -gamma*y
296	take in account the one in 'A'
304	take in account the one in 'A'
332	val=(y^T*u)
335	take in account the one
339	v = y - (1/2)gamma*val * u

EJML/xml/org/ejml/alg/block/decomposition/hessenberg/TridiagonalDecompositionBlockHouseholder.xml
53	matrix which is being decomposed householder vectors are stored along the upper triangle rows
56	temporary storage for block computations
58	stores intermediate results in matrix multiplication
62	temporary storage for zeros and ones in U
109	(Q1^T * (Q2^T * (Q3^t * A)))
132	zeros and ones are saved and overwritten in U so that standard matrix multiplication can be used
135	compute W for Q(i) = ( I + W*Y^T)
141	Apply the Qi to Q Qi = I + W*U^T
144	Note that U and V are really row vectors.  but standard notation assumed they are column vectors. which is why the functions called don't match the math above
147	(I + W*U^T)*Q F=U^T*Q(i)
153	Q(i+1) = Q(i) + W*F
168	save the zeros
173	save the one
184	save the zeros
188	save the one
218	System.out.println("-------- triag i "+i);
230	bidiagonalize the top row
233	apply Householder reflectors to the lower portion using block multiplication
236	take in account the 1 in the last row.  The others are skipped over.
240	A = A + U*V^T + V*U^T

EJML/xml/org/ejml/alg/block/decomposition/qr/BlockHouseHolder.xml
58	compute the householder vector
62	apply to rest of the columns in the block
93	computes tau and normalizes u by max
96	divide u by u_0
103	after the reflector is applied the column would be all zeros but be -tau in the first element
132	computes tau and normalizes u by max
135	divide u by u_0
141	after the reflector is applied the column would be all zeros but be -tau in the first element
168	total = U^T * A(:,j)
172	A(:,j) - gamma*U*total
193	for( int k = 0; k < height; k++
221	step through columns in top block, skipping over the first block
226	total = U^T * A(:,j) * gamma
229	A(:,j) - gamma*U*total just update the top most block
237	take in account zeros and one
276	total = U^T * A(i,:)
280	A(i,:) - gamma*U*total
333	total = U^T * A(i,:)
338	A(i,:) - gamma*U*total
339	plusScale_row(blockLength,);
344	skip over zeros and assume first element in U is 1
383	first column in the blocks
389	compute dot product down column vectors
398	handle leading zeros
402	handle leading one
407	standard vector dot product
410	for( int k = col+1; k < height; k++ , indexU += width, indexA += width ) {
414	standard vector dot product
416	for( int k = 0; k < height; k++ ) {
451	take in account the one in 'A'
468	handle leading one
497	for( int k = 0; k < height; k++
527	handle the one
530	scale rest of the vector
568	save this value so that the sign can be determined later on
634	save this value so that the sign can be determined later on
772	set the first column in W
777	set up rest of the columns
779	compute the z vector and insert it into W
813	take in account the first element in V being 1
858	handle the triangular portion with the leading zeros and the one
860	compute the rows of W * h
867	add the two vectors together and multiply by -beta
868	zeros
870	one
872	normal data
878	for( int k = 0; k < heightW; k++ ,
880	compute the rows of W * h
887	add the two vectors together and multiply by -beta

EJML/xml/org/ejml/alg/block/decomposition/qr/BlockMatrix64HouseholderQR.xml
64	the input matrix which is overwritten with the decomposition. Reflectors are stored in the lower triangular portion. The R matrix is stored in the upper triangle portion
69	where the computed W matrix is stored
71	Matrix used to store an intermediate calculation
74	size of the inner matrix block.
77	The submatrices which are being manipulated in each iteration
83	stores the computed gammas
86	save the W matrix the first time it is computed in the decomposition
198	(Q1^T * (Q2^T * (Q3^t * A)))
213	Compute W matrix from reflectors stored in Y
217	Apply the Qi to Q
245	(Q3^T * (Q2^T * (Q1^t * A)))
253	subB.row1 = B.numRows; subB.col0 = 0; subB.col1 = B.numCols;
258	W.original.reshape(W.row1,W.col1,false);
265	Compute W matrix from reflectors stored in Y
269	Apply the Qi to Q
313	process the matrix one column block at a time and overwrite the input matrix
319	compute the QR decomposition of the left most block column this overwrites the original input matrix
325	Update the remainder of the matrix using the reflectors just computed

EJML/xml/org/ejml/alg/block/GeneratorBlockInnerMultiplication.xml

EJML/xml/org/ejml/alg/block/linsol/chol/BlockCholeskyOuterSolver.xml
52	cholesky decomposition
55	size of a block take from input matrix
58	temporary data structure used in some calculation.
69	Extract a lower triangular solution
102	L * L^T*X = B
104	Solve for Y:  L*Y = B
107	L^T * X = Y
111	copy the solution from B into X
127	zero the upper triangular portion of A_inv
133	invert L from cholesky decomposition and write the solution into the lower triangular portion of A_inv B = inv(L)
138	B = L^-T * B todo could speed up by taking advantage of B being lower triangular todo take advantage of symmetry

EJML/xml/org/ejml/alg/block/linsol/qr/BlockQrHouseHolderSolver.xml
51	QR decomposition algorithm
54	the input matrix which has been decomposed
104	The system being solved for can be described as: Q*R*X = B
107	First apply householder reflectors to B Y = Q^T*B
111	Second solve for Y using the upper triangle matrix R and the just computed Y X = R^-1 * Y
115	extract a block aligned matrix
135	Solve for A^-1 Q*R*A^-1 = I
138	Apply householder reflectors to the identity matrix y = Q^T*I = Q^T
143	Solve using upper triangular R matrix R*A^-1 = y A^-1 = R^-1*y

EJML/xml/org/ejml/alg/dense/decomposition/BaseDecompositionBlock64.xml
60	doing an in-place convert is much more memory efficient at the cost of a little but of CPU
66	convert it back to the normal format if it wouldn't have been modified

EJML/xml/org/ejml/alg/dense/decomposition/bidiagonal/BidiagonalDecomposition.xml

EJML/xml/org/ejml/alg/dense/decomposition/bidiagonal/BidiagonalDecompositionNaive.xml
39	number of rows
41	number of columns
43	smallest of m and n
105	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
110	copy the householder vector to vector outside of the matrix to reduce caching issues big improvement on larger matrices and a relatively small performance hit on small matrices.
119	-------- set up the reflector Q_k
122	normalize to reduce overflow/underflow and compute tau for the reflector
134	write the reflector into the lower left column of the matrix
154	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
159	copy the householder vector to vector outside of the matrix to reduce caching issues big improvement on larger matrices and a relatively small performance hit on small matrices.
168	-------- set up the reflector Q_k
171	normalize to reduce overflow/underflow and compute tau for the reflector
183	write the reflector into the lower left column of the matrix
191	---------- multiply on the left by Q_k

EJML/xml/org/ejml/alg/dense/decomposition/bidiagonal/BidiagonalDecompositionRow.xml
37	A combined matrix that stores te upper Hessenberg matrix and the orthogonal matrix.
40	number of rows
42	number of columns
44	the smaller of m or n
47	the first element in the orthogonal vectors
50	temporary storage
140	System.arraycopy(UBV.data, 0, B.data, 0, UBV.getNumElements());
239	UBV.print();
241	todo the very first multiplication can be avoided by setting to the rank1update output
287	UBV.print();
289	System.out.println("--- after U"); UBV.print();
292	System.out.println("--- after V"); UBV.print();
302	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
307	copy the householder vector to vector outside of the matrix to reduce caching issues big improvement on larger matrices and a relatively small performance hit on small matrices.
316	-------- set up the reflector Q_k
319	write the reflector into the lower left column of the matrix while dividing u by nu
328	---------- multiply on the left by Q_k
342	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
347	-------- set up the reflector Q_k
351	write the reflector into the lower left column of the matrix
360	writing to u could be avoided by working directly with b. requires writing a custom rank1Update function ---------- multiply on the left by Q_k

EJML/xml/org/ejml/alg/dense/decomposition/bidiagonal/BidiagonalDecompositionTall.xml
58	TODO optimize this code
62	todo this should be passed in
67	number of rows
69	number of column
71	min(m,n)
103	U = Q*U1
108	U = [Q1*U1 Q2]
143	apply the column pivots. TODO this is horribly inefficient

EJML/xml/org/ejml/alg/dense/decomposition/chol/CholeskyBlockHelper.xml
35	the decomposed matrix
73	k = 0:i-1
75	sum -= el[i*n+k]*el[j*n+k];
80	is it positive-definate?

EJML/xml/org/ejml/alg/dense/decomposition/chol/CholeskyDecompositionBlock.xml
33	how wide the blocks should be
34	row rectangular matrix
58	if the matrix that is being decomposed is smaller than the block we really don't see the B matrix.
101	apply cholesky to the current block
107	B = L^(-1) * B
112	c = c - a^T*a
121	zero the top right corner.
160	for( int j = 0; j < n; j++ ) { for( int i = 0; i < widthL; i++ ) { double sum = dataSrc[indexSrc+i*b_src.numCols+j]; for( int k=0; k<i; k++ ) { sum -= L[i*widthL+k]* b[k*n+j]; } double val = sum / L[i*widthL+i]; dataSrc[indexDst+j*b_src.numCols+i] = val; b[i*n+j] = val; } }
176	for( int i = 0; i < widthL; i++
183	for( int k=0; k<i; k++ ) {
211	TODO update so that it doesn't modify/read parts that it shouldn't
215	for( int i = 0; i < a.numCols; i++ ) { for( int k = 0; k < a.numRows; k++ ) { double valA = dataA[k*a.numCols+i];  for( int j = i; j < a.numCols; j++ ) { dataC[startIndexC+i*c.numCols+j] -= valA * dataA[k*a.numCols+j]; } } }

EJML/xml/org/ejml/alg/dense/decomposition/chol/CholeskyDecompositionBlock64.xml
58	todo set zeros

EJML/xml/org/ejml/alg/dense/decomposition/chol/CholeskyDecompositionCommon.xml
54	it can decompose a matrix up to this width
57	width and height of the matrix
60	the decomposed matrix
64	tempoary variable used by various functions
67	is it a lower triangular matrix or an upper triangular matrix
155	see if it needs to declare a new matrix or not
165	write the values to T

EJML/xml/org/ejml/alg/dense/decomposition/chol/CholeskyDecompositionInner.xml
54	k = 0:i-1
56	sum -= el[i*n+k]*el[j*n+k];
61	is it positive-definite?
74	zero the top right corner.
98	is it positive-definite?
102	I suspect that the sqrt is slowing this down relative to MTJ
111	zero the lower left corner.

EJML/xml/org/ejml/alg/dense/decomposition/chol/CholeskyDecompositionLDL.xml
47	it can decompose a matrix up to this width
49	width and height of the matrix
52	the decomposed matrix
56	the D vector
59	tempoary variable used by various functions
109	is it positive-definate?
121	zero the top right corner.

EJML/xml/org/ejml/alg/dense/decomposition/eig/EigenPowerMethod.xml
57	used to determine convergence
114	q0.print();
157	swap vectors

EJML/xml/org/ejml/alg/dense/decomposition/eig/EigenvalueExtractor.xml

EJML/xml/org/ejml/alg/dense/decomposition/eig/EigenvalueSmall.xml
33	if |a11-a22| >> |a12+a21| there might be a better way.  see pg371
36	apply a rotators such that th a11 and a22 elements are the same
39	is this pointless since
59	double b22 = c2*a22 + s2*a11 + cs*(a12+a21);
61	apply second rotator to make A upper triangular if real eigenvalues
71	c2 = b12;//c*c; s2 = b21;s*s;
76	a12 = c2*b12 - s2*b21; a21 = c2*b21 - s2*b12;
116	See page 385 of Fundamentals of Matrix Computations 2nd
119	double p = (a11 - a22)*0.5; double r = Math.sqrt(p*p + a12*a12);  value0.real = a22 + a12*a12/(r-p); value1.real = a22 - a12*a12/(r+p); }  public void symm2x2_std( double a11 , double a12, double a22 ) {

EJML/xml/org/ejml/alg/dense/decomposition/eig/SwitchingEigenDecomposition.xml
38	tolerance used in deciding if a matrix is symmetric or not
45	should it compute eigenvectors or just eigenvalues?
101	since it doesn't know which algorithm will be used until a matrix is provided make a copy of all inputs

EJML/xml/org/ejml/alg/dense/decomposition/eig/symm/SymmetricQrAlgorithm.xml
38	performs many of the low level calculations
41	transpose of the orthogonal matrix
44	the eigenvalues previously computed
50	should it ever analytically compute eigenvalues if this is true then it can't compute eigenvalues at the same time
54	is it following a script or not
144	if it has cycled too many times give up
150	System.out.println("Steps = "+helper.steps);
151	see if it is done processing this submatrix
156	There are analytical solutions to this case. Just compute them directly. TODO might be able to speed this up by doing the 3 by 3 case also
162	it isn't a good sign if exceptional shifts are being done here
168	helper.printMatrix();
171	helper.printMatrix();
179	check for zeros
195	Using the true eigenvalues will in general lead to the fastest convergence typically takes 1 or 2 steps
200	the current eigenvalue isn't working so try something else
204	similar transforms

EJML/xml/org/ejml/alg/dense/decomposition/eig/symm/SymmetricQREigenHelper.xml
37	used in exceptional shifts
40	how many steps has it taken
43	how many exception shifts has it performed
45	the step number of the last exception shift
48	used to compute eigenvalues directly
51	orthogonal matrix used in similar transform.  optional
54	size of the matrix being processed
56	diagonal elements in the matrix
58	the off diagonal elements
61	which submatrix is being processed
65	where splits are performed
69	current value of the bulge
72	local helper functions
230	for( int i = 0; i < N; i++ ) { double a = Q.data[rowA+i]; double b = Q.data[rowB+i]; Q.data[rowA+i] = c*a + s*b; Q.data[rowB+i] = -s*a + c*b; }
265	multiply the rotator on the top left.
292	multiply the rotator on the top left.
305	double alpha = Math.sqrt(run*run + rise*rise); c = run/alpha; s = rise/alpha;
343	multiply the rotator on the top left.
366	multiply the rotator on the top left.
384	normalize to reduce overflow
392	see if it is a pathological case.  the diagonal must already be zero and the eigenvalues are all zero.  so just return
416	rotating by a random angle handles at least one case using a random lambda does not handle well: - two identical eigenvalues are next to each other and a very small diagonal element
457	normalize to reduce overflow
473	TODO see 385
477	return the eigenvalue closest to c

EJML/xml/org/ejml/alg/dense/decomposition/eig/SymmetricQRAlgorithmDecomposition.xml
50	computes a tridiagonal matrix whose eigenvalues are the same as the original matrix and can be easily computed.
53	helper class for eigenvalue and eigenvector algorithms
55	computes the eigenvectors
58	should it compute eigenvectors at the same time as the eigenvalues?
61	where the found eigenvalues are stored
64	where the tridiagonal matrix is stored
71	temporary variable used to store/compute eigenvectors
73	the extracted eigenvectors
76	should it compute eigenvectors or just eigenvalues
141	compute a similar tridiagonal matrix
151	Tell the helper to work with this matrix
171	extract the orthogonal from the similar transform
174	tell eigenvector algorithm to update this matrix as it computes the rotators
179	extract the eigenvalues
183	the V matrix contains the eigenvectors.  Convert those into column vectors
186	save a copy of them since this data structure will be recycled next
196	---- set up the helper to decompose the same tridiagonal matrix swap arrays instead of copying them to make it slightly faster
202	extract the orthogonal from the similar transform
205	tell eigenvector algorithm to update this matrix as it computes the rotators
208	extract eigenvectors
212	the ordering of the eigenvalues might have changed
214	the V matrix contains the eigenvectors.  Convert those into column vectors
226	make a copy of the internal tridiagonal matrix data for later use
233	extract the eigenvalues
237	save a copy of them since this data structure will be recycled next

EJML/xml/org/ejml/alg/dense/decomposition/eig/watched/WatchedDoubleStepQREigen.xml
43	TODO make rank1UpdateMultR efficient once again by setting 0 to x1 and creating a new one that updates all the rows TODO option of modifying original matrix
57	how many steps did it take to find the eigenvalue
63	computes eigenvalues for 2 by 2 submatrices
119	this provides a relative threshold for when dealing with very large/small numbers
124	according to Matrix Computations page 352 this is what is done in Eispack
146	zero all the off numbers that should be zero for a hessenberg matrix
171	perform a random shift that is of the same magnitude as the matrix
178	the closer the value is the better it handles identical eigenvalues cases
200	compute the wilkinson shift
225	these equations are derived when the eigenvalues are extracted from the lower right 2 by 2 matrix.  See page 388 of Fundamentals of Matrix Computations 2nd ed for details.
233	this is different from the version in the book and seems in my testing to be more resilient to over flow issues
269	this is different from the version in the book and seems in my testing to be more resilient to over flow issues
284	get rid of the bump
301	perform double steps
316	the last one has to be a single step
327	A.print("%12.3e");
340	get rid of the bump
353	perform simple steps
406	if( max <= Math.abs(A.get(i,i))*UtilEjml.EPS ) {
423	compute the reflector using the b's above
436	compute A_1 = Q_1^T * A * Q_1
438	apply Q*A  - just do the 3 rows
452	apply A*Q - just the three things
455	System.out.println("  after Q*A*Q "); A.print();
485	if( max <= Math.abs(A.get(i,i))*UtilEjml.EPS ) {
487	System.out.println("i = "+i); A.print();
502	compute the reflector using the b's above
514	compute A_1 = Q_1^T * A * Q_1
516	apply Q*A  - just do the 3 rows
524	apply A*Q - just the three things
565	System.out.printf("eigen (%6.3f , %6.3f) (%6.3f , %6.3f)\n",p0_real,p0_img,p1_real,p1_img);

EJML/xml/org/ejml/alg/dense/decomposition/eig/watched/WatchedDoubleStepQREigenvalue.xml
68	implicitQR.A.print();
72	implicitQR.A.print();
76	see if the matrix blew up
83	implicitQR.A.print();
110	see if it can perform a split
116	reduce the scope of what it is looking at

EJML/xml/org/ejml/alg/dense/decomposition/eig/watched/WatchedDoubleStepQREigenvector.xml
40	Q matrix from double step QR
75	UtilEjml.setnull(eigenvectors);
85	System.out.println("Orig A"); A.print("%12.10f");
97	extract eigenvectors from the shur matrix start at the top left corner of the matrix
112	translate the eigenvectors into the frame of the original matrix
192	TODO this must be very inefficient
204	use the already computed eigenvalues to recompute the Q and R matrices
212	Q.print("%1.10f");  implicit.A.print("%1.10f");
222	implicit.A.print();
238	implicit.A.print("%e");
239	System.err.println("If it needs to do an exceptional shift then something went very bad.");
240	return false;
244	check for convergence
258	check for splits
263	reduce the scope of what it is looking at
267	first try using known eigenvalues in the same order they were originally found
274	if no splits are found perform an implicit step
284	that didn't work so try a modified order

EJML/xml/org/ejml/alg/dense/decomposition/eig/WatchedDoubleStepQRDecomposition.xml
44	TODO looks like there might be some pointless copying of arrays going on
54	should it compute eigenvectors or just eigenvalues
74	algValue.getImplicitQR().setChecks(true,true,true);
79	for( int i = 0; i < A.numRows; i++ ) { System.out.println(algValue.getEigenvalues()[i]); }

EJML/xml/org/ejml/alg/dense/decomposition/hessenberg/HessenbergSimilarDecomposition.xml
48	TODO create a column based one similar to what was done for QR decomposition?
51	A combined matrix that stores te upper Hessenberg matrix and the orthogonal matrix.
53	number of rows and columns of the matrix being decompose
56	the first element in the orthogonal vectors
58	temporary storage
130	copy the first row
177	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
182	copy the householder vector to vector outside of the matrix to reduce caching issues big improvement on larger matrices and a relatively small performance hit on small matrices.
191	-------- set up the reflector Q_k
194	normalize to reduce overflow/underflow and compute tau for the reflector
206	write the reflector into the lower left column of the matrix
217	---------- multiply on the left by Q_k
220	---------- multiply on the right by Q_k
223	since the first element in the householder vector is known to be 1 store the full upper hessenberg

EJML/xml/org/ejml/alg/dense/decomposition/hessenberg/TridiagonalDecompositionBlock.xml

EJML/xml/org/ejml/alg/dense/decomposition/hessenberg/TridiagonalDecompositionHouseholder.xml
56	The size of the matrix
59	temporary storage
61	gammas for the householder operations
63	temporary storage
185	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
198	-------- set up the reflector Q_k
202	write the reflector into the lower left column of the matrix
210	---------- Specialized householder that takes advantage of the symmetry
213	since the first element in the householder vector is known to be 1 store the full upper hessenberg
231	compute v = -gamma*A*u
234	the lower triangle is not written to so it needs to traverse upwards to get the information.  Reduces the number of matrix writes need improving large matrix performance
245	alpha = -0.5*gamma*u^T*v
253	w = v + alpha*u
257	A = A + w*u^T + u*w^T
265	only write to the upper portion of the matrix this reduces the number of cache misses

EJML/xml/org/ejml/alg/dense/decomposition/hessenberg/TridiagonalDecompositionHouseholderOrig.xml
44	The size of the matrix
47	temporary storage
49	gammas for the householder operations
51	temporary storage
126	Q.print();
142	System.out.println("k=="+k); QT.print();
153	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
166	-------- set up the reflector Q_k
169	normalize to reduce overflow/underflow and compute tau for the reflector
181	write the reflector into the lower left column of the matrix
192	---------- Specialized householder that takes advantage of the symmetry
195	since the first element in the householder vector is known to be 1 store the full upper hessenberg
213	compute v = -gamma*A*u
220	System.out.println("y["+i+"] = "+w[i]);
222	alpha = -0.5*gamma*u^T*v
230	w = v + alpha*u
233	System.out.println("w["+i+"] = "+w[i]);
235	A = A + w*u^T + u*w^T
240	System.out.println("u["+i+"] = "+uu);
270	just copy the top right triangle

EJML/xml/org/ejml/alg/dense/decomposition/hessenberg/TridiagonalSimilarDecomposition.xml

EJML/xml/org/ejml/alg/dense/decomposition/lu/LUDecompositionAlt.xml
51	make a copy of the column to avoid cache jumping issues
56	Apply previous transformations.
60	Most of the time is spent in the following dot product.
70	Find pivot and exchange if necessary.
82	swap the rows
83	for (int k = 0; k < n; k++) { double t = dataLU[p*n + k]; dataLU[p*n + k] = dataLU[j*n + k]; dataLU[j*n + k] = t; }
101	Compute multipliers.

EJML/xml/org/ejml/alg/dense/decomposition/lu/LUDecompositionBase.xml
38	the decomposed matrix
41	it can decompose a matrix up to this size
44	the shape of the matrix
46	data in the matrix
49	used in set, solve, invert
51	used in set
55	used by determinant
215	Solve L*Y = B
223	for( int j = ii-1; j < i; j++ ) sum -= dataLU[i* n +j]*vv[j];
234	Solve U*X = Y;

EJML/xml/org/ejml/alg/dense/decomposition/qr/QRColPivDecompositionHouseholderColumn.xml
49	the ordering of each column, the current column i is the original column pivots[i]
51	F-norm  squared for each column
54	threshold used to determine when a column is considered to be singular Threshold is relative to the maxAbs
58	the matrix's rank
148	initialize pivot variables
151	go through each column and perform the decomposition
156	if its degenerate stop processing
198	if a negative sum has been found then clearly too much precision has been last and it should recompute the column norms from scratch
220	find the column with the largest norm
230	swap the columns
261	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
268	computes tau and normalizes u by max
271	divide u by u_0

EJML/xml/org/ejml/alg/dense/decomposition/qr/QRDecompositionBlock64.xml

EJML/xml/org/ejml/alg/dense/decomposition/qr/QRDecompositionHouseholder.xml
61	used internally to store temporary data
64	dimension of the decomposed matrices
65	this is 'n'
66	this is 'm'
71	the computed gamma for Q_k matrix
73	local variables
77	did it encounter an error?
246	find the element with the largest absolute value in the column and make a copy
253	absolute value of d
265	compute the norm2 of the matrix, with each element normalized by the max value to avoid overflow problems
301	much of the code below is equivalent to the rank1Update function however, since &tau; has already been computed there is no need to recompute it, saving a few multiplication operations
304	for( int i = w+1; i < numCols; i++ ) { double val = 0;  for( int k = w; k < numRows; k++ ) { val += u[k]*dataQR[k*numCols +i]; } v[i] = gamma*val; }
313	This is functionally the same as the above code but the order has been changed to avoid jumping the cpu cache
322	v[i] += u[k]*dataQR[k*numCols +i];
331	end of reordered code
338	dataQR[i*numCols+j] -= valU*v[j];
347	save the Q matrix in the lower portion of QR

EJML/xml/org/ejml/alg/dense/decomposition/qr/QRDecompositionHouseholderColumn.xml
45	[ column][ row ]
47	used internally to store temporary data
50	dimension of the decomposed matrices
51	this is 'n'
52	this is 'm'
55	the computed gamma for Q_k matrix
57	local variables
61	did it encounter an error?
245	find the largest value in this column this is used to normalize the column and mitigate overflow/underflow
253	computes tau and normalizes u by max
256	divide u by u_0

EJML/xml/org/ejml/alg/dense/decomposition/qr/QRDecompositionHouseholderTran.xml
38	TODO remove QR Col and replace with this one? -- On small matrices col seems to be about 10% faster
48	used internally to store temporary data
51	dimension of the decomposed matrices
52	this is 'n'
53	this is 'm'
56	the computed gamma for Q_k matrix
58	local variables
62	did it encounter an error?
124	Unlike applyQ() this takes advantage of zeros in the identity matrix by not multiplying across all rows.
270	computes tau and normalizes u by max
273	divide u by u_0
297	int rowW = w*numRows; int rowJ = rowW + numRows;  for( int j = w+1; j < numCols; j++ , rowJ += numRows) { double val = QR.data[rowJ + w];  val = gamma*u^T * A for( int k = w+1; k < numRows; k++ ) { val += QR.data[rowW + k]*QR.data[rowJ + k]; } val *= gamma;  A - val*u QR.data[rowJ + w] -= val; for( int i = w+1; i < numRows; i++ ) { QR.data[rowJ + i] -= QR.data[rowW + i]*val; } }
323	assume the first element in u is 1

EJML/xml/org/ejml/alg/dense/decomposition/qr/QrHelperFunctions.xml
65	double div_u = 1.0/u_0;  if( Double.isInfinite(div_u)) {
71	} else { for( int i = j; i < numRows; i++ ) { u[i] *= div_u; } }
79	double div_u = 1.0/u_0;  if( Double.isInfinite(div_u)) {
85	} else { for( int i = j; i < numRows; i++ ) { u[i+startU] *= div_u; } }
95	double div_u = 1.0/u_0;  if( Double.isInfinite(div_u)) {
101	} else { for( int i = j; i < numRows; i++ ) { u[i] = b[i+startB] *= div_u; } }
112	double div_u = 1.0/u_0;  if( Double.isInfinite(div_u)) {
119	} else { int indexB = j*numCols+startB; for( int i = j; i < numRows; i++ , indexB += numCols ) { b[indexB] = u[i] *= div_u; } }
128	compute the norm2 of the matrix, with each element normalized by the max value to avoid overflow problems
131	double div_max = 1.0/max; if( Double.isInfinite(div_max)) {
133	more accurate
138	} else { faster for( int i = j; i < numRows; i++ ) { double d = u[startU+i] *= div_max; tau += d*d; } }
177	double div_max = 1.0/max; if( Double.isInfinite(div_max)) {
183	} else { for( int i = j; i < numRows; i++ ) { double d = u[i] *= div_max; tau += d*d; } }
218	for( int i = colA0; i < A.numCols; i++ ) { double val = 0;  for( int k = w0; k < w1; k++ ) { val += u[k]*A.data[k*A.numCols +i]; } _temp[i] = gamma*val; }
227	reordered to reduce cpu cache issues
243	end of reorder
262	for( int i = colA0; i < A.numCols; i++ ) { double val = 0;  for( int k = w0; k < w1; k++ ) { val += u[k+offsetU]*A.data[k*A.numCols +i]; } _temp[i] = gamma*val; }
271	reordered to reduce cpu cache issues
287	end of reorder

EJML/xml/org/ejml/alg/dense/decomposition/qr/QrUpdate.xml
55	the decomposition that is being adjusted
57	product of planar multiplications
58	using transpose of U reduces cache misses
61	used to temporarially store data
64	it can process matrices up to this size
68	number of rows and columns in the original A matrix that was decomposed
70	number of rows in the adjusted matrices
73	should it declare new internal data when what currently exists is too small or throw and exception.
147	memory management and check precoditions
162	apply givens rotation to the first two rows of the augmented R matrix
165	compute new Q matrix
168	discard the reference since it is no longer needed
205	discard the reference since it is no longer needed
341	set U to its initial values
352	first compute the rotation
368	update R matrix
378	compute U^T = U^T_(x+1) * U^T_x
396	first compute the rotation
410	in the next iteration xj is r
413	compute U^T = U^T_(x+1) * U^T_x

EJML/xml/org/ejml/alg/dense/decomposition/svd/implicitqr/SvdImplicitQrAlgorithm.xml
55	used in exceptional shifts
58	U and V matrices in singular value decomposition.  Stored in the transpose to reduce cache jumps
63	number of times it has performed an implicit step, the most costly part of the algorithm
67	max value in original matrix.  used to test for zeros
70	matrix's size
73	used to compute eigenvalues directly
76	how many exception shifts has it performed
78	the step number of the last exception shift
81	diagonal elements in the matrix
83	the off diagonal elements
85	value of the bulge
88	the submatrix its working on
92	how many cycles has it run through looking for the current singular value
95	where splits are performed
99	After this many iterations it will perform an exceptional
103	should the steps use a sequence of predefined lambdas?
106	--------- variables for scripted step if following a sequence of steps, this is the point at which it decides its going no where and needs to use a different step
112	can it compute singularvalues directly
115	if not in scripted mode is it looking for new zeros first?
120	for debugging
121	SimpleMatrix B;
227	it is a zero matrix
231	if it has cycled too many times give up
237	System.out.println("steps = "+steps+"  script = "+followScript+" at "+x1); System.out.println("Split");
239	see if it is done processing this submatrix
244	There are analytical solutions to this case. Just compute them directly.
251	perform a step
261	printMatrix();
273	initially look for singular values of zero
282	For very large and very small numbers the only way to prevent overflow/underflow is to have a common scale between the wilkinson shift and the implicit single step What happens if you don't is that when the wilkinson shift returns the value it computed it multiplies it by the scale twice, which will cause an overflow
287	use the wilkinson shift to perform a step
301	give up on the script
304	use previous singular value to step
322	return Math.abs(diag[i]) <= maxValue* UtilEjml.EPS;
390	for( int i = 0; i < Q.numCols; i++ ) { double a = Q.get(rowA+i); double b = Q.get(rowB+i); Q.set( rowA+i, c*a + s*b); Q.set( rowB+i, -s*a + c*b); } System.out.println("------ AFter Update Rotator "+m+" "+n); Q.print(); System.out.println();
413	double b22 = diag[x1+1];  double scale = Math.max( Math.abs(b11) , Math.abs(b12));  return Math.max(scale,Math.abs(b22));
433	normalize to improve resistance to overflow/underflow
443	multiply the rotator on the top left.
449	SimpleMatrix Q = createQ(x1, c, s, false); B=B.mult(Q);  B.print(); printMatrix(); System.out.println("  bulge = "+bulge);
459	SimpleMatrix.wrap(Ut).mult(B).mult(SimpleMatrix.wrap(Vt).transpose()).print(); printMatrix(); System.out.println("bulge = "+bulge); System.out.println();
471	double gamma = Math.sqrt(rise*rise + run*run);  c = rise/gamma; s = run/gamma;
476	See page 384 of Fundamentals of Matrix Computations 2nd
498	apply rotator on the left
509	SimpleMatrix Q = createQ(x1, c, s, true); B=Q.mult(B);  B.print(); printMatrix(); System.out.println("  bulge = "+bulge);
519	SimpleMatrix.wrap(Ut).mult(B).mult(SimpleMatrix.wrap(Vt).transpose()).print(); printMatrix(); System.out.println("bulge = "+bulge); System.out.println();
533	apply rotator on the right
542	SimpleMatrix Q = createQ(x1+1, c, s, false); B=B.mult(Q);  B.print(); printMatrix(); System.out.println("  bulge = "+bulge);
552	SimpleMatrix.wrap(Ut).mult(B).mult(SimpleMatrix.wrap(Vt).transpose()).print(); printMatrix(); System.out.println("bulge = "+bulge); System.out.println();
597	return the eigenvalue closest to a22
612	normalize to reduce overflow
620	see if it is a pathological case.  the diagonal must already be zero and the eigenvalues are all zero.  so just return
646	check for zeros along off diagonal
649	System.out.println("steps at split = "+steps);
657	check for zeros along diagonal
660	System.out.println("steps at split = "+steps);
679	B = createB(); B.print();
686	}
699	apply rotator on the right
711	SimpleMatrix Q = createQ(m,m+1, c, s, true); B=Q.mult(B);  B.print(); printMatrix(); System.out.println("  bulge = "+bulge); System.out.println();
722	SimpleMatrix.wrap(Ut).mult(B).mult(SimpleMatrix.wrap(Vt).transpose()).print(); printMatrix(); System.out.println("bulge = "+bulge); System.out.println();
747	SimpleMatrix Q = createQ(m,m+offset, c, s, true); B=Q.mult(B);  B.print(); printMatrix(); System.out.println("  bulge = "+bulge); System.out.println();
758	SimpleMatrix.wrap(Ut).mult(B).mult(SimpleMatrix.wrap(Vt).transpose()).print(); printMatrix(); System.out.println("bulge = "+bulge); System.out.println();
777	allow more convergence time
778	(numExceptional+1)*

EJML/xml/org/ejml/alg/dense/decomposition/svd/SafeSvd.xml
33	the decomposition algorithm
35	storage for the input if it would be modified

EJML/xml/org/ejml/alg/dense/decomposition/svd/SvdImplicitQrDecompose.xml
52	dimensions of transposed matrix
56	if true then it can use the special Bidiagonal decomposition
59	If U is not being computed and the input matrix is 'tall' then a special bidiagonal decomposition can be used which is faster.
73	compute a compact SVD
75	What is actually computed
79	What the user requested to be computed If the transpose is computed instead then what is actually computed is swapped
84	Should it compute the transpose instead
87	Either a copy of the input matrix or a copy of it transposed
196	make sure all the singular values or positive
199	if transposed undo the transposition
211	change the matrix to bidiagonal form
240	long pointA = System.currentTimeMillis();
241	compute U and V matrices
257	long pointB = System.currentTimeMillis();
261	long pointC = System.currentTimeMillis(); System.out.println("  compute UV "+(pointB-pointA)+"  QR = "+(pointC-pointB));
270	flag what should be computed and what should not be computed
291	if it is a tall matrix and U is not needed then there is faster decomposition algorithm
316	compute the results of multiplying it by an element of -1 at this location in a diagonal matrix.

EJML/xml/org/ejml/alg/dense/decomposition/TriangularSolver.xml
92	for( int i = 0; i < n; i++ ) { double sum = b[i]; for( int k=0; k<i; k++ ) { sum -= L[i*n+k]* b[k]; } b[i] = sum / L[i*n+i]; }
175	for( int i =n-1; i>=0; i-- ) { double sum = b[i]; for( int j = i+1; j <n; j++ ) { sum -= U[i*n+j]* b[j]; } b[i] = sum/U[i*n+i]; }
194	for( int i =maxRow-1; i>=minRow; i-- ) { double sum = b[i]; for( int j = i+1; j <maxRow; j++ ) { sum -= U[i*sideLength+j]* b[j]; } b[i] = sum/U[i*sideLength+i]; }
243	todo comment out the above and optimize it

EJML/xml/org/ejml/alg/dense/linsol/AdjustableLinearSolver.xml

EJML/xml/org/ejml/alg/dense/linsol/chol/LinearSolverChol.xml
103	solve L*y=b storing y in x
106	solve L^T*x=y
137	TODO reorder these operations to avoid cache misses
139	inverts the lower triangular system and saves the result in the upper triangle to minimize cache misses
151	solve the system and handle the previous solution being in the upper triangle takes advantage of symmetry

EJML/xml/org/ejml/alg/dense/linsol/chol/LinearSolverCholBlock64.xml
52	since overwrite B is true X does not need to be passed in

EJML/xml/org/ejml/alg/dense/linsol/chol/LinearSolverCholLDL.xml
105	solve L*s=b storing y in x
108	solve D*y=s
113	solve L^T*x=y
130	solve L*z = b
141	solve D*y=z
149	solve L^T*x = y

EJML/xml/org/ejml/alg/dense/linsol/InvertUsingSolve.xml

EJML/xml/org/ejml/alg/dense/linsol/LinearSolverAbstract.xml

EJML/xml/org/ejml/alg/dense/linsol/LinearSolverSafe.xml
35	the solver it is wrapped around
38	local copies of input matrices that can be modified.

EJML/xml/org/ejml/alg/dense/linsol/LinearSolverUnrolled.xml

EJML/xml/org/ejml/alg/dense/linsol/lu/LinearSolverLu.xml
59	for( int j = 0; j < numCols; j++ ) { for( int i = 0; i < this.numCols; i++ ) vv[i] = dataB[i*numCols+j]; decomp._solveVectorInternal(vv); for( int i = 0; i < this.numCols; i++ ) dataX[i*numCols+j] = vv[i]; }

EJML/xml/org/ejml/alg/dense/linsol/lu/LinearSolverLuBase.xml
64	don't need to change inv into an identity matrix before hand
67	for( int i = 0; i < n; i++ ) dataInv[i* n +j] = vv[i];
97	BigDecimal sdp = new BigDecimal(0);
100	*NOTE* in the book this is a long double.  extra precision might be required
102	BigDecimal sdp = new BigDecimal(-dataB[ i * nc + k]);
105	sdp = sdp.add( BigDecimal.valueOf(dataA[i* n +j] * dataX[ j * nc + k]));
108	vv[i] = sdp.doubleValue();

EJML/xml/org/ejml/alg/dense/linsol/lu/LinearSolverLuKJI.xml
74	Copy right hand side with pivoting
78	Solve L*Y = B(piv,:)
86	Solve U*X = Y;

EJML/xml/org/ejml/alg/dense/linsol/qr/AdjLinearSolverQr.xml
47	allow it some room to grow
74	see if it needs to grow the data structures
76	grow by 10%

EJML/xml/org/ejml/alg/dense/linsol/qr/BaseLinearSolverQrp.xml
74	if true then only the basic solution will be found
80	stores sub-matrices inside the R matrix
83	store an identity matrix for computing the inverse
86	rank of the system matrix
91	used to compute optimal 2-norm solution
124	extract the r11 triangle sub matrix
129	extract the R12 sub-matrix
133	W=inv(R11)*R12
136	set the identity matrix in the upper portion
173	recycle Y
175	compute the z which will minimize the 2-norm of X because of the identity matrix tacked onto the end 'A' should never be singular
182	compute X by tweaking the original

EJML/xml/org/ejml/alg/dense/linsol/qr/LinearSolverQr.xml
127	solve each column one by one
130	make a copy of this column in the vector
135	Solve Qa=b a = Q'b
139	solve for Rx = b using the standard upper triangular solver
142	save the results

EJML/xml/org/ejml/alg/dense/linsol/qr/LinearSolverQrBlock64.xml

EJML/xml/org/ejml/alg/dense/linsol/qr/LinearSolverQrHouse.xml
111	solve each column one by one
114	make a copy of this column in the vector
119	Solve Qa=b a = Q'b a = Q_{n-1}...Q_2*Q_1*b  Q_n*b = (I-gamma*u*u^T)*b = b - u*(gamma*U^T*b)
127	U^T*b
132	gamma*U^T*b
140	solve for Rx = b using the standard upper triangular solver
143	save the results

EJML/xml/org/ejml/alg/dense/linsol/qr/LinearSolverQrHouseCol.xml
58	a column major QR matrix
118	solve each column one by one
121	make a copy of this column in the vector
126	Solve Qa=b a = Q'b a = Q_{n-1}...Q_2*Q_1*b  Q_n*b = (I-gamma*u*u^T)*b = b - u*(gamma*U^T*b)
140	solve for Rx = b using the standard upper triangular solver
143	save the results

EJML/xml/org/ejml/alg/dense/linsol/qr/LinearSolverQrHouseTran.xml
56	a column major QR matrix
93	even those it is transposed the diagonal elements are at the same elements
117	solve each column one by one
120	make a copy of this column in the vector
125	Solve Qa=b a = Q'b a = Q_{n-1}...Q_2*Q_1*b  Q_n*b = (I-gamma*u*u^T)*b = b - u*(gamma*U^T*b)
134	U^T*b
139	gamma*U^T*b
149	solve for Rx = b using the standard upper triangular solver
152	save the results

EJML/xml/org/ejml/alg/dense/linsol/qr/LinearSolverQrpHouseCol.xml
37	Computes the QR decomposition
40	storage for basic solution
59	get the pivots and transpose them
65	solve each column one by one
70	make a copy of this column in the vector
75	Solve Q*x=b => x = Q'*b Q_n*b = (I-gamma*u*u^T)*b = b - u*(gamma*U^T*b)
86	solve for Rx = b using the standard upper triangular solver
89	finish the basic solution by filling in zeros
97	save the results

EJML/xml/org/ejml/alg/dense/linsol/qr/SolvePseudoInverseQrp.xml
37	stores the orthogonal Q matrix from QR decomposition
40	storage for basic solution
75	get the pivots and transpose them
78	solve each column one by one
83	make a copy of this column in the vector
88	Solve Q*a=b => a = Q'*b
91	solve for Rx = b using the standard upper triangular solver
94	finish the basic solution by filling in zeros
102	save the results

EJML/xml/org/ejml/alg/dense/linsol/svd/SolvePseudoInverseSvd.xml
47	Used to compute pseudo inverse
50	the results of the pseudo-inverse
53	relative threshold used to select singular values
86	compute the threshold for singular values which are to be zeroed
95	computer the pseudo inverse of A
104	V*W
112	V*W*U^T

EJML/xml/org/ejml/alg/dense/linsol/WrapLinearSolverBlock64.xml
39	block matrix copy of the system A matrix.
41	block matrix copy of B matrix passed into solve
43	block matrix copy of X matrix passed into solve

EJML/xml/org/ejml/alg/dense/misc/DeterminantFromMinor.xml
49	how wide the square matrix is
52	used to decide at which point it uses a direct algorithm to compute the determinant
55	used to keep track of which submatrix it is computing the results for
57	the results at different levels of minor matrices
59	which columns where removed at what level
62	columns that are currently open
65	a minor matrix which is created at the lowest level
119	make sure everything is in the proper state before it starts
122	System.arraycopy(mat.data,0,minorMatrix[0],0,mat.data.length);
164	put it back into the list

EJML/xml/org/ejml/alg/dense/misc/ImplCommonOps_DenseMatrix64F.xml

EJML/xml/org/ejml/alg/dense/misc/ImplCommonOps_Matrix64F.xml

EJML/xml/org/ejml/alg/dense/misc/NaiveDeterminant.xml

EJML/xml/org/ejml/alg/dense/misc/PermuteArray.xml
34	used by next
71	Is there a way to compute the parity while performing the permutations making this much less expensive
155	boolean foundZero = false;
164	a new permutation has been created return the results.

EJML/xml/org/ejml/alg/dense/misc/RrefGaussJordanRowPivot.xml
32	tolerance for singular matrix
45	number of leading ones which have been found
47	compute the decomposition
50	select the row to pivot by finding the row with the largest column in 'i'
66	perform the row pivot NOTE: performance could be improved by delaying the physical swap of rows until the end and using a technique which does the minimal number of swaps
72	zero column 'i' in all but the pivot row
86	update the pivot row

EJML/xml/org/ejml/alg/dense/misc/TransposeAlgs.xml
77	int indexSrc = i*A.numCols + j; int indexDst = j*A_tran.numCols + i;
81	for( int l = 0; l < blockWidth; l++ , indexSrc++ ) {
86	for( int k = 0; k < blockHeight; k++ , rowSrc += A.numCols ) {
88	faster to write in sequence than to read in sequence

EJML/xml/org/ejml/alg/dense/misc/UnrolledDeterminantFromMinor.xml

EJML/xml/org/ejml/alg/dense/misc/UnrolledInverseFromMinor.xml

EJML/xml/org/ejml/alg/dense/mult/GeneratorMatrixMatrixMult.xml
164	make the op name

EJML/xml/org/ejml/alg/dense/mult/MatrixDimensionException.xml

EJML/xml/org/ejml/alg/dense/mult/MatrixMatrixMult.xml
82	need to assign c.data to a value initially
93	now add to it
94	k loop
100	j loop
158	create a copy of the column in B to avoid cache issues
192	first assign R
200	now increment it
205	this is the loop for j
236	loop for k
366	need to assign c.data to a value initially
377	now add to it
378	k loop
384	j loop
442	create a copy of the column in B to avoid cache issues
476	first assign R
484	now increment it
489	this is the loop for j
520	loop for k
650	need to assign c.data to a value initially
661	now add to it
662	k loop
668	j loop
726	create a copy of the column in B to avoid cache issues
760	first assign R
768	now increment it
773	this is the loop for j
804	loop for k
934	need to assign c.data to a value initially
945	now add to it
946	k loop
952	j loop
1010	create a copy of the column in B to avoid cache issues
1044	first assign R
1052	now increment it
1057	this is the loop for j
1088	loop for k

EJML/xml/org/ejml/alg/dense/mult/MatrixMultProduct.xml
53	for( int i = 0; i < a.numRows; i++ ) { for( int j = 0; j < a.numRows; j++ ) { double sum = 0; for( int k = 0; k < a.numCols; k++ ) { sum += a.get(i,k)*a.get(j,k); } c.set(i,j,sum); } }
80	for( int i = 0; i < a.numCols; i++ ) { for( int j = i; j < a.numCols; j++ ) { double sum = 0; for( int k = 0; k < a.numRows; k++ ) { sum += a.get(k,i)*a.get(k,j); } c.set(i,j,sum); c.set(j,i,sum); } }
117	for( int i = 0; i < a.numCols; i++ ) { for( int j = i; j < a.numCols; j++ ) { c.set(i,j,a.get(0,i)*a.get(0,j)); }  for( int k = 1; k < a.numRows; k++ ) { for( int j = i; j < a.numCols; j++ ) { c.set(i,j, c.get(i,j)+ a.get(k,i)*a.get(k,j)); } } for( int j = i; j < a.numCols; j++ ) { c.set(j,i,c.get(i,j)); } }

EJML/xml/org/ejml/alg/dense/mult/MatrixVectorMult.xml

EJML/xml/org/ejml/alg/dense/mult/SubmatrixOps.xml

EJML/xml/org/ejml/alg/dense/mult/VectorVectorMult.xml
33	TODO write this
40	TODO create a VectorOps for meer mortals to use? TODO have DenseMatrix64F flag itself as being a vector to make checks faster?
44	sanity check inputs
46	call the outer or inner product
124	TODO better name for this

EJML/xml/org/ejml/alg/fixed/FixedOps2.xml

EJML/xml/org/ejml/alg/fixed/FixedOps3.xml

EJML/xml/org/ejml/alg/fixed/FixedOps4.xml

EJML/xml/org/ejml/alg/fixed/FixedOps5.xml

EJML/xml/org/ejml/alg/fixed/FixedOps6.xml

EJML/xml/org/ejml/alg/generic/CodeGeneratorMisc.xml

EJML/xml/org/ejml/alg/generic/GenericMatrixOps.xml
31	public static DenseD2Matrix64F convertToD2( DenseMatrix64F orig ) { DenseD2Matrix64F ret = new DenseD2Matrix64F(orig.numRows,orig.numCols);  copy(orig,ret);  return ret; }

EJML/xml/org/ejml/data/BlockMatrix64F.xml
104	find the block it is inside

EJML/xml/org/ejml/data/Complex64F.xml

EJML/xml/org/ejml/data/D1Matrix64F.xml
102	See benchmarkFunctionReturn.  Pointless return does not degrade performance.  Tested on JDK 1.6.0_21
122	See benchmarkFunctionReturn.  Pointless return does not degrade performance.  Tested on JDK 1.6.0_21
142	See benchmarkFunctionReturn.  Pointless return does not degrade performance.  Tested on JDK 1.6.0_21
162	See benchmarkFunctionReturn.  Pointless return does not degrade performance.  Tested on JDK 1.6.0_21
182	See benchmarkFunctionReturn.  Pointless return does not degrade performance.  Tested on JDK 1.6.0_21

EJML/xml/org/ejml/data/D1Submatrix64F.xml
39	bounding rows and columns

EJML/xml/org/ejml/data/DenseMatrix64F.xml
278	todo move to commonops

EJML/xml/org/ejml/data/Eigenpair.xml

EJML/xml/org/ejml/data/FixedMatrix2_64F.xml

EJML/xml/org/ejml/data/FixedMatrix2x2_64F.xml

EJML/xml/org/ejml/data/FixedMatrix3_64F.xml

EJML/xml/org/ejml/data/FixedMatrix3x3_64F.xml

EJML/xml/org/ejml/data/FixedMatrix4_64F.xml

EJML/xml/org/ejml/data/FixedMatrix4x4_64F.xml

EJML/xml/org/ejml/data/FixedMatrix5_64F.xml

EJML/xml/org/ejml/data/FixedMatrix5x5_64F.xml

EJML/xml/org/ejml/data/FixedMatrix64F.xml

EJML/xml/org/ejml/data/FixedMatrix6_64F.xml

EJML/xml/org/ejml/data/FixedMatrix6x6_64F.xml

EJML/xml/org/ejml/data/Matrix64F.xml

EJML/xml/org/ejml/data/MatrixIterator.xml
33	the matrix which is being iterated through
36	should it iterate through by row or by column
39	the first row and column it returns
43	where in the iteration it is
45	how many elements inside will it return
48	how wide the submatrix is
51	the current element

EJML/xml/org/ejml/data/ReshapeMatrix64F.xml

EJML/xml/org/ejml/data/RowD1Matrix64F.xml

EJML/xml/org/ejml/EjmlParameters.xml

EJML/xml/org/ejml/factory/CholeskyDecomposition.xml

EJML/xml/org/ejml/factory/DecompositionFactory.xml
123	Don't allow the tall decomposition by default since it *might* be less stable

EJML/xml/org/ejml/factory/DecompositionInterface.xml

EJML/xml/org/ejml/factory/EigenDecomposition.xml

EJML/xml/org/ejml/factory/LinearSolver.xml

EJML/xml/org/ejml/factory/LinearSolverFactory.xml

EJML/xml/org/ejml/factory/LUDecomposition.xml

EJML/xml/org/ejml/factory/QRDecomposition.xml

EJML/xml/org/ejml/factory/QRPDecomposition.xml

EJML/xml/org/ejml/factory/ReducedRowEchelonForm.xml

EJML/xml/org/ejml/factory/SingularMatrixException.xml

EJML/xml/org/ejml/factory/SingularValueDecomposition.xml

EJML/xml/org/ejml/ops/CommonOps.xml
97	TODO add a matrix vectory multiply here
120	todo check a.numCols == 1 and do inner product? there are significantly faster algorithms when dealing with vectors
150	TODO add a matrix vectory multiply here
195	TODO add a matrix vectory multiply here
214	there are significantly faster algorithms when dealing with vectors
242	TODO add a matrix vectory multiply here
341	TODO add a matrix vectory multiply here
394	TODO add a matrix vectory multiply here
435	TODO add a matrix vectory multiply here
454	there are significantly faster algorithms when dealing with vectors
482	TODO add a matrix vectory multiply here
522	make sure the inputs 'a' and 'b' are not modified
624	slight performance boost overall by doing it this way when it was the case statement the VM did some strange optimization and made case 2 about 1/2 the speed
982	TODO see comment below this will work well for small matrices but an alternative version should be made for large matrices
1038	interestingly, the performance is only different for small matrices but identical for larger ones
1679	on very small matrices (2 by 2) the call to getNumElements() can slow it down slightly compared to other libraries since it involves an extra multiplication.

EJML/xml/org/ejml/ops/ConvertMatrixType.xml

EJML/xml/org/ejml/ops/CovarianceOps.xml
102	wrap it to make sure the covariance is not modified.

EJML/xml/org/ejml/ops/CovarianceRandomDraw.xml

EJML/xml/org/ejml/ops/EigenOps.xml
91	perturb the eigenvalue slightly so that its not an exact solution the first time
92	eigenvalue -= eigenvalue*UtilEjml.EPS*10;
109	if the matrix is singular then the eigenvalue is within machine precision of the true value, meaning that x must also be.
117	see if solve silently failed
124	if it failed on the first trial try perturbing it some more
126	maybe this should be turn into a parameter allowing the user to configure the wise of each step
132	otherwise assume that it was so accurate that the matrix was singular and return that result
142	compute the residual
147	if the error increased it is probably converging towards a different eigenvalue
149	CommonOps.set(b,1);
155	see if it has converged
159	update everything
185	TODO maybe do the regular power method, estimate the eigenvalue, then shift invert?
190	eh maybe 0.1 is a good value.  who knows.
194	power.getEigenVector();

EJML/xml/org/ejml/ops/EjmlUnitTests.xml
179	if turned on use asserts
181	otherwise throw an exception

EJML/xml/org/ejml/ops/MatrixComponent.xml

EJML/xml/org/ejml/ops/MatrixFeatures.xml
555	TODO write this
420	if either is negative or positive infinity the result will be positive infinity if either is NaN the result will be NaN
424	diff = NaN == false diff = infinity == false
480	LU decomposition
488	if they are linearly independent it should not be singular
501	see if the result is an identity matrix
528	see if the result is an identity matrix

EJML/xml/org/ejml/ops/MatrixIO.xml
200	public static void main( String []args ) { Random rand = new Random(234234); DenseMatrix64F A = RandomMatrices.createRandom(50,70,rand);  SingularValueDecomposition decomp = DecompositionFactory.svd();  decomp.decompose(A);  displayMatrix(A,"Original"); displayMatrix(decomp.getU(false),"U"); displayMatrix(decomp.getV(false),"V"); displayMatrix(decomp.getW(null),"W"); }
53	clean up

EJML/xml/org/ejml/ops/MatrixVisualization.xml

EJML/xml/org/ejml/ops/NormOps.xml
108	square matrices are the typical case
430	the largest singular value is the induced p2 norm

EJML/xml/org/ejml/ops/RandomMatrices.xml
57	is there a faster algorithm out there? This one is a bit sluggish
68	System.out.println(" i = "+i);
73	System.out.println("j = "+j);
77	find a vector that is normal to vector j u[i] = (1/2)*(r + Q[j]*r)
84	UtilEjml.print(a);
90	normalize it so it doesn't get too small
353	This is not formally proven to work.  It just seems to work.

EJML/xml/org/ejml/ops/ReadCsv.xml
44	if there is a comment character
46	what the comment character is
49	reader for the input stream
52	number of lines that have been read
106	skip comment lines
112	extract the words, which are the variables encoded
131	see if its at the end of a word
144	if the line ended add the final word

EJML/xml/org/ejml/ops/ReadMatrixCsv.xml

EJML/xml/org/ejml/ops/SingularOps.xml
50	TODO the number of copies can probably be reduced here
63	find the smallest singular value in the submatrix
73	only swap if the current index is not the smallest
78	there is at least one uncountable singular value.  just stop here
114	checkSvdMatrixSize(U, tranU, W, V, tranV);
120	find the smallest singular value in the submatrix
130	only swap if the current index is not the smallest
135	there is at least one uncountable singular value.  just stop here
190	swap the rows
197	swap the columns
234	first determine the size of the null space
243	declare output data
250	now extract the vectors
312	find the smallest singular value
323	extract the null space

EJML/xml/org/ejml/ops/SpecializedOps.xml
390	TODO make faster by just checking the upper triangular portion

EJML/xml/org/ejml/simple/SimpleBase.xml
914	see if its a DenseMatrix64F
918	if not convert it into one and wrap it
954	see if its a DenseMatrix64F
958	if not convert it into one and wrap it

EJML/xml/org/ejml/simple/SimpleEVD.xml

EJML/xml/org/ejml/simple/SimpleMatrix.xml
259	TODO should this function be added back?  It makes the code hard to read when its used
260	/** * <p> * Performs one of the following matrix multiplication operations:<br> * <br> * c = a * b <br> * c = a<sup>T</sup> * b <br> * c = a * b <sup>T</sup><br> * c = a<sup>T</sup> * b <sup>T</sup><br> * <br> * where c is the returned matrix, a is this matrix, and b is the passed in matrix. * </p> * * @see CommonOps#mult(DenseMatrix64F, DenseMatrix64F, DenseMatrix64F) * @see CommonOps#multTransA(DenseMatrix64F, DenseMatrix64F, DenseMatrix64F) * @see CommonOps#multTransB(DenseMatrix64F, DenseMatrix64F, DenseMatrix64F) * @see CommonOps#multTransAB(DenseMatrix64F, DenseMatrix64F, DenseMatrix64F) * * @param tranA If true matrix A is transposed. * @param tranB If true matrix B is transposed. * @param b A matrix that is n by bn. Not modified. * * @return The results of this operation. */ public SimpleMatrix mult( boolean tranA , boolean tranB , SimpleMatrix b) { SimpleMatrix ret;  if( tranA && tranB ) { ret = createMatrix(mat.numCols,b.mat.numRows); CommonOps.multTransAB(mat,b.mat,ret.mat); } else if( tranA ) { ret = createMatrix(mat.numCols,b.mat.numCols); CommonOps.multTransA(mat,b.mat,ret.mat); } else if( tranB ) { ret = createMatrix(mat.numRows,b.mat.numRows); CommonOps.multTransB(mat,b.mat,ret.mat); }  else  { ret = createMatrix(mat.numRows,b.mat.numCols); CommonOps.mult(mat,b.mat,ret.mat); }  return ret; }

EJML/xml/org/ejml/simple/SimpleSVD.xml
60	order singular values from largest to smallest
118	TODO take advantage of the singular values being ordered already

EJML/xml/org/ejml/UtilEjml.xml
96	there is the possibility the first element could be empty
99	covert it from string to doubles

