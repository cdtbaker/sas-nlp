package sasnlp.nlpstats.output;

import java.text.DecimalFormat;
import java.util.HashMap;
import java.util.Map.Entry;

import javax.xml.xpath.XPathExpressionException;

import org.w3c.dom.Element;

import sasnlp.nlpstats.core.NGramParser;
import sasnlp.nlpstats.core.PMI;
import edu.stanford.nlp.stats.Counter;

public class PMIWriter extends XMLWriter {

	private NGramParser biGramExtractor = null;
	private Counter<String> words = null;
	private Counter<String> wordsGeneral = null;
	private Counter<String> wordsDomain = null;
	private HashMap<String, HashMap<String, Float>> tdidfWORDSPerDoc = null;
	private HashMap<String, HashMap<String, Float>> tdidfNGRAMSPerDoc = null;
	private HashMap<String, NGramParser> ngramsperdoc = null;

	public PMIWriter(NGramParser biGramExtractor, Counter<String> words,
			HashMap<String, HashMap<String, Float>> tdidfWORDSPerDoc,
			HashMap<String, HashMap<String, Float>> tdidfNGRAMPerDoc,
			Counter<String> wordsGeneral, Counter<String> wordsDomain,
			HashMap<String, NGramParser> ngramsPerDoc) {
		super("pmi", "xmlstylesheet");

		this.biGramExtractor = biGramExtractor;
		this.words = words;
		this.tdidfWORDSPerDoc = tdidfWORDSPerDoc;
		this.tdidfNGRAMSPerDoc = tdidfNGRAMPerDoc;

		this.wordsDomain = wordsDomain;
		this.wordsGeneral = wordsGeneral;
		this.ngramsperdoc = ngramsPerDoc;
	}

	@Override
	protected void generateXMLContents() throws XPathExpressionException {

		root().setAttribute("countBiGrams",
				String.valueOf(biGramExtractor.getNgramCount()));
		for (Entry<String, Integer> i : biGramExtractor.getNGramMap().entrySet()) {
			String[] s = i.getKey().split(" ");

			double pw1w2 = ((double) i.getValue() / (double) biGramExtractor
					.getNgramCount());
			double pw1 = (words.getCount(s[0]) / words.totalCount());
			double pw2 = (words.getCount(s[1]) / words.totalCount());

			Element bigram = doc().createElement("bigram");
			bigram.setAttribute("first", s[0]);
			bigram.setAttribute("firstFreq",
					String.valueOf(words.getCount(s[0])));
			bigram.setAttribute("second", s[1]);
			bigram.setAttribute("secondFreq",
					String.valueOf(words.getCount(s[1])));
			bigram.setAttribute("bigram", i.getKey());
			bigram.setAttribute("bigramFreq", String.valueOf(i.getValue()));
			bigram.setAttribute("pmi",
					String.valueOf(PMI.calculate(pw1, pw2, pw1w2)));

			// TFIDF tfidf = new TFIDF();
			bigram.setAttribute("pmi",
					String.valueOf(PMI.calculate(pw1, pw2, pw1w2)));

			root().appendChild(bigram);
		}

		Element docs = doc().createElement("docs");

		for (Entry<String, HashMap<String, Float>> td : tdidfWORDSPerDoc
				.entrySet()) {
			Element doc = doc().createElement("doc");
			doc.setAttribute("name", td.getKey());

			Element tdidfs = doc().createElement("tdidfs");

			for (Entry<String, Float> sdf : td.getValue().entrySet()) {
				Element tdidf = doc().createElement("tdidf");
				tdidf.setAttribute("word", sdf.getKey());

				DecimalFormat df = new DecimalFormat("0.0000000000000");

				tdidf.setAttribute("tdidf", df.format(sdf.getValue()));

				double domainspecificity = 0;

				double occurWord_Domain = wordsDomain.getCount(sdf.getKey());
				double occurWord_General = wordsGeneral.getCount(sdf.getKey());

				if (occurWord_General == 0)
					occurWord_General = 1;

				double totalWord_Domain = wordsDomain.totalCount();
				double totalWord_General = wordsGeneral.totalCount();

				domainspecificity = occurWord_Domain / totalWord_Domain
						/ occurWord_General / totalWord_General;

				if (td.getKey().contains("domain"))
					tdidf.setAttribute("domainspecificity",
							df.format(domainspecificity));

				tdidfs.appendChild(tdidf);
			}

			doc.appendChild(tdidfs);
			docs.appendChild(doc);
		}

		Element docsNGrams = doc().createElement("docsNGrams");

		for (Entry<String, HashMap<String, Float>> td : tdidfNGRAMSPerDoc
				.entrySet()) {
			Element doc = doc().createElement("doc");
			doc.setAttribute("name", td.getKey());

			Element tdidfs = doc().createElement("tdidfs");

			for (Entry<String, Float> sdf : td.getValue().entrySet()) {
				Element tdidf = doc().createElement("tdidf");
				tdidf.setAttribute("word", sdf.getKey());

				DecimalFormat df = new DecimalFormat("0.0000000000000");

				tdidf.setAttribute("tdidf", df.format(sdf.getValue()));

				double domainspecificity = 0;

				double occurWord_Domain = 0;

				if (ngramsperdoc.get("Comment - domain").getNGramMap()
						.get(sdf.getKey()) != null)
					occurWord_Domain = ngramsperdoc.get("Comment - domain")
							.getNGramMap().get(sdf.getKey());

				double occurWord_General = 1;

				if (ngramsperdoc.get("SO - general").getNGramMap()
						.get(sdf.getKey()) != null)
					occurWord_General = ngramsperdoc.get("SO - general")
							.getNGramMap().get(sdf.getKey());

				double totalWord_Domain = ngramsperdoc.get("Comment - domain")
						.getNgramCount();
				double totalWord_General = ngramsperdoc.get("SO - general")
						.getNgramCount();

				domainspecificity = occurWord_Domain / totalWord_Domain
						/ occurWord_General / totalWord_General;

				System.out.println("WORD: " + sdf.getKey());
				System.out.println("occurWord_Domain: " + occurWord_Domain);
				System.out.println("occurWord_General: " + occurWord_General);
				System.out.println("totalWord_Domain: " + totalWord_Domain);
				System.out.println("totalWord_General: " + totalWord_General);

				if (td.getKey().contains("domain"))
					tdidf.setAttribute("domainspecificity",
							df.format(domainspecificity));

				tdidfs.appendChild(tdidf);
			}

			doc.appendChild(tdidfs);
			docsNGrams.appendChild(doc);
		}

		root().appendChild(docsNGrams);
		root().appendChild(docs);
	}

	@Override
	public String getXMLFilename() {
		return "NLP_XML.xml";
	}

}
