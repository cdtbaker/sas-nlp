<?xml version="1.0" encoding="UTF-8"?>
<source package="org.apache.commons.math3.optimization.general">
  <import name="org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction" />
  <import name="org.apache.commons.math3.analysis.FunctionUtils" />
  <import name="org.apache.commons.math3.analysis.differentiation.DerivativeStructure" />
  <import name="org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction" />
  <import name="org.apache.commons.math3.exception.DimensionMismatchException" />
  <import name="org.apache.commons.math3.exception.NumberIsTooSmallException" />
  <import name="org.apache.commons.math3.exception.util.LocalizedFormats" />
  <import name="org.apache.commons.math3.linear.ArrayRealVector" />
  <import name="org.apache.commons.math3.linear.RealMatrix" />
  <import name="org.apache.commons.math3.linear.DiagonalMatrix" />
  <import name="org.apache.commons.math3.linear.DecompositionSolver" />
  <import name="org.apache.commons.math3.linear.MatrixUtils" />
  <import name="org.apache.commons.math3.linear.QRDecomposition" />
  <import name="org.apache.commons.math3.linear.EigenDecomposition" />
  <import name="org.apache.commons.math3.optimization.OptimizationData" />
  <import name="org.apache.commons.math3.optimization.InitialGuess" />
  <import name="org.apache.commons.math3.optimization.Target" />
  <import name="org.apache.commons.math3.optimization.Weight" />
  <import name="org.apache.commons.math3.optimization.ConvergenceChecker" />
  <import name="org.apache.commons.math3.optimization.DifferentiableMultivariateVectorOptimizer" />
  <import name="org.apache.commons.math3.optimization.PointVectorValuePair" />
  <import name="org.apache.commons.math3.optimization.direct.BaseAbstractMultivariateVectorOptimizer" />
  <import name="org.apache.commons.math3.util.FastMath" />
  <class name="AbstractLeastSquaresOptimizer" extends="BaseAbstractMultivariateVectorOptimizer<DifferentiableMultivariateVectorFunction>" startLine="44">
    <implements name="DifferentiableMultivariateVectorOptimizer" />
    <javadoc>
      <text>* Base class for implementing least squares optimizers.
 * It handles the boilerplate methods associated to thresholds settings,
 * Jacobian and error estimation.
 * <br/>
 * This class constructs the Jacobian matrix of the function argument in method{@link BaseAbstractMultivariateVectorOptimizer#optimize(int,MultivariateVectorFunction,OptimizationData[])optimize} and assumes that the rows of that matrix iterate on the model
 * functions while the columns iterate on the parameters; thus, the numbers
 * of rows is equal to the dimension of the{@link org.apache.commons.math3.optimization.Target Target} while
 * the number of columns is equal to the dimension of the{@link org.apache.commons.math3.optimization.InitialGuess InitialGuess}.</text>
      <version>$Id: AbstractLeastSquaresOptimizer.java 1426759 2012-12-29 13:26:44Z erans $</version>
      <deprecated>As of 3.1 (to be removed in 4.0).</deprecated>
      <since>1.2</since>
    </javadoc>
    <javadoc>
      <text>* Singularity threshold (cf. {@link #getCovariances(double)}).</text>
      <deprecated>As of 3.1.</deprecated>
    </javadoc>
    <declaration type="double" name="DEFAULT_SINGULARITY_THRESHOLD" />
    <javadoc>
      <text>* Jacobian matrix of the weighted residuals.
 * This matrix is in canonical form just after the calls to{@link #updateJacobian()}, but may be modified by the solver
 * in the derived class (the {@link LevenbergMarquardtOptimizerLevenberg-Marquardt optimizer} does this).</text>
      <deprecated>As of 3.1. To be removed in 4.0. Please use{@link #computeWeightedJacobian(double[])} instead.</deprecated>
    </javadoc>
    <declaration type="double[][]" name="weightedResidualJacobian" />
    <javadoc>
      <text>* Number of columns of the jacobian matrix.</text>
      <deprecated>As of 3.1.</deprecated>
    </javadoc>
    <declaration type="int" name="cols" />
    <javadoc>
      <text>* Number of rows of the jacobian matrix.</text>
      <deprecated>As of 3.1.</deprecated>
    </javadoc>
    <declaration type="int" name="rows" />
    <javadoc>
      <text>* Current point.</text>
      <deprecated>As of 3.1.</deprecated>
    </javadoc>
    <declaration type="double[]" name="point" />
    <javadoc>
      <text>* Current objective function value.</text>
      <deprecated>As of 3.1.</deprecated>
    </javadoc>
    <declaration type="double[]" name="objective" />
    <javadoc>
      <text>* Weighted residuals</text>
      <deprecated>As of 3.1.</deprecated>
    </javadoc>
    <declaration type="double[]" name="weightedResiduals" />
    <javadoc>
      <text>* Cost value (square root of the sum of the residuals).</text>
      <deprecated>As of 3.1. Field to become "private" in 4.0.
 * Please use {@link #setCost(double)}.</deprecated>
    </javadoc>
    <declaration type="double" name="cost" />
    <javadoc>
      <text>* Objective function derivatives.</text>
    </javadoc>
    <declaration type="MultivariateDifferentiableVectorFunction" name="jF" />
    <javadoc>
      <text>* Number of evaluations of the Jacobian.</text>
    </javadoc>
    <declaration type="int" name="jacobianEvaluations" />
    <javadoc>
      <text>* Square-root of the weight matrix.</text>
    </javadoc>
    <declaration type="RealMatrix" name="weightMatrixSqrt" />
    <javadoc>
      <text>* Simple constructor with default settings.
 * The convergence check is set to a {@link org.apache.commons.math3.optimization.SimpleVectorValueChecker}.</text>
      <deprecated>See {@link org.apache.commons.math3.optimization.SimpleValueChecker#SimpleValueChecker()}</deprecated>
    </javadoc>
    <method type="constructor" name="AbstractLeastSquaresOptimizer" startLine="128" endLine="128" />
    <javadoc>
      <param>checker Convergence checker.</param>
    </javadoc>
    <method type="constructor" name="AbstractLeastSquaresOptimizer" startLine="133" endLine="135" />
    <javadoc>
      <return>the number of evaluations of the Jacobian function.</return>
    </javadoc>
    <method type="int" name="getJacobianEvaluations" startLine="140" endLine="142" />
    <javadoc>
      <text>* Update the jacobian matrix.</text>
      <throws>DimensionMismatchException if the Jacobian dimension does not
 * match problem dimension.</throws>
      <deprecated>As of 3.1. Please use {@link #computeWeightedJacobian(double[])}instead.</deprecated>
    </javadoc>
    <method type="void" name="updateJacobian" startLine="153" endLine="156">
      <declaration type="RealMatrix" name="weightedJacobian" />
    </method>
    <javadoc>
      <text>* Computes the Jacobian matrix.</text>
      <param>params Model parameters at which to compute the Jacobian.</param>
      <return>the weighted Jacobian: W<sup>1/2</sup> J.</return>
      <throws>DimensionMismatchException if the Jacobian dimension does not
 * match problem dimension.</throws>
      <since>3.1</since>
    </javadoc>
    <method type="RealMatrix" name="computeWeightedJacobian" startLine="167" endLine="191">
      <declaration type="DerivativeStructure[]" name="dsPoint" />
      <declaration type="int" name="nC" />
      <scope startLine="172" endLine="174" />
      <declaration type="DerivativeStructure[]" name="dsValue" />
      <declaration type="int" name="nR" />
      <scope startLine="177" endLine="179" />
      <declaration type="double[][]" name="jacobianData" />
      <scope startLine="181" endLine="188">
        <declaration type="int[]" name="orders" />
        <scope startLine="183" endLine="187" />
      </scope>
    </method>
    <javadoc>
      <text>* Update the residuals array and cost function value.</text>
      <throws>DimensionMismatchException if the dimension does not match the
 * problem dimension.</throws>
      <throws>org.apache.commons.math3.exception.TooManyEvaluationsExceptionif the maximal number of evaluations is exceeded.</throws>
      <deprecated>As of 3.1. Please use {@link #computeResiduals(double[])},{@link #computeObjectiveValue(double[])}, {@link #computeCost(double[])}and {@link #setCost(double)} instead.</deprecated>
    </javadoc>
    <method type="void" name="updateResidualsAndCost" startLine="204" endLine="214">
      <declaration type="double[]" name="res" />
      <declaration type="ArrayRealVector" name="residuals" />
      <comment>Compute cost.</comment>
      <comment>Compute weighted residuals.</comment>
    </method>
    <javadoc>
      <text>* Computes the cost.</text>
      <param>residuals Residuals.</param>
      <return>the cost.</return>
      <see>#computeResiduals(double[])</see>
      <since>3.1</since>
    </javadoc>
    <method type="double" name="computeCost" startLine="224" endLine="227">
      <declaration type="ArrayRealVector" name="r" />
    </method>
    <javadoc>
      <text>* Get the Root Mean Square value.
 * Get the Root Mean Square value, i.e. the root of the arithmetic
 * mean of the square of all weighted residuals. This is related to the
 * criterion that is minimized by the optimizer as follows: if
 * <em>c</em> if the criterion, and <em>n</em> is the number of
 * measurements, then the RMS is <em>sqrt (c/n)</em>.</text>
      <return>RMS value</return>
    </javadoc>
    <method type="double" name="getRMS" startLine="239" endLine="241" />
    <javadoc>
      <text>* Get a Chi-Square-like value assuming the N residuals follow N
 * distinct normal distributions centered on 0 and whose variances are
 * the reciprocal of the weights.</text>
      <return>chi-square value</return>
    </javadoc>
    <method type="double" name="getChiSquare" startLine="249" endLine="251" />
    <javadoc>
      <text>* Gets the square-root of the weight matrix.</text>
      <return>the square-root of the weight matrix.</return>
      <since>3.1</since>
    </javadoc>
    <method type="RealMatrix" name="getWeightSquareRoot" startLine="259" endLine="261" />
    <javadoc>
      <text>* Sets the cost.</text>
      <param>cost Cost value.</param>
      <since>3.1</since>
    </javadoc>
    <method type="void" name="setCost" startLine="269" endLine="271" />
    <javadoc>
      <text>* Get the covariance matrix of the optimized parameters.</text>
      <return>the covariance matrix.</return>
      <throws>org.apache.commons.math3.linear.SingularMatrixExceptionif the covariance matrix cannot be computed (singular problem).</throws>
      <see>#getCovariances(double)</see>
      <deprecated>As of 3.1. Please use {@link #computeCovariances(double[],double)}instead.</deprecated>
    </javadoc>
    <method type="double[][]" name="getCovariances" startLine="284" endLine="286" />
    <javadoc>
      <text>* Get the covariance matrix of the optimized parameters.
 * <br/>
 * Note that this operation involves the inversion of the
 * <code>J<sup>T</sup>J</code> matrix, where {@code J} is the
 * Jacobian matrix.
 * The {@code threshold} parameter is a way for the caller to specify
 * that the result of this computation should be considered meaningless,
 * and thus trigger an exception.</text>
      <param>threshold Singularity threshold.</param>
      <return>the covariance matrix.</return>
      <throws>org.apache.commons.math3.linear.SingularMatrixExceptionif the covariance matrix cannot be computed (singular problem).</throws>
      <deprecated>As of 3.1. Please use {@link #computeCovariances(double[],double)}instead.</deprecated>
    </javadoc>
    <method type="double[][]" name="getCovariances" startLine="306" endLine="308" />
    <javadoc>
      <text>* Get the covariance matrix of the optimized parameters.
 * <br/>
 * Note that this operation involves the inversion of the
 * <code>J<sup>T</sup>J</code> matrix, where {@code J} is the
 * Jacobian matrix.
 * The {@code threshold} parameter is a way for the caller to specify
 * that the result of this computation should be considered meaningless,
 * and thus trigger an exception.</text>
      <param>params Model parameters.</param>
      <param>threshold Singularity threshold.</param>
      <return>the covariance matrix.</return>
      <throws>org.apache.commons.math3.linear.SingularMatrixExceptionif the covariance matrix cannot be computed (singular problem).</throws>
      <since>3.1</since>
    </javadoc>
    <method type="double[][]" name="computeCovariances" startLine="328" endLine="339">
      <declaration type="RealMatrix" name="j" />
      <declaration type="RealMatrix" name="jTj" />
      <declaration type="DecompositionSolver" name="solver" />
      <comment>Set up the Jacobian.</comment>
      <comment>Compute transpose(J)J.</comment>
      <comment>Compute the covariances matrix.</comment>
    </method>
    <javadoc>
      <text>* <p>
 * Returns an estimate of the standard deviation of each parameter. The
 * returned values are the so-called (asymptotic) standard errors on the
 * parameters, defined as {@code sd(a[i]) = sqrt(S / (n - m) * C[i][i])},
 * where {@code a[i]} is the optimized value of the {@code i}-th parameter,{@code S} is the minimized value of the sum of squares objective function
 * (as returned by {@link #getChiSquare()}), {@code n} is the number of
 * observations, {@code m} is the number of parameters and {@code C} is the
 * covariance matrix.
 * </p>
 * <p>
 * See also
 * <a href="http://en.wikipedia.org/wiki/Least_squares">Wikipedia</a>,
 * or
 * <a href="http://mathworld.wolfram.com/LeastSquaresFitting.html">MathWorld</a>,
 * equations (34) and (35) for a particular case.
 * </p></text>
      <return>an estimate of the standard deviation of the optimized parameters</return>
      <throws>org.apache.commons.math3.linear.SingularMatrixExceptionif the covariance matrix cannot be computed.</throws>
      <throws>NumberIsTooSmallException if the number of degrees of freedom is not
 * positive, i.e. the number of measurements is less or equal to the number of
 * parameters.</throws>
      <deprecated>as of version 3.1, {@link #computeSigma(double[],double)} should be used
 * instead. It should be emphasized that {@code guessParametersErrors} and{@code computeSigma} are <em>not</em> strictly equivalent.</deprecated>
    </javadoc>
    <method type="double[]" name="guessParametersErrors" startLine="371" endLine="383">
      <scope startLine="372" endLine="375" />
      <declaration type="double[]" name="errors" />
      <declaration type="double" name="c" />
      <declaration type="double[][]" name="covar" />
      <scope startLine="379" endLine="381" />
    </method>
    <javadoc>
      <text>* Computes an estimate of the standard deviation of the parameters. The
 * returned values are the square root of the diagonal coefficients of the
 * covariance matrix, {@code sd(a[i]) ~= sqrt(C[i][i])}, where {@code a[i]}is the optimized value of the {@code i}-th parameter, and {@code C} is
 * the covariance matrix.</text>
      <param>params Model parameters.</param>
      <param>covarianceSingularityThreshold Singularity threshold (see{@link #computeCovariances(double[],double) computeCovariances}).</param>
      <return>an estimate of the standard deviation of the optimized parameters</return>
      <throws>org.apache.commons.math3.linear.SingularMatrixExceptionif the covariance matrix cannot be computed.</throws>
      <since>3.1</since>
    </javadoc>
    <method type="double[]" name="computeSigma" startLine="401" endLine="409">
      <declaration type="int" name="nC" />
      <declaration type="double[]" name="sig" />
      <declaration type="double[][]" name="cov" />
      <scope startLine="405" endLine="407" />
    </method>
    <javadoc>
      <text>* {@inheritDoc}</text>
      <deprecated>As of 3.1. Please use{@link BaseAbstractMultivariateVectorOptimizer#optimize(int,MultivariateVectorFunction,OptimizationData[])optimize(int,MultivariateDifferentiableVectorFunction,OptimizationData...)}instead.</deprecated>
    </javadoc>
    <method type="PointVectorValuePair" name="optimize" startLine="422" endLine="428" />
    <javadoc>
      <text>* Optimize an objective function.
 * Optimization is considered to be a weighted least-squares minimization.
 * The cost function to be minimized is
 * <code>&sum;weight<sub>i</sub>(objective<sub>i</sub> - target<sub>i</sub>)<sup>2</sup></code></text>
      <param>f Objective function.</param>
      <param>target Target value for the objective functions at optimum.</param>
      <param>weights Weights for the least squares cost computation.</param>
      <param>startPoint Start point for optimization.</param>
      <return>the point/value pair giving the optimal value for objective
 * function.</return>
      <param>maxEval Maximum number of function evaluations.</param>
      <throws>org.apache.commons.math3.exception.DimensionMismatchExceptionif the start point dimension is wrong.</throws>
      <throws>org.apache.commons.math3.exception.TooManyEvaluationsExceptionif the maximal number of evaluations is exceeded.</throws>
      <throws>org.apache.commons.math3.exception.NullArgumentException if
 * any argument is {@code null}.</throws>
      <deprecated>As of 3.1. Please use{@link BaseAbstractMultivariateVectorOptimizer#optimize(int,MultivariateVectorFunction,OptimizationData[])optimize(int,MultivariateDifferentiableVectorFunction,OptimizationData...)}instead.</deprecated>
    </javadoc>
    <method type="PointVectorValuePair" name="optimize" startLine="458" endLine="463" />
    <javadoc>
      <text>* Optimize an objective function.
 * Optimization is considered to be a weighted least-squares minimization.
 * The cost function to be minimized is
 * <code>&sum;weight<sub>i</sub>(objective<sub>i</sub> - target<sub>i</sub>)<sup>2</sup></code></text>
      <param>maxEval Allowed number of evaluations of the objective function.</param>
      <param>f Objective function.</param>
      <param>optData Optimization data. The following data will be looked for:
 * <ul>
 * <li>{@link Target}</li>
 * <li>{@link Weight}</li>
 * <li>{@link InitialGuess}</li>
 * </ul></param>
      <return>the point/value pair giving the optimal value of the objective
 * function.</return>
      <throws>org.apache.commons.math3.exception.TooManyEvaluationsException if
 * the maximal number of evaluations is exceeded.</throws>
      <throws>DimensionMismatchException if the target, and weight arguments
 * have inconsistent dimensions.</throws>
      <see>BaseAbstractMultivariateVectorOptimizer#optimizeInternal(int,MultivariateVectorFunction,OptimizationData[])</see>
      <since>3.1</since>
      <deprecated>As of 3.1. Override is necessary only until this class's generic
 * argument is changed to {@code MultivariateDifferentiableVectorFunction}.</deprecated>
    </javadoc>
    <method type="PointVectorValuePair" name="optimizeInternal" startLine="493" endLine="497">
      <comment>XXX Conversion will be removed when the generic argument of the</comment>
      <comment>base class becomes "MultivariateDifferentiableVectorFunction".</comment>
    </method>
    <javadoc>
      <text>* {@inheritDoc}</text>
    </javadoc>
    <method type="void" name="setUp" startLine="501" endLine="522">
      <comment>Reset counter.</comment>
      <comment>Square-root of the weight matrix.</comment>
      <comment>Store least squares problem characteristics.</comment>
      <comment>XXX The conversion won't be necessary when the generic argument of</comment>
      <comment>the base class becomes "MultivariateDifferentiableVectorFunction".</comment>
      <comment>XXX "jF" is not strictly necessary anymore but is currently more</comment>
      <comment>efficient than converting the value returned from "getObjectiveFunction()"</comment>
      <comment>every time it is used.</comment>
      <comment>Arrays shared with "private" and "protected" methods.</comment>
    </method>
    <javadoc>
      <text>* Computes the residuals.
 * The residual is the difference between the observed (target)
 * values and the model (objective function) value.
 * There is one residual for each element of the vector-valued
 * function.</text>
      <param>objectiveValue Value of the the objective function. This is
 * the value returned from a call to{@link #computeObjectiveValue(double[]) computeObjectiveValue}(whose array argument contains the model parameters).</param>
      <return>the residuals.</return>
      <throws>DimensionMismatchException if {@code params} has a wrong
 * length.</throws>
      <since>3.1</since>
    </javadoc>
    <method type="double[]" name="computeResiduals" startLine="540" endLine="553">
      <declaration type="double[]" name="target" />
      <scope startLine="542" endLine="545" />
      <declaration type="double[]" name="residuals" />
      <scope startLine="548" endLine="550" />
    </method>
    <javadoc>
      <text>* Computes the square-root of the weight matrix.</text>
      <param>m Symmetric, positive-definite (weight) matrix.</param>
      <return>the square-root of the weight matrix.</return>
    </javadoc>
    <method type="RealMatrix" name="squareRoot" startLine="561" endLine="573">
      <scope startLine="562" endLine="569">
        <declaration type="int" name="dim" />
        <declaration type="RealMatrix" name="sqrtM" />
        <scope startLine="565" endLine="567" />
      </scope>
      <scope startLine="569" endLine="572">
        <declaration type="EigenDecomposition" name="dec" />
      </scope>
    </method>
  </class>
</source>
