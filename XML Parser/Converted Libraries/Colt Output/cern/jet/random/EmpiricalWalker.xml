<?xml version="1.0" encoding="UTF-8"?>
<class name="EmpiricalWalker">
  <javadoc>
    <text>Discrete Empirical distribution (pdf's can be specified).
 * &lt;p&gt;
 * The probability distribution function (pdf) must be provided by the user as an array of positive real numbers. 
 * The pdf does not need to be provided in the form of relative probabilities, absolute probabilities are also accepted.
 * &lt;p&gt;
 * &lt;p&gt;
 * Instance methods operate on a user supplied uniform random number generator; they are unsynchronized.
 * &lt;dt&gt;
 * Static methods operate on a default uniform random number generator; they are synchronized.
 * &lt;p&gt;
 * &lt;b&gt;Implementation:&lt;/b&gt;
 * Walker's algorithm. 
 * Generating a random number takes &lt;tt&gt;O(1)&lt;/tt&gt;, i.e. constant time, as opposed to commonly used algorithms with logarithmic time complexity.
 * Preprocessing time (on object construction) is &lt;tt&gt;O(k)&lt;/tt&gt; where &lt;tt&gt;k&lt;/tt&gt; is the number of elements of the provided empirical pdf.
 * Space complexity is &lt;tt&gt;O(k)&lt;/tt&gt;.
 * &lt;p&gt;
 * This is a port of &lt;A HREF="http://sourceware.cygnus.com/cgi-bin/cvsweb.cgi/gsl/randist/discrete.c?cvsroot=gsl"&gt;discrete.c&lt;/A&gt; which was written by James Theiler and is distributed with &lt;A HREF="http://sourceware.cygnus.com/gsl/"&gt;GSL 0.4.1&lt;/A&gt;.
 * Theiler's implementation in turn is based upon
 * &lt;p&gt;
 * Alastair J. Walker, An efficient method for generating
 * discrete random variables with general distributions, ACM Trans
 * Math Soft 3, 253-256 (1977).
 * &lt;p&gt;
 * See also: D. E. Knuth, The Art of
 * Computer Programming, Volume 2 (Seminumerical algorithms), 3rd
 * edition, Addison-Wesley (1997), p120.</text>
    <author>wolfgang.hoschek@cern.ch</author>
    <version>1.0, 09/24/99</version>
  </javadoc>
  <declaration type="int" name="K" />
  <declaration type="int[]" name="A" />
  <declaration type="double[]" name="F" />
  <declaration type="double[]" name="cdf" />
  <javadoc>
    <text>Constructs an Empirical distribution.
 * The probability distribution function (pdf) is an array of positive real numbers. 
 * It need not be provided in the form of relative probabilities, absolute probabilities are also accepted.
 * The &lt;tt&gt;pdf&lt;/tt&gt; must satisfy both of the following conditions
 * &lt;ul&gt;
 * &lt;li&gt;&lt;tt&gt;0.0 &amp;lt;= pdf[i] : 0&amp;lt;=i&amp;lt;=pdf.length-1&lt;/tt&gt;
 * &lt;li&gt;&lt;tt&gt;0.0 &amp;lt; Sum(pdf[i]) : 0&amp;lt;=i&amp;lt;=pdf.length-1&lt;/tt&gt;
 * &lt;/ul&gt;</text>
    <param>pdf the probability distribution function.</param>
    <param>interpolationType can be either &lt;tt&gt;Empirical.NO_INTERPOLATION&lt;/tt&gt; or &lt;tt&gt;Empirical.LINEAR_INTERPOLATION&lt;/tt&gt;.</param>
    <param>randomGenerator a uniform random number generator.</param>
    <throws>IllegalArgumentException if at least one of the three conditions above is violated.</throws>
  </javadoc>
  <method type="constructor" name="EmpiricalWalker" />
  <javadoc>
    <text>Returns the cumulative distribution function.</text>
  </javadoc>
  <method type="double" name="cdf" />
  <javadoc>
    <text>Returns a deep copy of the receiver; the copy will produce identical sequences.
 * After this call has returned, the copy and the receiver have equal but separate state.</text>
    <return>a copy of the receiver.</return>
  </javadoc>
  <method type="Object" name="clone">
    <declaration type="EmpiricalWalker" name="copy" />
  </method>
  <javadoc>
    <text>Returns a random integer &lt;tt&gt;k&lt;/tt&gt; with probability &lt;tt&gt;pdf(k)&lt;/tt&gt;.</text>
  </javadoc>
  <method type="int" name="nextInt">
    <declaration type="int" name="c" />
    <declaration type="double" name="u" />
    <scope />
    <scope />
    <comment>#if KNUTH_CONVENTION</comment>
    <comment>c = (int)(u*(g-&gt;K));</comment>
    <comment>#else</comment>
    <comment>#endif</comment>
    <comment>fprintf(stderr,"c,f,u: %d %.4f %f\n",c,f,u);</comment>
  </method>
  <javadoc>
    <text>Returns the probability distribution function.</text>
  </javadoc>
  <method type="double" name="pdf" />
  <javadoc>
    <text>Sets the distribution parameters.
 * The &lt;tt&gt;pdf&lt;/tt&gt; must satisfy all of the following conditions
 * &lt;ul&gt;
 * &lt;li&gt;&lt;tt&gt;pdf != null &amp;&amp; pdf.length &amp;gt; 0&lt;/tt&gt;
 * &lt;li&gt;&lt;tt&gt;0.0 &amp;lt;= pdf[i] : 0 &amp;lt; =i &amp;lt;= pdf.length-1&lt;/tt&gt;
 * &lt;li&gt;&lt;tt&gt;0.0 &amp;lt; Sum(pdf[i]) : 0 &amp;lt;=i &amp;lt;= pdf.length-1&lt;/tt&gt;
 * &lt;/ul&gt;</text>
    <param>pdf probability distribution function.</param>
    <throws>IllegalArgumentException if at least one of the three conditions above is violated.</throws>
  </javadoc>
  <method type="void" name="setState">
    <scope />
    <declaration type="int" name="nBins" />
    <scope />
    <scope />
    <comment>compute cumulative distribution function (cdf) from probability distribution function (pdf)</comment>
    <comment>now normalize to 1 (relative probabilities).</comment>
    <comment>cdf is now cached...</comment>
  </method>
  <javadoc>
    <text>Sets the distribution parameters.
 * The &lt;tt&gt;pdf&lt;/tt&gt; must satisfy both of the following conditions
 * &lt;ul&gt;
 * &lt;li&gt;&lt;tt&gt;0.0 &amp;lt;= pdf[i] : 0 &amp;lt; =i &amp;lt;= pdf.length-1&lt;/tt&gt;
 * &lt;li&gt;&lt;tt&gt;0.0 &amp;lt; Sum(pdf[i]) : 0 &amp;lt;=i &amp;lt;= pdf.length-1&lt;/tt&gt;
 * &lt;/ul&gt;</text>
    <param>pdf probability distribution function.</param>
    <throws>IllegalArgumentException if at least one of the three conditions above is violated.</throws>
  </javadoc>
  <method type="void" name="setState2">
    <declaration type="int" name="size" />
    <declaration type="int" name="k" />
    <declaration type="int" name="nBigs" />
    <declaration type="Stack" name="Bigs" />
    <declaration type="Stack" name="Smalls" />
    <declaration type="double[]" name="E" />
    <declaration type="double" name="pTotal" />
    <declaration type="double" name="mean" />
    <scope />
    <scope />
    <scope />
    <scope>
      <scope />
      <scope />
    </scope>
    <scope>
      <scope />
      <scope />
      <scope />
      <scope />
    </scope>
    <scope />
    <comment>if (size &lt; 1) {</comment>
    <comment>throw new IllegalArgumentException("must have size greater than zero");</comment>
    <comment>}</comment>
    <comment>Make sure elements of ProbArray[] are positive.
 Won't enforce that sum is unity; instead will just normalize</comment>
    <comment>if (pdf[k] &lt; 0) {</comment>
    <comment>throw new IllegalArgumentException("Probabilities must be &gt;= 0: "+pdf[k]);</comment>
    <comment>}</comment>
    <comment>Begin setting up the internal state</comment>
    <comment>normalize to relative probability</comment>
    <comment>Now create the Bigs and the Smalls</comment>
    <comment>Now work through the smalls</comment>
    <comment>Then we are on our last value</comment>
    <comment>#if DEBUG
fprintf(stderr,"s=%2d, A=%2d, F=%.4f\n",s,(g-&gt;A)[s],(g-&gt;F)[s]);
#endif</comment>
    <comment>E[s] += d;               now E[s] == mean</comment>
    <comment>Smalls.push(b);  no longer big, join ranks of the small</comment>
    <comment>Bigs.push(b);  still big, put it back where you found it</comment>
    <comment>E[b]==mean implies it is finished too</comment>
    <comment>Stacks have been emptied, and A and F have been filled</comment>
    <comment>#if 0</comment>
    <comment>if 1, then artificially set all F[k]'s to unity.  This will
 give wrong answers, but you'll get them faster.  But, not
 that much faster (I get maybe 20%); that's an upper bound
 on what the optimal preprocessing would give.</comment>
    <comment>for (k=0; k&lt;size; ++k) {
F[k] = 1.0;
}
#endif</comment>
    <comment>#if KNUTH_CONVENTION</comment>
    <comment>For convenience, set F'[k]=(k+F[k])K</comment>
    <comment>This saves some arithmetic in gsl_ran_discrete(); I find that
 it doesn't actually make much difference.</comment>
    <comment>for (k=0; k&lt;size; ++k) {
F[k] += k;
F[k] = size;
}
#endif</comment>
    <comment>free_stack(Bigs);
free_stack(Smalls);
free((char )E);

return g;</comment>
  </method>
  <javadoc>
    <text>Returns a String representation of the receiver.</text>
  </javadoc>
  <method type="String" name="toString">
    <declaration type="String" name="interpolation" />
  </method>
  <comment>Copyright ï¿½ 1999 CERN - European Organization for Nuclear Research.
Permission to use, copy, modify, distribute and sell this software and its documentation for any purpose
is hereby granted without fee, provided that the above copyright notice appear in all copies and
that both that copyright notice and this permission notice appear in supporting documentation.
CERN makes no representations about the suitability of this software for any purpose.
It is provided "as is" without expressed or implied warranty.</comment>
  <comment>cumulative distribution function</comment>
  <comment>James Theiler, jt@lanl.gov, the author of the GSL routine this port is based on, describes his approach as follows:

 Based on: Alastair J Walker, An efficient method for generating
 discrete random variables with general distributions, ACM Trans
 Math Soft 3, 253-256 (1977).  See also: D. E. Knuth, The Art of
 Computer Programming, Volume 2 (Seminumerical algorithms), 3rd
 edition, Addison-Wesley (1997), p120.

 Walker's algorithm does some preprocessing, and provides two
 arrays: floating point F[k] and integer A[k].  A value k is chosen
 from 0..K-1 with equal likelihood, and then a uniform random number
 u is compared to F[k].  If it is less than F[k], then k is
 returned.  Otherwise, A[k] is returned.

 Walker's original paper describes an O(K^2) algorithm for setting
 up the F and A arrays.  I found this disturbing since I wanted to
 use very large values of K.  I'm sure I'm not the first to realize
 this, but in fact the preprocessing can be done in O(K) steps.

 A figure of merit for the preprocessing is the average value for
 the F[k]'s (that is, SUM_k F[k]K); this corresponds to the
 probability that k is returned, instead of A[k], thereby saving a
 redirection.  Walker's O(K^2) preprocessing will generally improve
 that figure of merit, compared to my cheaper O(K) method; from some
 experiments with a perl script, I get values of around 0.6 for my
 method and just under 0.75 for Walker's.  Knuth has pointed out
 that finding _the_ optimum lookup tables, which maximize the
 average F[k], is a combinatorially difficult problem.  But any
 valid preprocessing will still provide O(1) time for the call to
 gsl_ran_discrete().  I find that if I artificially set F[k]=1 --
 ie, better than optimum! -- I get a speedup of maybe 20%, so that's
 the maximum I could expect from the most expensive preprocessing.
 Folding in the difference of 0.6 vs 0.75, I'd estimate that the
 speedup would be less than 10%.

 I've not implemented it here, but one compromise is to sort the
 probabilities once, and then work from the two ends inward.  This
 requires O(K log K), still lots cheaper than O(K^2), and from my
 experiments with the perl script, the figure of merit is within
 about 0.01 for K up to 1000, and no sign of diverging (in fact,
 they seemed to be converging, but it's hard to say with just a
 handful of runs).

 The O(K) algorithm goes through all the p_k's and decides if they
 are "smalls" or "bigs" according to whether they are less than or
 greater than the mean value 1K.  The indices to the smalls and the
 bigs are put in separate stacks, and then we work through the
 stacks together.  For each small, we pair it up with the next big
 in the stack (Walker always wanted to pair up the smallest small
 with the biggest big).  The small "borrows" from the big just
 enough to bring the small up to mean.  This reduces the size of the
 big, so the (smaller) big is compared again to the mean, and if it
 is smaller, it gets "popped" from the big stack and "pushed" to the
 small stack.  Otherwise, it stays put.  Since every time we pop a
 small, we are able to deal with it right then and there, and we
 never have to pop more than K smalls, then the algorithm is O(K).

 This implementation sets up two separate stacks, and allocates K
 elements between them.  Since neither stack ever grows, we do an
 extra O(K) pass through the data to determine how many smalls and
 bigs there are to begin with and allocate appropriately.  In all
 there are 2Ksizeof(double) transient bytes of memory that are
 used than returned, and K(sizeof(int)+sizeof(double)) bytes used
 in the lookup table.

 Walker spoke of using two random numbers (an integer 0..K-1, and a
 floating point u in [0,1]), but Knuth points out that one can just
 use the integer and fractional parts of Ku where u is in [0,1].
 In fact, Knuth further notes that taking F'[k]=(k+F[k])K, one can
 directly compare u to F'[k] without having to explicitly set
 u=Ku-int(Ku).

 Usage:

 Starting with an array of probabilities P, initialize and do
 preprocessing with a call to:

    gsl_rng r;
    gsl_ran_discrete_t f;
    f = gsl_ran_discrete_preproc(K,P);

 Then, whenever a random index 0..K-1 is desired, use

    k = gsl_ran_discrete(r,f);

 Note that several different randevent struct's can be
 simultaneously active.

 Aside: A very clever alternative approach is described in
 Abramowitz and Stegun, p 950, citing: Marsaglia, Random variables
 and computers, Proc Third Prague Conference in Probability Theory,
 1962.  A more accesible reference is: G. Marsaglia, Generating
 discrete random numbers in a computer, Comm ACM 6, 37-38 (1963).
 If anybody is interested, I (jt) have also coded up this version as
 part of another software package.  However, I've done some
 comparisons, and the Walker method is both faster and more stingy
 with memory.  So, in the end I decided not to include it with the
 GSL package.

 Written 26 Jan 1999, James Theiler, jt@lanl.gov
 Adapted to GSL, 30 Jan 1999, jt</comment>
</class>
